{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CS506 Midterm Kaggle Competition Final Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name: Youxuan Ma, U23330522"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kaggle Username: MarkMa316"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from geopy.distance import geodesic\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Calculate distance from home function\n",
    "def calculate_distance(row):\n",
    "    home_location = (row['lat'], row['long'])\n",
    "    merch_location = (row['merch_lat'], row['merch_long'])\n",
    "    return geodesic(home_location, merch_location).miles\n",
    "\n",
    "# Function to calculate distance between two points\n",
    "def calculate_distance2(row1, row2):\n",
    "    point1 = (row1['lat'], row1['long'])\n",
    "    point2 = (row2['lat'], row2['long'])\n",
    "    return geodesic(point1, point2).miles\n",
    "\n",
    "def calculate_similarity_score(amount, fraud_mean, fraud_std, normal_mean, normal_std):\n",
    "    # Calculate Z-scores for fraud and normal\n",
    "    z_score_fraud = abs((amount - fraud_mean) / fraud_std)\n",
    "    z_score_normal = abs((amount - normal_mean) / normal_std)\n",
    "    \n",
    "    # Invert the Z-scores to get similarity scores\n",
    "    fraud_similarity = 1 / (1 + z_score_fraud)\n",
    "    normal_similarity = 1 / (1 + z_score_normal)\n",
    "    \n",
    "    return fraud_similarity, normal_similarity\n",
    "\n",
    "def process(df):\n",
    "    # Rearrange the rows\n",
    "    df['original_order'] = range(df.shape[0])\n",
    "\n",
    "    df['trans_date_trans_time'] = pd.to_datetime(df['trans_date_trans_time'], format='%d/%m/%Y %H:%M')\n",
    "    df['dob'] = pd.to_datetime(df['dob'], format='%d/%m/%Y')\n",
    "\n",
    "    df.sort_values(by=['cc_num', 'trans_date_trans_time'], inplace=True)\n",
    "    \n",
    "    # Calculate the time difference between transactions\n",
    "    df['Time_Delta'] = df.groupby('cc_num')['trans_date_trans_time'].diff().dt.total_seconds() / 60.0  # Time delta in minutes\n",
    "    df['Time_Delta'] = df['Time_Delta'].fillna(value=0)\n",
    "    \n",
    "    # Shift the latitude and longitude to get the previous transaction's location\n",
    "    df['prev_lat'] = df.groupby('cc_num')['merch_lat'].shift(1)\n",
    "    df['prev_long'] = df.groupby('cc_num')['merch_long'].shift(1)\n",
    "\n",
    "    # Calculate the distance to the previous transaction\n",
    "    df['distance_to_prev'] = df.apply(\n",
    "        lambda row: calculate_distance2(\n",
    "            {'lat': row['merch_lat'], 'long': row['merch_long']},\n",
    "            {'lat': row['prev_lat'], 'long': row['prev_long']}\n",
    "        ) if not pd.isnull(row['prev_lat']) else None,\n",
    "        axis=1\n",
    "    )\n",
    "    df['distance_to_prev'] = df['distance_to_prev'].fillna(value=0)\n",
    "\n",
    "    # Calculate location consistency as the inverse of the average distance to previous transactions (higher value means more consistency)\n",
    "    df['location_consistency'] = 100 / df.groupby('cc_num')['distance_to_prev'].transform('mean')\n",
    "\n",
    "    # Time-based features\n",
    "    df['hour'] = df['trans_date_trans_time'].dt.hour\n",
    "    df['day_of_week'] = df['trans_date_trans_time'].dt.dayofweek\n",
    "    df['month'] = df['trans_date_trans_time'].dt.month\n",
    "    df['day_of_month'] = df['trans_date_trans_time'].dt.day\n",
    "   \n",
    "    # Age of the account holder\n",
    "    df['age'] = (df['trans_date_trans_time'] - df['dob']).dt.days // 365\n",
    "\n",
    "    # Calculate the transaction distance from home\n",
    "    df['dist_to_home'] = df.apply(calculate_distance, axis=1)\n",
    "\n",
    "    # Group by category and calculate the mean and standard deviation of transaction amounts\n",
    "    category_stats = df.groupby('category')['amt'].agg(['mean', 'std']).reset_index()\n",
    "    # Merge these stats back into the main dataframe\n",
    "    df = df.merge(category_stats, on='category', how='left')\n",
    "    # Calculate z-score for each transaction amount within its category\n",
    "    df['amt_anomaly_score_cat'] = ((df['amt'] - df['mean']) / df['std'])\n",
    "    df.drop(columns=['mean', 'std'], inplace=True)\n",
    "    # Group by merchant and calculate the mean and standard deviation of transaction amounts\n",
    "    merchant_stats = df.groupby('merchant')['amt'].agg(['mean', 'std']).reset_index()\n",
    "    # Merge these stats back into the main dataframe\n",
    "    df = df.merge(merchant_stats, on='merchant', how='left')\n",
    "    # Calculate z-score for each transaction amount within its merchant\n",
    "    df['amt_anomaly_score_merch'] = ((df['amt'] - df['mean']) / df['std'])\n",
    "    df.drop(columns=['mean', 'std'], inplace=True)\n",
    "\n",
    "    # Calculate the historical average transaction amount for each user\n",
    "    avg_amt_per_user = df.groupby('cc_num')['amt'].transform('mean').rename('avg_amt_per_user')\n",
    "\n",
    "    # Append this feature to the dataset\n",
    "    df['amt_relative_avg'] = (abs(df['amt'] - avg_amt_per_user) / avg_amt_per_user)\n",
    "\n",
    "    kmeans = KMeans(n_clusters=12, random_state=42)\n",
    "\n",
    "    # Create a new column for the city pop cluster labels\n",
    "    df['city_pop_cluster'] = kmeans.fit_predict(df[['city_pop']])\n",
    "\n",
    "    df.drop(columns=['trans_date_trans_time', 'lat', 'long', 'merch_lat', 'merch_long'], inplace=True)\n",
    "    df.drop(columns=['prev_lat', 'prev_long'], inplace=True)\n",
    "\n",
    "    # Identify categorical columns to encode\n",
    "    categorical_cols = ['merchant', 'category', 'gender', 'city', 'state', 'job']\n",
    "\n",
    "    mappings = {}\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    for col in categorical_cols:\n",
    "        df[col] = label_encoder.fit_transform(df[col])\n",
    "        mappings[col] = {label: index for index, label in enumerate(label_encoder.classes_)}\n",
    "\n",
    "    # Calculate the fraud rate by category\n",
    "    fraud_rate_by_category = df.groupby('category')['is_fraud'].mean().reset_index()\n",
    "    fraud_rate_by_category.rename(columns={'is_fraud': 'fraud_rate_cat'}, inplace=True)\n",
    "\n",
    "    # Merge the fraud rate back into the main DataFrame\n",
    "    df = pd.merge(df, fraud_rate_by_category[['category', 'fraud_rate_cat']], on='category', how='left')\n",
    "\n",
    "    # Calculate the fraud rate by merchant\n",
    "    fraud_rate_by_merchant = df.groupby('merchant')['is_fraud'].mean().reset_index()\n",
    "    fraud_rate_by_merchant.rename(columns={'is_fraud': 'fraud_rate_merch'}, inplace=True)\n",
    "\n",
    "    # Merge the fraud rate back into the main DataFrame\n",
    "    df = pd.merge(df, fraud_rate_by_merchant[['merchant', 'fraud_rate_merch']], on='merchant', how='left')\n",
    "\n",
    "    # Separate the transactions by fraud and normal\n",
    "    fraud_trans = df[df['is_fraud'] == 1]['amt']\n",
    "    normal_trans = df[df['is_fraud'] == 0]['amt']\n",
    "\n",
    "    # Calculate statistics\n",
    "    fraud_mean, fraud_std = fraud_trans.mean(), fraud_trans.std()\n",
    "    normal_mean, normal_std = normal_trans.mean(), normal_trans.std()\n",
    "\n",
    "    v_calculate_similarity_score = np.vectorize(calculate_similarity_score)\n",
    "\n",
    "    # Apply the function\n",
    "    df['fraud_similarity'], df['normal_similarity'] = v_calculate_similarity_score(\n",
    "        df['amt'],\n",
    "        fraud_mean, fraud_std,\n",
    "        normal_mean, normal_std\n",
    "    )\n",
    "\n",
    "    # Sort the dataset back to its original order\n",
    "    df.sort_values(by='original_order', inplace=True)\n",
    "    df.drop(columns='original_order', inplace=True)\n",
    "    df.drop(columns='cc_num', inplace=True)\n",
    "\n",
    "    return df, mappings\n",
    "\n",
    "trainingSet = pd.read_csv(\"./data/train.csv\")\n",
    "submissionSet = pd.read_csv(\"./data/test.csv\")\n",
    "train_processed, cat_map = process(trainingSet)\n",
    "train_processed.drop(columns=['first', 'last', 'street', 'dob', 'zip', 'trans_num', 'unix_time'], inplace=True)\n",
    "\n",
    "# Merge on Id so that the test set can have feature columns as well\n",
    "test_df = pd.merge(train_processed, submissionSet, left_on='Id', right_on='Id')\n",
    "test_df = test_df.drop(columns=['is_fraud_x'])\n",
    "test_df = test_df.rename(columns={'is_fraud_y': 'is_fraud'})\n",
    "\n",
    "# The training set is where the score is not null\n",
    "train_df = train_processed[train_processed['is_fraud'].notnull()]\n",
    "\n",
    "# Save the datasets with the new features\n",
    "test_df.to_csv(\"./data/final_processed_test.csv\", index=False)\n",
    "train_df.to_csv(\"./data/final_processed_train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Turned out the 'city_pop_cluster' feature was not useful\n",
    "X = train_df.drop(['is_fraud', 'Id', 'city_pop_cluster'], axis=1)\n",
    "y = train_df['is_fraud']\n",
    "\n",
    "num_cols = ['amt', 'Time_Delta', 'distance_to_prev', 'location_consistency', 'dist_to_home', 'amt_anomaly_score_cat', 'amt_anomaly_score_merch', 'amt_relative_avg', 'fraud_rate_cat', 'fraud_rate_merch', 'fraud_similarity', 'normal_similarity']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X[num_cols] = scaler.fit_transform(X[num_cols])\n",
    "test_df[num_cols] = scaler.transform(test_df[num_cols])\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score, make_scorer\n",
    "\n",
    "# Initialize the XGBClassifier\n",
    "xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7, 10, None],\n",
    "    'learning_rate': [0.05, 0.1, 0.15, 0.2],\n",
    "    'n_estimators': [300, 500, 900],\n",
    "    'colsample_bytree': [0.3, 0.7, 0.9]\n",
    "}\n",
    "\n",
    "# Set up GridSearchCV to find the best hyperparameters\n",
    "grid_search = GridSearchCV(estimator=xgb, param_grid=param_grid, scoring='f1_micro', cv=5, n_jobs=-1, verbose=3)\n",
    "grid_search.fit(X_train, y_train)\n",
    "clf = grid_search.best_estimator_\n",
    "# Best parameters and best score\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "print(\"Best average F1 score found: \", f1_score(y_val, clf.predict(X_val)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9085714285714286\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     96876\n",
      "         1.0       0.98      0.85      0.91       375\n",
      "\n",
      "    accuracy                           1.00     97251\n",
      "   macro avg       0.99      0.92      0.95     97251\n",
      "weighted avg       1.00      1.00      1.00     97251\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score, make_scorer\n",
    "# Initialize the XGBClassifier with the best hyperparameters\n",
    "xgb_clf = XGBClassifier(colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=900, use_label_encoder=False, eval_metric='logloss')\n",
    "\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_xgb = xgb_clf.predict(X_val)\n",
    "print(f1_score(y_val, y_pred_xgb))\n",
    "print(classification_report(y_val, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8981348637015782\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     96876\n",
      "         1.0       0.97      0.83      0.90       375\n",
      "\n",
      "    accuracy                           1.00     97251\n",
      "   macro avg       0.99      0.92      0.95     97251\n",
      "weighted avg       1.00      1.00      1.00     97251\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score, make_scorer\n",
    "# Initialize the XGBClassifier with another set of hyperparameters\n",
    "xgb_clf2 = XGBClassifier(colsample_bytree=0.9, learning_rate=0.15, max_depth=None, n_estimators=900, use_label_encoder=False, eval_metric='logloss')\n",
    "\n",
    "xgb_clf2.fit(X_train, y_train)\n",
    "\n",
    "y_pred_xgb2 = xgb_clf2.predict(X_val)\n",
    "print(f1_score(y_val, y_pred_xgb2))\n",
    "print(classification_report(y_val, y_pred_xgb2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building estimator 1 of 7 for this parallel run (total 100)...\n",
      "Building estimator 1 of 6 for this parallel run (total 100)...\n",
      "Building estimator 1 of 7 for this parallel run (total 100)...\n",
      "Building estimator 1 of 6 for this parallel run (total 100)...\n",
      "Building estimator 1 of 7 for this parallel run (total 100)...\n",
      "Building estimator 1 of 6 for this parallel run (total 100)...\n",
      "Building estimator 1 of 7 for this parallel run (total 100)...\n",
      "Building estimator 1 of 6 for this parallel run (total 100)...\n",
      "Building estimator 1 of 6 for this parallel run (total 100)...\n",
      "Building estimator 1 of 6 for this parallel run (total 100)...\n",
      "Building estimator 1 of 6 for this parallel run (total 100)...\n",
      "Building estimator 1 of 6 for this parallel run (total 100)...\n",
      "Building estimator 1 of 6 for this parallel run (total 100)...\n",
      "Building estimator 1 of 6 for this parallel run (total 100)...\n",
      "Building estimator 1 of 6 for this parallel run (total 100)...\n",
      "Building estimator 1 of 6 for this parallel run (total 100)...\n",
      "Building estimator 2 of 6 for this parallel run (total 100)...\n",
      "Building estimator 2 of 7 for this parallel run (total 100)...\n",
      "Building estimator 2 of 6 for this parallel run (total 100)...\n",
      "Building estimator 2 of 7 for this parallel run (total 100)...\n",
      "Building estimator 2 of 6 for this parallel run (total 100)...\n",
      "Building estimator 2 of 6 for this parallel run (total 100)...\n",
      "Building estimator 2 of 6 for this parallel run (total 100)...\n",
      "Building estimator 2 of 6 for this parallel run (total 100)...\n",
      "Building estimator 2 of 6 for this parallel run (total 100)...\n",
      "Building estimator 2 of 6 for this parallel run (total 100)...\n",
      "Building estimator 2 of 6 for this parallel run (total 100)...\n",
      "Building estimator 2 of 7 for this parallel run (total 100)...\n",
      "Building estimator 2 of 6 for this parallel run (total 100)...\n",
      "Building estimator 2 of 7 for this parallel run (total 100)...\n",
      "Building estimator 2 of 6 for this parallel run (total 100)...\n",
      "Building estimator 2 of 6 for this parallel run (total 100)...\n",
      "Building estimator 3 of 6 for this parallel run (total 100)...\n",
      "Building estimator 3 of 7 for this parallel run (total 100)...\n",
      "Building estimator 3 of 6 for this parallel run (total 100)...\n",
      "Building estimator 3 of 7 for this parallel run (total 100)...\n",
      "Building estimator 3 of 7 for this parallel run (total 100)...\n",
      "Building estimator 3 of 6 for this parallel run (total 100)...\n",
      "Building estimator 3 of 6 for this parallel run (total 100)...\n",
      "Building estimator 3 of 6 for this parallel run (total 100)...\n",
      "Building estimator 3 of 6 for this parallel run (total 100)...\n",
      "Building estimator 3 of 6 for this parallel run (total 100)...\n",
      "Building estimator 3 of 6 for this parallel run (total 100)...\n",
      "Building estimator 3 of 6 for this parallel run (total 100)...\n",
      "Building estimator 3 of 6 for this parallel run (total 100)...\n",
      "Building estimator 3 of 7 for this parallel run (total 100)...\n",
      "Building estimator 3 of 6 for this parallel run (total 100)...\n",
      "Building estimator 3 of 6 for this parallel run (total 100)...\n",
      "Building estimator 4 of 6 for this parallel run (total 100)...\n",
      "Building estimator 4 of 6 for this parallel run (total 100)...\n",
      "Building estimator 4 of 7 for this parallel run (total 100)...\n",
      "Building estimator 4 of 7 for this parallel run (total 100)...\n",
      "Building estimator 4 of 7 for this parallel run (total 100)...\n",
      "Building estimator 4 of 6 for this parallel run (total 100)...\n",
      "Building estimator 4 of 6 for this parallel run (total 100)...\n",
      "Building estimator 4 of 6 for this parallel run (total 100)...\n",
      "Building estimator 4 of 6 for this parallel run (total 100)...\n",
      "Building estimator 4 of 6 for this parallel run (total 100)...\n",
      "Building estimator 4 of 6 for this parallel run (total 100)...\n",
      "Building estimator 4 of 6 for this parallel run (total 100)...\n",
      "Building estimator 4 of 7 for this parallel run (total 100)...\n",
      "Building estimator 4 of 6 for this parallel run (total 100)...\n",
      "Building estimator 4 of 6 for this parallel run (total 100)...\n",
      "Building estimator 4 of 6 for this parallel run (total 100)...\n",
      "Building estimator 5 of 6 for this parallel run (total 100)...\n",
      "Building estimator 5 of 6 for this parallel run (total 100)...\n",
      "Building estimator 5 of 7 for this parallel run (total 100)...\n",
      "Building estimator 5 of 7 for this parallel run (total 100)...\n",
      "Building estimator 5 of 6 for this parallel run (total 100)...\n",
      "Building estimator 5 of 6 for this parallel run (total 100)...\n",
      "Building estimator 5 of 6 for this parallel run (total 100)...\n",
      "Building estimator 5 of 7 for this parallel run (total 100)...\n",
      "Building estimator 5 of 6 for this parallel run (total 100)...\n",
      "Building estimator 5 of 6 for this parallel run (total 100)...\n",
      "Building estimator 5 of 6 for this parallel run (total 100)...\n",
      "Building estimator 5 of 6 for this parallel run (total 100)...\n",
      "Building estimator 5 of 6 for this parallel run (total 100)...\n",
      "Building estimator 5 of 7 for this parallel run (total 100)...\n",
      "Building estimator 5 of 6 for this parallel run (total 100)...\n",
      "Building estimator 5 of 6 for this parallel run (total 100)...\n",
      "Building estimator 6 of 6 for this parallel run (total 100)...\n",
      "Building estimator 6 of 6 for this parallel run (total 100)...\n",
      "Building estimator 6 of 7 for this parallel run (total 100)...\n",
      "Building estimator 6 of 6 for this parallel run (total 100)...\n",
      "Building estimator 6 of 7 for this parallel run (total 100)...\n",
      "Building estimator 6 of 6 for this parallel run (total 100)...\n",
      "Building estimator 6 of 6 for this parallel run (total 100)...\n",
      "Building estimator 6 of 6 for this parallel run (total 100)...\n",
      "Building estimator 6 of 6 for this parallel run (total 100)...\n",
      "Building estimator 6 of 7 for this parallel run (total 100)...\n",
      "Building estimator 6 of 6 for this parallel run (total 100)...\n",
      "Building estimator 6 of 6 for this parallel run (total 100)...\n",
      "Building estimator 6 of 6 for this parallel run (total 100)...\n",
      "Building estimator 6 of 7 for this parallel run (total 100)...\n",
      "Building estimator 6 of 6 for this parallel run (total 100)...\n",
      "Building estimator 6 of 6 for this parallel run (total 100)...\n",
      "Building estimator 7 of 7 for this parallel run (total 100)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Done   3 out of  16 | elapsed:  2.4min remaining: 10.3min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building estimator 7 of 7 for this parallel run (total 100)...\n",
      "Building estimator 7 of 7 for this parallel run (total 100)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Done   9 out of  16 | elapsed:  2.4min remaining:  1.9min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building estimator 7 of 7 for this parallel run (total 100)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:  2.7min finished\n",
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done   3 out of  16 | elapsed:    8.7s remaining:   37.6s\n",
      "[Parallel(n_jobs=16)]: Done   9 out of  16 | elapsed:    9.0s remaining:    7.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8694362017804155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:    9.7s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pickle\n",
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "# Initialize the Bagging Classifier with the XGB Classifier as the base estimator\n",
    "bagging_clf = BaggingClassifier(estimator=xgb_clf, n_estimators=100, random_state=42, n_jobs=-1, verbose=3)\n",
    "\n",
    "bagging_clf.fit(X_train, y_train)\n",
    "y_pred_bag = bagging_clf.predict(X_val)\n",
    "print(f1_score(y_val, y_pred_bag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize a basic Random Forest model\n",
    "rf = RandomForestClassifier(class_weight='balanced_subsample', random_state=40)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [300, 500, 900],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "# Setup GridSearchCV to find the best hyperparameters\n",
    "grid_search_rf = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, scoring='f1', n_jobs=-1, verbose=3)\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and model\n",
    "best_params = grid_search_rf.best_params_\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "\n",
    "best_rf_model = grid_search_rf.best_estimator_\n",
    "# Prediction and Evaluation\n",
    "y_pred_rf = best_rf_model.predict(X_val)\n",
    "print(f1_score(y_val, y_pred_rf))\n",
    "print(classification_report(y_val, y_pred_rf))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8115107913669065\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     96876\n",
      "         1.0       0.88      0.75      0.81       375\n",
      "\n",
      "    accuracy                           1.00     97251\n",
      "   macro avg       0.94      0.88      0.91     97251\n",
      "weighted avg       1.00      1.00      1.00     97251\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pickle\n",
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "# Initialize the Random Forest Classifier with the best hyperparameters\n",
    "rf1 = RandomForestClassifier(class_weight='balanced_subsample', n_estimators=300, max_depth=None, min_samples_split=10, min_samples_leaf=4, criterion='entropy', n_jobs=-1, random_state=42)\n",
    "\n",
    "rf1.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf1 = rf1.predict(X_val)\n",
    "print(f1_score(y_val, y_pred_rf1))\n",
    "print(classification_report(y_val, y_pred_rf1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8036529680365296\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     96876\n",
      "         1.0       0.94      0.70      0.80       375\n",
      "\n",
      "    accuracy                           1.00     97251\n",
      "   macro avg       0.97      0.85      0.90     97251\n",
      "weighted avg       1.00      1.00      1.00     97251\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test out another set of hyperparameters\n",
    "rf2 = RandomForestClassifier(class_weight='balanced_subsample', n_estimators=900, max_depth=None, min_samples_split=10, min_samples_leaf=1, criterion='entropy', n_jobs=-1)\n",
    "\n",
    "rf2.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf2 = rf2.predict(X_val)\n",
    "print(f1_score(y_val, y_pred_rf2))\n",
    "print(classification_report(y_val, y_pred_rf2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building estimator 1 of 7 for this parallel run (total 100)...\n",
      "Building estimator 1 of 7 for this parallel run (total 100)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building estimator 1 of 7 for this parallel run (total 100)...\n",
      "Building estimator 1 of 7 for this parallel run (total 100)...\n",
      "Building estimator 1 of 6 for this parallel run (total 100)...\n",
      "Building estimator 1 of 6 for this parallel run (total 100)...\n",
      "Building estimator 1 of 6 for this parallel run (total 100)...\n",
      "Building estimator 1 of 6 for this parallel run (total 100)...\n",
      "Building estimator 1 of 6 for this parallel run (total 100)...\n",
      "Building estimator 1 of 6 for this parallel run (total 100)...\n",
      "Building estimator 1 of 6 for this parallel run (total 100)...\n",
      "Building estimator 1 of 6 for this parallel run (total 100)...\n",
      "Building estimator 1 of 6 for this parallel run (total 100)...\n",
      "Building estimator 1 of 6 for this parallel run (total 100)...\n",
      "Building estimator 1 of 6 for this parallel run (total 100)...\n",
      "Building estimator 1 of 6 for this parallel run (total 100)...\n",
      "Building estimator 2 of 7 for this parallel run (total 100)...\n",
      "Building estimator 2 of 7 for this parallel run (total 100)...\n",
      "Building estimator 2 of 7 for this parallel run (total 100)...\n",
      "Building estimator 2 of 6 for this parallel run (total 100)...\n",
      "Building estimator 2 of 7 for this parallel run (total 100)...\n",
      "Building estimator 2 of 6 for this parallel run (total 100)...\n",
      "Building estimator 2 of 6 for this parallel run (total 100)...\n",
      "Building estimator 2 of 6 for this parallel run (total 100)...\n",
      "Building estimator 2 of 6 for this parallel run (total 100)...\n",
      "Building estimator 2 of 6 for this parallel run (total 100)...\n",
      "Building estimator 2 of 6 for this parallel run (total 100)...\n",
      "Building estimator 2 of 6 for this parallel run (total 100)...\n",
      "Building estimator 2 of 6 for this parallel run (total 100)...\n",
      "Building estimator 2 of 6 for this parallel run (total 100)...\n",
      "Building estimator 2 of 6 for this parallel run (total 100)...\n",
      "Building estimator 2 of 6 for this parallel run (total 100)...\n",
      "Building estimator 3 of 7 for this parallel run (total 100)...\n",
      "Building estimator 3 of 7 for this parallel run (total 100)...\n",
      "Building estimator 3 of 6 for this parallel run (total 100)...\n",
      "Building estimator 3 of 7 for this parallel run (total 100)...\n",
      "Building estimator 3 of 6 for this parallel run (total 100)...\n",
      "Building estimator 3 of 6 for this parallel run (total 100)...\n",
      "Building estimator 3 of 7 for this parallel run (total 100)...\n",
      "Building estimator 3 of 6 for this parallel run (total 100)...\n",
      "Building estimator 3 of 6 for this parallel run (total 100)...\n",
      "Building estimator 3 of 6 for this parallel run (total 100)...\n",
      "Building estimator 3 of 6 for this parallel run (total 100)...\n",
      "Building estimator 3 of 6 for this parallel run (total 100)...\n",
      "Building estimator 3 of 6 for this parallel run (total 100)...\n",
      "Building estimator 3 of 6 for this parallel run (total 100)...\n",
      "Building estimator 3 of 6 for this parallel run (total 100)...\n",
      "Building estimator 3 of 6 for this parallel run (total 100)...\n",
      "Building estimator 4 of 7 for this parallel run (total 100)...\n",
      "Building estimator 4 of 7 for this parallel run (total 100)...\n",
      "Building estimator 4 of 6 for this parallel run (total 100)...\n",
      "Building estimator 4 of 6 for this parallel run (total 100)...\n",
      "Building estimator 4 of 7 for this parallel run (total 100)...\n",
      "Building estimator 4 of 6 for this parallel run (total 100)...\n",
      "Building estimator 4 of 6 for this parallel run (total 100)...\n",
      "Building estimator 4 of 7 for this parallel run (total 100)...\n",
      "Building estimator 4 of 6 for this parallel run (total 100)...\n",
      "Building estimator 4 of 6 for this parallel run (total 100)...\n",
      "Building estimator 4 of 6 for this parallel run (total 100)...\n",
      "Building estimator 4 of 6 for this parallel run (total 100)...\n",
      "Building estimator 4 of 6 for this parallel run (total 100)...\n",
      "Building estimator 4 of 6 for this parallel run (total 100)...\n",
      "Building estimator 4 of 6 for this parallel run (total 100)...\n",
      "Building estimator 4 of 6 for this parallel run (total 100)...\n",
      "Building estimator 5 of 7 for this parallel run (total 100)...\n",
      "Building estimator 5 of 7 for this parallel run (total 100)...\n",
      "Building estimator 5 of 6 for this parallel run (total 100)...\n",
      "Building estimator 5 of 7 for this parallel run (total 100)...\n",
      "Building estimator 5 of 6 for this parallel run (total 100)...\n",
      "Building estimator 5 of 6 for this parallel run (total 100)...\n",
      "Building estimator 5 of 7 for this parallel run (total 100)...\n",
      "Building estimator 5 of 6 for this parallel run (total 100)...\n",
      "Building estimator 5 of 6 for this parallel run (total 100)...\n",
      "Building estimator 5 of 6 for this parallel run (total 100)...\n",
      "Building estimator 5 of 6 for this parallel run (total 100)...\n",
      "Building estimator 5 of 6 for this parallel run (total 100)...\n",
      "Building estimator 5 of 6 for this parallel run (total 100)...\n",
      "Building estimator 5 of 6 for this parallel run (total 100)...\n",
      "Building estimator 5 of 6 for this parallel run (total 100)...\n",
      "Building estimator 5 of 6 for this parallel run (total 100)...\n",
      "Building estimator 6 of 7 for this parallel run (total 100)...\n",
      "Building estimator 6 of 7 for this parallel run (total 100)...\n",
      "Building estimator 6 of 6 for this parallel run (total 100)...\n",
      "Building estimator 6 of 7 for this parallel run (total 100)...\n",
      "Building estimator 6 of 6 for this parallel run (total 100)...\n",
      "Building estimator 6 of 6 for this parallel run (total 100)...\n",
      "Building estimator 6 of 7 for this parallel run (total 100)...\n",
      "Building estimator 6 of 6 for this parallel run (total 100)...\n",
      "Building estimator 6 of 6 for this parallel run (total 100)...\n",
      "Building estimator 6 of 6 for this parallel run (total 100)...\n",
      "Building estimator 6 of 6 for this parallel run (total 100)...\n",
      "Building estimator 6 of 6 for this parallel run (total 100)...\n",
      "Building estimator 6 of 6 for this parallel run (total 100)...\n",
      "Building estimator 6 of 6 for this parallel run (total 100)...\n",
      "Building estimator 6 of 6 for this parallel run (total 100)...\n",
      "Building estimator 6 of 6 for this parallel run (total 100)...\n",
      "Building estimator 7 of 7 for this parallel run (total 100)...\n",
      "Building estimator 7 of 7 for this parallel run (total 100)...\n",
      "Building estimator 7 of 7 for this parallel run (total 100)...\n",
      "Building estimator 7 of 7 for this parallel run (total 100)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Done   3 out of  16 | elapsed: 15.0min remaining: 64.9min\n",
      "[Parallel(n_jobs=16)]: Done   9 out of  16 | elapsed: 15.1min remaining: 11.8min\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed: 15.5min finished\n",
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=16)]: Done   3 out of  16 | elapsed:    2.9s remaining:   12.5s\n",
      "[Parallel(n_jobs=16)]: Done   9 out of  16 | elapsed:    6.5s remaining:    5.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7867435158501441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:    9.9s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pickle\n",
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "# Initialize the Bagging Classifier for the Random Forest model\n",
    "bagging_rf_clf = BaggingClassifier(estimator=rf1, n_estimators=100, n_jobs=-1, verbose=3)\n",
    "\n",
    "bagging_rf_clf.fit(X_train, y_train)\n",
    "y_pred_bag_rf = bagging_rf_clf.predict(X_val)\n",
    "print(f1_score(y_val, y_pred_bag_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building estimator 1 of 7 for this parallel run (total 100)...\n",
      "Building estimator 1 of 7 for this parallel run (total 100)...\n",
      "Building estimator 1 of 7 for this parallel run (total 100)...\n",
      "Building estimator 1 of 7 for this parallel run (total 100)...\n",
      "Building estimator 1 of 6 for this parallel run (total 100)...\n",
      "Building estimator 1 of 6 for this parallel run (total 100)...\n",
      "Building estimator 1 of 6 for this parallel run (total 100)...\n",
      "Building estimator 1 of 6 for this parallel run (total 100)...\n",
      "Building estimator 1 of 6 for this parallel run (total 100)...\n",
      "Building estimator 1 of 6 for this parallel run (total 100)...\n",
      "Building estimator 1 of 6 for this parallel run (total 100)...\n",
      "Building estimator 1 of 6 for this parallel run (total 100)...\n",
      "Building estimator 1 of 6 for this parallel run (total 100)...\n",
      "Building estimator 1 of 6 for this parallel run (total 100)...\n",
      "Building estimator 1 of 6 for this parallel run (total 100)...\n",
      "Building estimator 1 of 6 for this parallel run (total 100)...\n",
      "Building estimator 2 of 6 for this parallel run (total 100)...\n",
      "Building estimator 2 of 6 for this parallel run (total 100)...\n",
      "Building estimator 2 of 7 for this parallel run (total 100)...\n",
      "Building estimator 2 of 6 for this parallel run (total 100)...\n",
      "Building estimator 2 of 6 for this parallel run (total 100)...\n",
      "Building estimator 2 of 6 for this parallel run (total 100)...\n",
      "Building estimator 2 of 7 for this parallel run (total 100)...\n",
      "Building estimator 2 of 6 for this parallel run (total 100)...\n",
      "Building estimator 2 of 6 for this parallel run (total 100)...\n",
      "Building estimator 2 of 6 for this parallel run (total 100)...\n",
      "Building estimator 2 of 6 for this parallel run (total 100)...\n",
      "Building estimator 2 of 7 for this parallel run (total 100)...\n",
      "Building estimator 2 of 6 for this parallel run (total 100)...\n",
      "Building estimator 2 of 7 for this parallel run (total 100)...\n",
      "Building estimator 2 of 6 for this parallel run (total 100)...\n",
      "Building estimator 2 of 6 for this parallel run (total 100)...\n",
      "Building estimator 3 of 6 for this parallel run (total 100)...\n",
      "Building estimator 3 of 6 for this parallel run (total 100)...\n",
      "Building estimator 3 of 7 for this parallel run (total 100)...\n",
      "Building estimator 3 of 6 for this parallel run (total 100)...\n",
      "Building estimator 3 of 7 for this parallel run (total 100)...\n",
      "Building estimator 3 of 6 for this parallel run (total 100)...\n",
      "Building estimator 3 of 6 for this parallel run (total 100)...\n",
      "Building estimator 3 of 6 for this parallel run (total 100)...\n",
      "Building estimator 3 of 6 for this parallel run (total 100)...\n",
      "Building estimator 3 of 7 for this parallel run (total 100)...\n",
      "Building estimator 3 of 6 for this parallel run (total 100)...\n",
      "Building estimator 3 of 6 for this parallel run (total 100)...\n",
      "Building estimator 3 of 6 for this parallel run (total 100)...\n",
      "Building estimator 3 of 6 for this parallel run (total 100)...\n",
      "Building estimator 3 of 7 for this parallel run (total 100)...\n",
      "Building estimator 3 of 6 for this parallel run (total 100)...\n",
      "Building estimator 4 of 6 for this parallel run (total 100)...\n",
      "Building estimator 4 of 6 for this parallel run (total 100)...\n",
      "Building estimator 4 of 7 for this parallel run (total 100)...\n",
      "Building estimator 4 of 6 for this parallel run (total 100)...\n",
      "Building estimator 4 of 6 for this parallel run (total 100)...\n",
      "Building estimator 4 of 6 for this parallel run (total 100)...\n",
      "Building estimator 4 of 7 for this parallel run (total 100)...\n",
      "Building estimator 4 of 6 for this parallel run (total 100)...\n",
      "Building estimator 4 of 6 for this parallel run (total 100)...\n",
      "Building estimator 4 of 6 for this parallel run (total 100)...\n",
      "Building estimator 4 of 6 for this parallel run (total 100)...\n",
      "Building estimator 4 of 6 for this parallel run (total 100)...\n",
      "Building estimator 4 of 6 for this parallel run (total 100)...\n",
      "Building estimator 4 of 6 for this parallel run (total 100)...\n",
      "Building estimator 4 of 7 for this parallel run (total 100)...\n",
      "Building estimator 4 of 7 for this parallel run (total 100)...\n",
      "Building estimator 5 of 6 for this parallel run (total 100)...\n",
      "Building estimator 5 of 6 for this parallel run (total 100)...\n",
      "Building estimator 5 of 6 for this parallel run (total 100)...\n",
      "Building estimator 5 of 6 for this parallel run (total 100)...\n",
      "Building estimator 5 of 7 for this parallel run (total 100)...\n",
      "Building estimator 5 of 6 for this parallel run (total 100)...\n",
      "Building estimator 5 of 6 for this parallel run (total 100)...\n",
      "Building estimator 5 of 6 for this parallel run (total 100)...\n",
      "Building estimator 5 of 7 for this parallel run (total 100)...\n",
      "Building estimator 5 of 6 for this parallel run (total 100)...\n",
      "Building estimator 5 of 6 for this parallel run (total 100)...\n",
      "Building estimator 5 of 6 for this parallel run (total 100)...\n",
      "Building estimator 5 of 6 for this parallel run (total 100)...\n",
      "Building estimator 5 of 7 for this parallel run (total 100)...\n",
      "Building estimator 5 of 7 for this parallel run (total 100)...\n",
      "Building estimator 5 of 6 for this parallel run (total 100)...\n",
      "Building estimator 6 of 6 for this parallel run (total 100)...\n",
      "Building estimator 6 of 6 for this parallel run (total 100)...\n",
      "Building estimator 6 of 6 for this parallel run (total 100)...\n",
      "Building estimator 6 of 7 for this parallel run (total 100)...\n",
      "Building estimator 6 of 6 for this parallel run (total 100)...\n",
      "Building estimator 6 of 6 for this parallel run (total 100)...\n",
      "Building estimator 6 of 6 for this parallel run (total 100)...\n",
      "Building estimator 6 of 6 for this parallel run (total 100)...\n",
      "Building estimator 6 of 6 for this parallel run (total 100)...\n",
      "Building estimator 6 of 7 for this parallel run (total 100)...\n",
      "Building estimator 6 of 6 for this parallel run (total 100)...\n",
      "Building estimator 6 of 6 for this parallel run (total 100)...\n",
      "Building estimator 6 of 6 for this parallel run (total 100)...\n",
      "Building estimator 6 of 7 for this parallel run (total 100)...\n",
      "Building estimator 6 of 7 for this parallel run (total 100)...\n",
      "Building estimator 6 of 6 for this parallel run (total 100)...\n",
      "Building estimator 7 of 7 for this parallel run (total 100)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Done   3 out of  16 | elapsed:  2.5min remaining: 11.0min\n",
      "[Parallel(n_jobs=16)]: Done   9 out of  16 | elapsed:  2.5min remaining:  2.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building estimator 7 of 7 for this parallel run (total 100)...\n",
      "Building estimator 7 of 7 for this parallel run (total 100)...\n",
      "Building estimator 7 of 7 for this parallel run (total 100)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:  2.8min finished\n",
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done   3 out of  16 | elapsed:    8.5s remaining:   36.9s\n",
      "[Parallel(n_jobs=16)]: Done   9 out of  16 | elapsed:    9.0s remaining:    7.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.888243831640058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:   10.0s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pickle\n",
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Initialize the Voting Classifier with the best models\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('xgb', xgb_clf), ('xgb2', xgb_clf2), ('rf', rf1), ('bag_xgb', bagging_clf)],\n",
    "    voting='soft',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "vot_clf = voting_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_vote = vot_clf.predict(X_val)\n",
    "f1_score_vote = f1_score(y_val, y_pred_vote)\n",
    "print(f1_score_vote)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building estimator 1 of 7 for this parallel run (total 100)...\n",
      "Building estimator 1 of 7 for this parallel run (total 100)...\n",
      "Building estimator 1 of 7 for this parallel run (total 100)...\n",
      "Building estimator 1 of 7 for this parallel run (total 100)...\n",
      "Building estimator 1 of 6 for this parallel run (total 100)...\n",
      "Building estimator 1 of 6 for this parallel run (total 100)...\n",
      "Building estimator 1 of 6 for this parallel run (total 100)...\n",
      "Building estimator 1 of 6 for this parallel run (total 100)...\n",
      "Building estimator 1 of 6 for this parallel run (total 100)...\n",
      "Building estimator 1 of 6 for this parallel run (total 100)...\n",
      "Building estimator 1 of 6 for this parallel run (total 100)...\n",
      "Building estimator 1 of 6 for this parallel run (total 100)...\n",
      "Building estimator 1 of 6 for this parallel run (total 100)...\n",
      "Building estimator 1 of 6 for this parallel run (total 100)...\n",
      "Building estimator 1 of 6 for this parallel run (total 100)...\n",
      "Building estimator 1 of 6 for this parallel run (total 100)...\n",
      "Building estimator 2 of 7 for this parallel run (total 100)...\n",
      "Building estimator 2 of 6 for this parallel run (total 100)...\n",
      "Building estimator 2 of 7 for this parallel run (total 100)...\n",
      "Building estimator 2 of 6 for this parallel run (total 100)...\n",
      "Building estimator 2 of 6 for this parallel run (total 100)...\n",
      "Building estimator 2 of 7 for this parallel run (total 100)...\n",
      "Building estimator 2 of 6 for this parallel run (total 100)...\n",
      "Building estimator 2 of 7 for this parallel run (total 100)...\n",
      "Building estimator 2 of 6 for this parallel run (total 100)...\n",
      "Building estimator 2 of 6 for this parallel run (total 100)...\n",
      "Building estimator 2 of 6 for this parallel run (total 100)...\n",
      "Building estimator 2 of 6 for this parallel run (total 100)...\n",
      "Building estimator 2 of 6 for this parallel run (total 100)...\n",
      "Building estimator 2 of 6 for this parallel run (total 100)...\n",
      "Building estimator 2 of 6 for this parallel run (total 100)...\n",
      "Building estimator 2 of 6 for this parallel run (total 100)...\n",
      "Building estimator 3 of 7 for this parallel run (total 100)...\n",
      "Building estimator 3 of 7 for this parallel run (total 100)...\n",
      "Building estimator 3 of 7 for this parallel run (total 100)...\n",
      "Building estimator 3 of 7 for this parallel run (total 100)...\n",
      "Building estimator 3 of 6 for this parallel run (total 100)...\n",
      "Building estimator 3 of 6 for this parallel run (total 100)...\n",
      "Building estimator 3 of 6 for this parallel run (total 100)...\n",
      "Building estimator 3 of 6 for this parallel run (total 100)...\n",
      "Building estimator 3 of 6 for this parallel run (total 100)...\n",
      "Building estimator 3 of 6 for this parallel run (total 100)...\n",
      "Building estimator 3 of 6 for this parallel run (total 100)...\n",
      "Building estimator 3 of 6 for this parallel run (total 100)...\n",
      "Building estimator 3 of 6 for this parallel run (total 100)...\n",
      "Building estimator 3 of 6 for this parallel run (total 100)...\n",
      "Building estimator 3 of 6 for this parallel run (total 100)...\n",
      "Building estimator 3 of 6 for this parallel run (total 100)...\n",
      "Building estimator 4 of 7 for this parallel run (total 100)...\n",
      "Building estimator 4 of 6 for this parallel run (total 100)...\n",
      "Building estimator 4 of 7 for this parallel run (total 100)...\n",
      "Building estimator 4 of 7 for this parallel run (total 100)...\n",
      "Building estimator 4 of 7 for this parallel run (total 100)...\n",
      "Building estimator 4 of 6 for this parallel run (total 100)...\n",
      "Building estimator 4 of 6 for this parallel run (total 100)...\n",
      "Building estimator 4 of 6 for this parallel run (total 100)...\n",
      "Building estimator 4 of 6 for this parallel run (total 100)...\n",
      "Building estimator 4 of 6 for this parallel run (total 100)...\n",
      "Building estimator 4 of 6 for this parallel run (total 100)...\n",
      "Building estimator 4 of 6 for this parallel run (total 100)...\n",
      "Building estimator 4 of 6 for this parallel run (total 100)...\n",
      "Building estimator 4 of 6 for this parallel run (total 100)...\n",
      "Building estimator 4 of 6 for this parallel run (total 100)...\n",
      "Building estimator 4 of 6 for this parallel run (total 100)...\n",
      "Building estimator 5 of 7 for this parallel run (total 100)...\n",
      "Building estimator 5 of 6 for this parallel run (total 100)...\n",
      "Building estimator 5 of 7 for this parallel run (total 100)...\n",
      "Building estimator 5 of 7 for this parallel run (total 100)...\n",
      "Building estimator 5 of 6 for this parallel run (total 100)...\n",
      "Building estimator 5 of 7 for this parallel run (total 100)...\n",
      "Building estimator 5 of 6 for this parallel run (total 100)...\n",
      "Building estimator 5 of 6 for this parallel run (total 100)...\n",
      "Building estimator 5 of 6 for this parallel run (total 100)...\n",
      "Building estimator 5 of 6 for this parallel run (total 100)...\n",
      "Building estimator 5 of 6 for this parallel run (total 100)...\n",
      "Building estimator 5 of 6 for this parallel run (total 100)...\n",
      "Building estimator 5 of 6 for this parallel run (total 100)...\n",
      "Building estimator 5 of 6 for this parallel run (total 100)...\n",
      "Building estimator 5 of 6 for this parallel run (total 100)...\n",
      "Building estimator 5 of 6 for this parallel run (total 100)...\n",
      "Building estimator 6 of 7 for this parallel run (total 100)...\n",
      "Building estimator 6 of 6 for this parallel run (total 100)...\n",
      "Building estimator 6 of 7 for this parallel run (total 100)...\n",
      "Building estimator 6 of 7 for this parallel run (total 100)...\n",
      "Building estimator 6 of 7 for this parallel run (total 100)...\n",
      "Building estimator 6 of 6 for this parallel run (total 100)...\n",
      "Building estimator 6 of 6 for this parallel run (total 100)...\n",
      "Building estimator 6 of 6 for this parallel run (total 100)...\n",
      "Building estimator 6 of 6 for this parallel run (total 100)...\n",
      "Building estimator 6 of 6 for this parallel run (total 100)...\n",
      "Building estimator 6 of 6 for this parallel run (total 100)...\n",
      "Building estimator 6 of 6 for this parallel run (total 100)...\n",
      "Building estimator 6 of 6 for this parallel run (total 100)...\n",
      "Building estimator 6 of 6 for this parallel run (total 100)...\n",
      "Building estimator 6 of 6 for this parallel run (total 100)...\n",
      "Building estimator 6 of 6 for this parallel run (total 100)...\n",
      "Building estimator 7 of 7 for this parallel run (total 100)...\n",
      "Building estimator 7 of 7 for this parallel run (total 100)...\n",
      "Building estimator 7 of 7 for this parallel run (total 100)...\n",
      "Building estimator 7 of 7 for this parallel run (total 100)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Done   3 out of  16 | elapsed:  3.2min remaining: 13.8min\n",
      "[Parallel(n_jobs=16)]: Done   9 out of  16 | elapsed:  3.2min remaining:  2.5min\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:  3.5min finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pickle\n",
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('xgb', xgb_clf), ('xgb2', xgb_clf2), ('rf', rf1), ('bag_xgb', bagging_clf)],\n",
    "    voting='soft',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Train the ensemble model with the full training dataset\n",
    "vot_clf = voting_clf.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building estimator 1 of 7 for this parallel run (total 100)...\n",
      "Building estimator 1 of 7 for this parallel run (total 100)...\n",
      "Building estimator 1 of 7 for this parallel run (total 100)...Building estimator 1 of 7 for this parallel run (total 100)...\n",
      "Building estimator 1 of 6 for this parallel run (total 100)...\n",
      "Building estimator 1 of 6 for this parallel run (total 100)...\n",
      "Building estimator 1 of 6 for this parallel run (total 100)...\n",
      "\n",
      "Building estimator 1 of 6 for this parallel run (total 100)...\n",
      "Building estimator 1 of 6 for this parallel run (total 100)...\n",
      "Building estimator 1 of 6 for this parallel run (total 100)...\n",
      "Building estimator 1 of 6 for this parallel run (total 100)...\n",
      "Building estimator 1 of 6 for this parallel run (total 100)...\n",
      "Building estimator 1 of 6 for this parallel run (total 100)...\n",
      "Building estimator 1 of 6 for this parallel run (total 100)...\n",
      "Building estimator 1 of 6 for this parallel run (total 100)...\n",
      "Building estimator 1 of 6 for this parallel run (total 100)...\n",
      "Building estimator 2 of 6 for this parallel run (total 100)...\n",
      "Building estimator 2 of 6 for this parallel run (total 100)...\n",
      "Building estimator 2 of 6 for this parallel run (total 100)...\n",
      "Building estimator 2 of 6 for this parallel run (total 100)...\n",
      "Building estimator 2 of 7 for this parallel run (total 100)...\n",
      "Building estimator 2 of 6 for this parallel run (total 100)...\n",
      "Building estimator 2 of 6 for this parallel run (total 100)...\n",
      "Building estimator 2 of 6 for this parallel run (total 100)...\n",
      "Building estimator 2 of 6 for this parallel run (total 100)...\n",
      "Building estimator 2 of 6 for this parallel run (total 100)...\n",
      "Building estimator 2 of 7 for this parallel run (total 100)...\n",
      "Building estimator 2 of 6 for this parallel run (total 100)...\n",
      "Building estimator 2 of 7 for this parallel run (total 100)...\n",
      "Building estimator 2 of 6 for this parallel run (total 100)...\n",
      "Building estimator 2 of 7 for this parallel run (total 100)...\n",
      "Building estimator 2 of 6 for this parallel run (total 100)...\n",
      "Building estimator 3 of 7 for this parallel run (total 100)...\n",
      "Building estimator 3 of 6 for this parallel run (total 100)...\n",
      "Building estimator 3 of 6 for this parallel run (total 100)...\n",
      "Building estimator 3 of 6 for this parallel run (total 100)...\n",
      "Building estimator 3 of 6 for this parallel run (total 100)...\n",
      "Building estimator 3 of 6 for this parallel run (total 100)...\n",
      "Building estimator 3 of 6 for this parallel run (total 100)...\n",
      "Building estimator 3 of 6 for this parallel run (total 100)...\n",
      "Building estimator 3 of 6 for this parallel run (total 100)...\n",
      "Building estimator 3 of 6 for this parallel run (total 100)...\n",
      "Building estimator 3 of 6 for this parallel run (total 100)...\n",
      "Building estimator 3 of 7 for this parallel run (total 100)...\n",
      "Building estimator 3 of 7 for this parallel run (total 100)...\n",
      "Building estimator 3 of 6 for this parallel run (total 100)...\n",
      "Building estimator 3 of 7 for this parallel run (total 100)...\n",
      "Building estimator 3 of 6 for this parallel run (total 100)...\n",
      "Building estimator 4 of 7 for this parallel run (total 100)...\n",
      "Building estimator 4 of 6 for this parallel run (total 100)...\n",
      "Building estimator 4 of 6 for this parallel run (total 100)...\n",
      "Building estimator 4 of 6 for this parallel run (total 100)...\n",
      "Building estimator 4 of 6 for this parallel run (total 100)...\n",
      "Building estimator 4 of 6 for this parallel run (total 100)...\n",
      "Building estimator 4 of 6 for this parallel run (total 100)...\n",
      "Building estimator 4 of 6 for this parallel run (total 100)...\n",
      "Building estimator 4 of 6 for this parallel run (total 100)...\n",
      "Building estimator 4 of 6 for this parallel run (total 100)...\n",
      "Building estimator 4 of 7 for this parallel run (total 100)...\n",
      "Building estimator 4 of 6 for this parallel run (total 100)...\n",
      "Building estimator 4 of 6 for this parallel run (total 100)...\n",
      "Building estimator 4 of 7 for this parallel run (total 100)...\n",
      "Building estimator 4 of 7 for this parallel run (total 100)...\n",
      "Building estimator 4 of 6 for this parallel run (total 100)...\n",
      "Building estimator 5 of 6 for this parallel run (total 100)...\n",
      "Building estimator 5 of 7 for this parallel run (total 100)...\n",
      "Building estimator 5 of 6 for this parallel run (total 100)...\n",
      "Building estimator 5 of 6 for this parallel run (total 100)...\n",
      "Building estimator 5 of 6 for this parallel run (total 100)...\n",
      "Building estimator 5 of 6 for this parallel run (total 100)...\n",
      "Building estimator 5 of 6 for this parallel run (total 100)...\n",
      "Building estimator 5 of 6 for this parallel run (total 100)...\n",
      "Building estimator 5 of 6 for this parallel run (total 100)...\n",
      "Building estimator 5 of 6 for this parallel run (total 100)...\n",
      "Building estimator 5 of 7 for this parallel run (total 100)...\n",
      "Building estimator 5 of 6 for this parallel run (total 100)...\n",
      "Building estimator 5 of 6 for this parallel run (total 100)...\n",
      "Building estimator 5 of 7 for this parallel run (total 100)...\n",
      "Building estimator 5 of 7 for this parallel run (total 100)...\n",
      "Building estimator 5 of 6 for this parallel run (total 100)...\n",
      "Building estimator 6 of 6 for this parallel run (total 100)...\n",
      "Building estimator 6 of 6 for this parallel run (total 100)...\n",
      "Building estimator 6 of 7 for this parallel run (total 100)...\n",
      "Building estimator 6 of 6 for this parallel run (total 100)...\n",
      "Building estimator 6 of 6 for this parallel run (total 100)...\n",
      "Building estimator 6 of 6 for this parallel run (total 100)...\n",
      "Building estimator 6 of 6 for this parallel run (total 100)...\n",
      "Building estimator 6 of 6 for this parallel run (total 100)...\n",
      "Building estimator 6 of 6 for this parallel run (total 100)...\n",
      "Building estimator 6 of 6 for this parallel run (total 100)...\n",
      "Building estimator 6 of 7 for this parallel run (total 100)...\n",
      "Building estimator 6 of 6 for this parallel run (total 100)...\n",
      "Building estimator 6 of 6 for this parallel run (total 100)...\n",
      "Building estimator 6 of 7 for this parallel run (total 100)...\n",
      "Building estimator 6 of 7 for this parallel run (total 100)...\n",
      "Building estimator 6 of 6 for this parallel run (total 100)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Done   3 out of  16 | elapsed:  2.2min remaining:  9.6min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building estimator 7 of 7 for this parallel run (total 100)...\n",
      "Building estimator 7 of 7 for this parallel run (total 100)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Done   9 out of  16 | elapsed:  2.3min remaining:  1.8min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building estimator 7 of 7 for this parallel run (total 100)...\n",
      "Building estimator 7 of 7 for this parallel run (total 100)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:  2.5min finished\n",
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done   3 out of  16 | elapsed:    9.6s remaining:   41.8s\n",
      "[Parallel(n_jobs=16)]: Done   9 out of  16 | elapsed:   10.0s remaining:    7.8s\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:   11.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8988439306358381\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pickle\n",
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Initialize the Voting Classifier with fewer models\n",
    "voting_clf2 = VotingClassifier(\n",
    "    estimators=[('xgb', xgb_clf), ('bag', bagging_clf), ('xgb2', xgb_clf2)],\n",
    "    voting='soft',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "vot_clf2 = voting_clf2.fit(X_train, y_train)\n",
    "\n",
    "y_pred_vote2 = vot_clf2.predict(X_val)\n",
    "f1_score_vote2 = f1_score(y_val, y_pred_vote2)\n",
    "print(f1_score_vote2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building estimator 1 of 7 for this parallel run (total 100)...\n",
      "Building estimator 1 of 7 for this parallel run (total 100)...\n",
      "Building estimator 1 of 7 for this parallel run (total 100)...\n",
      "Building estimator 1 of 7 for this parallel run (total 100)...\n",
      "Building estimator 1 of 6 for this parallel run (total 100)...\n",
      "Building estimator 1 of 6 for this parallel run (total 100)...\n",
      "Building estimator 1 of 6 for this parallel run (total 100)...\n",
      "Building estimator 1 of 6 for this parallel run (total 100)...\n",
      "Building estimator 1 of 6 for this parallel run (total 100)...\n",
      "Building estimator 1 of 6 for this parallel run (total 100)...\n",
      "Building estimator 1 of 6 for this parallel run (total 100)...\n",
      "Building estimator 1 of 6 for this parallel run (total 100)...\n",
      "Building estimator 1 of 6 for this parallel run (total 100)...\n",
      "Building estimator 1 of 6 for this parallel run (total 100)...\n",
      "Building estimator 1 of 6 for this parallel run (total 100)...\n",
      "Building estimator 1 of 6 for this parallel run (total 100)...\n",
      "Building estimator 2 of 7 for this parallel run (total 100)...\n",
      "Building estimator 2 of 6 for this parallel run (total 100)...\n",
      "Building estimator 2 of 6 for this parallel run (total 100)...\n",
      "Building estimator 2 of 7 for this parallel run (total 100)...\n",
      "Building estimator 2 of 6 for this parallel run (total 100)...\n",
      "Building estimator 2 of 7 for this parallel run (total 100)...\n",
      "Building estimator 2 of 6 for this parallel run (total 100)...\n",
      "Building estimator 2 of 6 for this parallel run (total 100)...\n",
      "Building estimator 2 of 6 for this parallel run (total 100)...\n",
      "Building estimator 2 of 6 for this parallel run (total 100)...\n",
      "Building estimator 2 of 6 for this parallel run (total 100)...\n",
      "Building estimator 2 of 6 for this parallel run (total 100)...\n",
      "Building estimator 2 of 6 for this parallel run (total 100)...\n",
      "Building estimator 2 of 6 for this parallel run (total 100)...\n",
      "Building estimator 2 of 7 for this parallel run (total 100)...\n",
      "Building estimator 2 of 6 for this parallel run (total 100)...\n",
      "Building estimator 3 of 7 for this parallel run (total 100)...\n",
      "Building estimator 3 of 6 for this parallel run (total 100)...\n",
      "Building estimator 3 of 6 for this parallel run (total 100)...\n",
      "Building estimator 3 of 6 for this parallel run (total 100)...\n",
      "Building estimator 3 of 7 for this parallel run (total 100)...\n",
      "Building estimator 3 of 6 for this parallel run (total 100)...\n",
      "Building estimator 3 of 6 for this parallel run (total 100)...\n",
      "Building estimator 3 of 6 for this parallel run (total 100)...\n",
      "Building estimator 3 of 6 for this parallel run (total 100)...\n",
      "Building estimator 3 of 6 for this parallel run (total 100)...\n",
      "Building estimator 3 of 6 for this parallel run (total 100)...\n",
      "Building estimator 3 of 7 for this parallel run (total 100)...\n",
      "Building estimator 3 of 6 for this parallel run (total 100)...\n",
      "Building estimator 3 of 6 for this parallel run (total 100)...\n",
      "Building estimator 3 of 7 for this parallel run (total 100)...\n",
      "Building estimator 3 of 6 for this parallel run (total 100)...\n",
      "Building estimator 4 of 6 for this parallel run (total 100)...\n",
      "Building estimator 4 of 7 for this parallel run (total 100)...\n",
      "Building estimator 4 of 6 for this parallel run (total 100)...\n",
      "Building estimator 4 of 6 for this parallel run (total 100)...\n",
      "Building estimator 4 of 7 for this parallel run (total 100)...\n",
      "Building estimator 4 of 6 for this parallel run (total 100)...\n",
      "Building estimator 4 of 6 for this parallel run (total 100)...\n",
      "Building estimator 4 of 7 for this parallel run (total 100)...\n",
      "Building estimator 4 of 6 for this parallel run (total 100)...\n",
      "Building estimator 4 of 6 for this parallel run (total 100)...\n",
      "Building estimator 4 of 6 for this parallel run (total 100)...\n",
      "Building estimator 4 of 6 for this parallel run (total 100)...\n",
      "Building estimator 4 of 6 for this parallel run (total 100)...\n",
      "Building estimator 4 of 6 for this parallel run (total 100)...\n",
      "Building estimator 4 of 7 for this parallel run (total 100)...\n",
      "Building estimator 4 of 6 for this parallel run (total 100)...\n",
      "Building estimator 5 of 6 for this parallel run (total 100)...\n",
      "Building estimator 5 of 7 for this parallel run (total 100)...\n",
      "Building estimator 5 of 6 for this parallel run (total 100)...\n",
      "Building estimator 5 of 7 for this parallel run (total 100)...\n",
      "Building estimator 5 of 6 for this parallel run (total 100)...\n",
      "Building estimator 5 of 6 for this parallel run (total 100)...\n",
      "Building estimator 5 of 6 for this parallel run (total 100)...\n",
      "Building estimator 5 of 6 for this parallel run (total 100)...\n",
      "Building estimator 5 of 6 for this parallel run (total 100)...\n",
      "Building estimator 5 of 6 for this parallel run (total 100)...\n",
      "Building estimator 5 of 6 for this parallel run (total 100)...\n",
      "Building estimator 5 of 6 for this parallel run (total 100)...\n",
      "Building estimator 5 of 7 for this parallel run (total 100)...\n",
      "Building estimator 5 of 6 for this parallel run (total 100)...\n",
      "Building estimator 5 of 7 for this parallel run (total 100)...\n",
      "Building estimator 5 of 6 for this parallel run (total 100)...\n",
      "Building estimator 6 of 6 for this parallel run (total 100)...\n",
      "Building estimator 6 of 7 for this parallel run (total 100)...\n",
      "Building estimator 6 of 6 for this parallel run (total 100)...\n",
      "Building estimator 6 of 7 for this parallel run (total 100)...\n",
      "Building estimator 6 of 6 for this parallel run (total 100)...\n",
      "Building estimator 6 of 6 for this parallel run (total 100)...\n",
      "Building estimator 6 of 6 for this parallel run (total 100)...\n",
      "Building estimator 6 of 6 for this parallel run (total 100)...\n",
      "Building estimator 6 of 6 for this parallel run (total 100)...\n",
      "Building estimator 6 of 6 for this parallel run (total 100)...\n",
      "Building estimator 6 of 6 for this parallel run (total 100)...\n",
      "Building estimator 6 of 7 for this parallel run (total 100)...\n",
      "Building estimator 6 of 6 for this parallel run (total 100)...\n",
      "Building estimator 6 of 6 for this parallel run (total 100)...\n",
      "Building estimator 6 of 7 for this parallel run (total 100)...\n",
      "Building estimator 6 of 6 for this parallel run (total 100)...\n",
      "Building estimator 7 of 7 for this parallel run (total 100)...\n",
      "Building estimator 7 of 7 for this parallel run (total 100)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Done   3 out of  16 | elapsed:  2.9min remaining: 12.6min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building estimator 7 of 7 for this parallel run (total 100)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Done   9 out of  16 | elapsed:  2.9min remaining:  2.3min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building estimator 7 of 7 for this parallel run (total 100)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:  3.3min finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pickle\n",
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "voting_clf2 = VotingClassifier(\n",
    "    estimators=[('xgb', xgb_clf), ('bag', bagging_clf), ('xgb2', xgb_clf2)],\n",
    "    voting='soft',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Train the second ensemble model with the full training dataset\n",
    "vot_clf2 = voting_clf2.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done   3 out of  16 | elapsed:    7.0s remaining:   30.4s\n",
      "[Parallel(n_jobs=16)]: Done   9 out of  16 | elapsed:    7.1s remaining:    5.6s\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:    7.5s finished\n"
     ]
    }
   ],
   "source": [
    "# Create Kaggle Submission 1\n",
    "pred = test_df.drop(['is_fraud', 'city_pop_cluster', 'Id'], axis=1)\n",
    "pred2 = test_df.drop(['is_fraud'], axis=1)\n",
    "\n",
    "pred2['is_fraud'] = vot_clf.predict(pred)\n",
    "pred2.is_fraud = pred2.is_fraud.astype(int)\n",
    "submission = pred2[['Id', 'is_fraud']]\n",
    "submission.to_csv(\"./data/competition_submission_final.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done   3 out of  16 | elapsed:    8.4s remaining:   36.4s\n",
      "[Parallel(n_jobs=16)]: Done   9 out of  16 | elapsed:    8.7s remaining:    6.8s\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:    9.2s finished\n"
     ]
    }
   ],
   "source": [
    "# Create Kaggle Submission 2\n",
    "pred3 = test_df.drop(['is_fraud'], axis=1)\n",
    "\n",
    "pred3['is_fraud'] = vot_clf2.predict(pred)\n",
    "pred3.is_fraud = pred3.is_fraud.astype(int)\n",
    "submission2 = pred3[['Id', 'is_fraud']]\n",
    "submission2.to_csv(\"./data/competition_submission_final2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the two ensemble models\n",
    "with open('competitioin_model_final.obj', 'wb') as f:\n",
    "    pickle.dump(vot_clf, f)\n",
    "\n",
    "with open('competitioin_model_final2.obj', 'wb') as f:\n",
    "    pickle.dump(vot_clf2, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done   3 out of  16 | elapsed:    5.7s remaining:   24.7s\n",
      "[Parallel(n_jobs=16)]: Done   9 out of  16 | elapsed:    6.0s remaining:    4.6s\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:    6.5s finished\n"
     ]
    }
   ],
   "source": [
    "# Create Kaggle Submission 3 with only the Bagging Classifier\n",
    "pred4 = test_df.drop(['is_fraud'], axis=1)\n",
    "\n",
    "pred4['is_fraud'] = bagging_clf.predict(pred)\n",
    "pred4.is_fraud = pred4.is_fraud.astype(int)\n",
    "submission2 = pred4[['Id', 'is_fraud']]\n",
    "submission2.to_csv(\"./data/competition_submission_final3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Employing Stratified K-Fold Cross-Validation for the Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "f1scores = []  # To store the F1 scores from each fold\n",
    "\n",
    "# Perform cross-validation\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # Fit the model on the training data\n",
    "    vot_clf.fit(X_train, y_train)\n",
    "    # Make predictions on the test set\n",
    "    y_pred = vot_clf.predict(X_test)\n",
    "    # Calculate and store the F1 score\n",
    "    score = f1_score(y_test, y_pred)\n",
    "    f1scores.append(score)\n",
    "\n",
    "# Compute the average F1 score across all folds\n",
    "average_f1 = np.mean(f1scores)\n",
    "print(f\"Average F1 Score across all folds: {average_f1}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
