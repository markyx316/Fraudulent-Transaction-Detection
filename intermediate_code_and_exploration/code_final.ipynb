{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from geopy.distance import geodesic\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Calculate distance from home function\n",
    "def calculate_distance(row):\n",
    "    home_location = (row['lat'], row['long'])\n",
    "    merch_location = (row['merch_lat'], row['merch_long'])\n",
    "    return geodesic(home_location, merch_location).miles\n",
    "\n",
    "# Function to calculate distance between two points\n",
    "def calculate_distance2(row1, row2):\n",
    "    point1 = (row1['lat'], row1['long'])\n",
    "    point2 = (row2['lat'], row2['long'])\n",
    "    return geodesic(point1, point2).miles\n",
    "\n",
    "def calculate_similarity_score(amount, fraud_mean, fraud_std, normal_mean, normal_std):\n",
    "    # Calculate Z-scores for fraud and normal\n",
    "    z_score_fraud = abs((amount - fraud_mean) / fraud_std)\n",
    "    z_score_normal = abs((amount - normal_mean) / normal_std)\n",
    "    \n",
    "    # Invert the Z-scores to get similarity scores\n",
    "    fraud_similarity = 1 / (1 + z_score_fraud)\n",
    "    normal_similarity = 1 / (1 + z_score_normal)\n",
    "    \n",
    "    return fraud_similarity, normal_similarity\n",
    "\n",
    "def process(df):\n",
    "    # Add new features\n",
    "    # Rearrange the rows\n",
    "    df['original_order'] = range(df.shape[0])\n",
    "\n",
    "    df['trans_date_trans_time'] = pd.to_datetime(df['trans_date_trans_time'], format='%d/%m/%Y %H:%M')\n",
    "    df['dob'] = pd.to_datetime(df['dob'], format='%d/%m/%Y')\n",
    "\n",
    "    df.sort_values(by=['cc_num', 'trans_date_trans_time'], inplace=True)\n",
    "    \n",
    "    # Calculate the time difference between transactions\n",
    "    df['Time_Delta'] = df.groupby('cc_num')['trans_date_trans_time'].diff().dt.total_seconds() / 60.0  # Time delta in minutes\n",
    "    df['Time_Delta'] = df['Time_Delta'].fillna(value=0)\n",
    "    \n",
    "    # Shift the latitude and longitude to get the previous transaction's location\n",
    "    df['prev_lat'] = df.groupby('cc_num')['merch_lat'].shift(1)\n",
    "    df['prev_long'] = df.groupby('cc_num')['merch_long'].shift(1)\n",
    "\n",
    "    # Calculate the distance to the previous transaction\n",
    "    df['distance_to_prev'] = df.apply(\n",
    "        lambda row: calculate_distance2(\n",
    "            {'lat': row['merch_lat'], 'long': row['merch_long']},\n",
    "            {'lat': row['prev_lat'], 'long': row['prev_long']}\n",
    "        ) if not pd.isnull(row['prev_lat']) else None,\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    df['distance_to_prev'] = df['distance_to_prev'].fillna(value=0)\n",
    "\n",
    "    # Calculate location consistency as the inverse of the average distance to previous transactions (higher value means more consistency)\n",
    "    df['location_consistency'] = 100 / df.groupby('cc_num')['distance_to_prev'].transform('mean')\n",
    "\n",
    "    # Time-based features\n",
    "    df['hour'] = df['trans_date_trans_time'].dt.hour\n",
    "    df['day_of_week'] = df['trans_date_trans_time'].dt.dayofweek\n",
    "   \n",
    "    # Age of the account holder\n",
    "    df['age'] = (df['trans_date_trans_time'] - df['dob']).dt.days // 365\n",
    "\n",
    "    df['dist_to_home'] = df.apply(calculate_distance, axis=1)\n",
    "\n",
    "    # Group by category and calculate the mean and standard deviation of transaction amounts\n",
    "    category_stats = df.groupby('category')['amt'].agg(['mean', 'std']).reset_index()\n",
    "    # Merge these stats back into the main dataframe\n",
    "    df = df.merge(category_stats, on='category', how='left')\n",
    "    # Calculate z-score for each transaction amount within its category\n",
    "    df['amt_anomaly_score_cat'] = ((df['amt'] - df['mean']) / df['std'])\n",
    "    df.drop(columns=['mean', 'std'], inplace=True)\n",
    "    # Group by merchant and calculate the mean and standard deviation of transaction amounts\n",
    "    merchant_stats = df.groupby('merchant')['amt'].agg(['mean', 'std']).reset_index()\n",
    "    # Merge these stats back into the main dataframe\n",
    "    df = df.merge(merchant_stats, on='merchant', how='left')\n",
    "    # Calculate z-score for each transaction amount within its merchant\n",
    "    df['amt_anomaly_score_merch'] = ((df['amt'] - df['mean']) / df['std'])\n",
    "    df.drop(columns=['mean', 'std'], inplace=True)\n",
    "\n",
    "    # Calculate the historical average transaction amount for each user\n",
    "    avg_amt_per_user = df.groupby('cc_num')['amt'].transform('mean').rename('avg_amt_per_user')\n",
    "\n",
    "    # Append this feature to the dataset\n",
    "    df['amt_relative_avg'] = (abs(df['amt'] - avg_amt_per_user) / avg_amt_per_user)\n",
    "\n",
    "    kmeans = KMeans(n_clusters=12, random_state=42)\n",
    "\n",
    "    # Create a new column for the cluster labels\n",
    "    df['city_pop_cluster'] = kmeans.fit_predict(df[['city_pop']])\n",
    "\n",
    "    df.drop(columns=['trans_date_trans_time', 'lat', 'long', 'merch_lat', 'merch_long'], inplace=True)\n",
    "    df.drop(columns=['prev_lat', 'prev_long', 'cc_num'], inplace=True)\n",
    "\n",
    "    # Identify categorical columns to encode\n",
    "    categorical_cols = ['merchant', 'category', 'gender', 'city', 'state', 'job']\n",
    "\n",
    "    mappings = {}\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    for col in categorical_cols:\n",
    "        df[col] = label_encoder.fit_transform(df[col])\n",
    "        mappings[col] = {label: index for index, label in enumerate(label_encoder.classes_)}\n",
    "\n",
    "\n",
    "    # Calculate the fraud rate by category\n",
    "    fraud_rate_by_category = df.groupby('category')['is_fraud'].mean().reset_index()\n",
    "    fraud_rate_by_category.rename(columns={'is_fraud': 'fraud_rate_cat'}, inplace=True)\n",
    "\n",
    "    # Merge the fraud rate back into the main DataFrame\n",
    "    df = pd.merge(df, fraud_rate_by_category[['category', 'fraud_rate_cat']], on='category', how='left')\n",
    "\n",
    "    # Calculate the fraud rate by merchant\n",
    "    fraud_rate_by_merchant = df.groupby('merchant')['is_fraud'].mean().reset_index()\n",
    "    fraud_rate_by_merchant.rename(columns={'is_fraud': 'fraud_rate_merch'}, inplace=True)\n",
    "\n",
    "    # Merge the fraud rate back into the main DataFrame\n",
    "    df = pd.merge(df, fraud_rate_by_merchant[['merchant', 'fraud_rate_merch']], on='merchant', how='left')\n",
    "\n",
    "    # Separate the transactions\n",
    "    fraud_trans = df[df['is_fraud'] == 1]['amt']\n",
    "    normal_trans = df[df['is_fraud'] == 0]['amt']\n",
    "\n",
    "    # Calculate statistics\n",
    "    fraud_mean, fraud_std = fraud_trans.mean(), fraud_trans.std()\n",
    "    normal_mean, normal_std = normal_trans.mean(), normal_trans.std()\n",
    "\n",
    "    v_calculate_similarity_score = np.vectorize(calculate_similarity_score)\n",
    "\n",
    "    # Apply the function\n",
    "    df['fraud_similarity'], df['normal_similarity'] = v_calculate_similarity_score(\n",
    "        df['amt'],\n",
    "        fraud_mean, fraud_std,\n",
    "        normal_mean, normal_std\n",
    "    )\n",
    "\n",
    "    # Sort the dataset back to its original order\n",
    "    df.sort_values(by='original_order', inplace=True)\n",
    "    df.drop(columns='original_order', inplace=True)\n",
    "\n",
    "    return df, mappings\n",
    "\n",
    "trainingSet = pd.read_csv(\"./data/train.csv\")\n",
    "submissionSet = pd.read_csv(\"./data/test.csv\")\n",
    "train_processed, cat_map = process(trainingSet)\n",
    "train_processed.drop(columns=['first', 'last', 'street', 'dob', 'zip', 'trans_num', 'unix_time'], inplace=True)\n",
    "\n",
    "# Merge on Id so that the test set can have feature columns as well\n",
    "test_df = pd.merge(train_processed, submissionSet, left_on='Id', right_on='Id')\n",
    "test_df = test_df.drop(columns=['is_fraud_x'])\n",
    "test_df = test_df.rename(columns={'is_fraud_y': 'is_fraud'})\n",
    "\n",
    "# The training set is where the score is not null\n",
    "train_df = train_processed[train_processed['is_fraud'].notnull()]\n",
    "\n",
    "# Save the datasets with the new features for easy access later\n",
    "test_df.to_csv(\"./data/processed_test.csv\", index=False)\n",
    "train_df.to_csv(\"./data/processed_train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Assuming 'train_df' includes both features and the target ('is_fraud')\n",
    "X = train_df.drop(['is_fraud', 'Id', 'city_pop_cluster'], axis=1)\n",
    "y = train_df['is_fraud']\n",
    "\n",
    "num_cols = ['amt', 'Time_Delta', 'distance_to_prev', 'location_consistency', 'dist_to_home', 'amt_anomaly_score_cat', 'amt_anomaly_score_merch', 'amt_relative_avg', 'fraud_rate_cat', 'fraud_rate_merch', 'fraud_similarity', 'normal_similarity']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X[num_cols] = scaler.fit_transform(X[num_cols])\n",
    "test_df[num_cols] = scaler.transform(test_df[num_cols])\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 240 candidates, totalling 1200 fits\n",
      "[CV 3/5] END colsample_bytree=0.1, learning_rate=0.1, max_depth=3, n_estimators=300;, score=0.772 total time=   4.3s\n",
      "[CV 2/5] END colsample_bytree=0.1, learning_rate=0.1, max_depth=3, n_estimators=300;, score=0.784 total time=   4.4s\n",
      "[CV 4/5] END colsample_bytree=0.1, learning_rate=0.1, max_depth=3, n_estimators=300;, score=0.793 total time=   4.4s\n",
      "[CV 5/5] END colsample_bytree=0.1, learning_rate=0.1, max_depth=3, n_estimators=300;, score=0.774 total time=   4.4s\n",
      "[CV 1/5] END colsample_bytree=0.1, learning_rate=0.1, max_depth=3, n_estimators=300;, score=0.751 total time=   4.6s\n",
      "[CV 1/5] END colsample_bytree=0.1, learning_rate=0.1, max_depth=3, n_estimators=500;, score=0.783 total time=   6.8s\n",
      "[CV 5/5] END colsample_bytree=0.1, learning_rate=0.1, max_depth=3, n_estimators=500;, score=0.802 total time=   6.8s\n",
      "[CV 3/5] END colsample_bytree=0.1, learning_rate=0.1, max_depth=3, n_estimators=500;, score=0.780 total time=   6.8s\n",
      "[CV 4/5] END colsample_bytree=0.1, learning_rate=0.1, max_depth=3, n_estimators=500;, score=0.810 total time=   6.8s\n",
      "[CV 2/5] END colsample_bytree=0.1, learning_rate=0.1, max_depth=3, n_estimators=500;, score=0.805 total time=   6.8s\n",
      "[CV 3/5] END colsample_bytree=0.1, learning_rate=0.1, max_depth=5, n_estimators=300;, score=0.787 total time=   6.0s\n",
      "[CV 1/5] END colsample_bytree=0.1, learning_rate=0.1, max_depth=5, n_estimators=300;, score=0.792 total time=   6.1s\n",
      "[CV 4/5] END colsample_bytree=0.1, learning_rate=0.1, max_depth=5, n_estimators=300;, score=0.825 total time=   6.0s\n",
      "[CV 2/5] END colsample_bytree=0.1, learning_rate=0.1, max_depth=5, n_estimators=300;, score=0.813 total time=   6.1s\n",
      "[CV 5/5] END colsample_bytree=0.1, learning_rate=0.1, max_depth=5, n_estimators=300;, score=0.808 total time=   6.0s\n",
      "[CV 3/5] END colsample_bytree=0.1, learning_rate=0.1, max_depth=3, n_estimators=900;, score=0.790 total time=  11.9s\n",
      "[CV 2/5] END colsample_bytree=0.1, learning_rate=0.1, max_depth=3, n_estimators=900;, score=0.831 total time=  12.2s\n",
      "[CV 4/5] END colsample_bytree=0.1, learning_rate=0.1, max_depth=3, n_estimators=900;, score=0.827 total time=  12.1s\n",
      "[CV 1/5] END colsample_bytree=0.1, learning_rate=0.1, max_depth=3, n_estimators=900;, score=0.810 total time=  12.3s\n",
      "[CV 5/5] END colsample_bytree=0.1, learning_rate=0.1, max_depth=3, n_estimators=900;, score=0.834 total time=  12.1s\n",
      "[CV 2/5] END colsample_bytree=0.1, learning_rate=0.1, max_depth=5, n_estimators=500;, score=0.836 total time=   9.3s\n",
      "[CV 4/5] END colsample_bytree=0.1, learning_rate=0.1, max_depth=5, n_estimators=500;, score=0.838 total time=   9.3s\n",
      "[CV 1/5] END colsample_bytree=0.1, learning_rate=0.1, max_depth=5, n_estimators=500;, score=0.828 total time=   9.5s\n",
      "[CV 3/5] END colsample_bytree=0.1, learning_rate=0.1, max_depth=5, n_estimators=500;, score=0.806 total time=   9.4s\n",
      "[CV 5/5] END colsample_bytree=0.1, learning_rate=0.1, max_depth=5, n_estimators=500;, score=0.828 total time=   9.5s\n",
      "[CV 1/5] END colsample_bytree=0.1, learning_rate=0.1, max_depth=7, n_estimators=300;, score=0.809 total time=   7.7s\n",
      "[CV 3/5] END colsample_bytree=0.1, learning_rate=0.1, max_depth=7, n_estimators=300;, score=0.797 total time=   7.8s\n",
      "[CV 2/5] END colsample_bytree=0.1, learning_rate=0.1, max_depth=7, n_estimators=300;, score=0.824 total time=   7.8s\n",
      "[CV 4/5] END colsample_bytree=0.1, learning_rate=0.1, max_depth=7, n_estimators=300;, score=0.828 total time=   7.7s\n",
      "[CV 5/5] END colsample_bytree=0.1, learning_rate=0.1, max_depth=7, n_estimators=300;, score=0.823 total time=   8.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END colsample_bytree=0.1, learning_rate=0.1, max_depth=5, n_estimators=900;, score=0.835 total time=  16.4s\n",
      "[CV 2/5] END colsample_bytree=0.1, learning_rate=0.1, max_depth=5, n_estimators=900;, score=0.849 total time=  16.5s\n",
      "[CV 4/5] END colsample_bytree=0.1, learning_rate=0.1, max_depth=5, n_estimators=900;, score=0.846 total time=  16.6s\n",
      "[CV 5/5] END colsample_bytree=0.1, learning_rate=0.1, max_depth=5, n_estimators=900;, score=0.846 total time=  16.7s\n",
      "[CV 3/5] END colsample_bytree=0.1, learning_rate=0.1, max_depth=5, n_estimators=900;, score=0.825 total time=  16.8s\n",
      "[CV 1/5] END colsample_bytree=0.1, learning_rate=0.1, max_depth=7, n_estimators=500;, score=0.822 total time=  12.4s\n",
      "[CV 2/5] END colsample_bytree=0.1, learning_rate=0.1, max_depth=7, n_estimators=500;, score=0.834 total time=  12.2s\n",
      "[CV 3/5] END colsample_bytree=0.1, learning_rate=0.1, max_depth=7, n_estimators=500;, score=0.800 total time=  12.3s\n",
      "[CV 4/5] END colsample_bytree=0.1, learning_rate=0.1, max_depth=7, n_estimators=500;, score=0.849 total time=  12.4s\n",
      "[CV 5/5] END colsample_bytree=0.1, learning_rate=0.1, max_depth=7, n_estimators=500;, score=0.836 total time=  12.1s\n",
      "[CV 2/5] END colsample_bytree=0.1, learning_rate=0.1, max_depth=10, n_estimators=300;, score=0.816 total time=   9.9s\n",
      "[CV 1/5] END colsample_bytree=0.1, learning_rate=0.1, max_depth=10, n_estimators=300;, score=0.809 total time=  10.2s\n",
      "[CV 3/5] END colsample_bytree=0.1, learning_rate=0.1, max_depth=10, n_estimators=300;, score=0.798 total time=  10.1s\n",
      "[CV 4/5] END colsample_bytree=0.1, learning_rate=0.1, max_depth=10, n_estimators=300;, score=0.828 total time=   9.9s\n",
      "[CV 5/5] END colsample_bytree=0.1, learning_rate=0.1, max_depth=10, n_estimators=300;, score=0.808 total time=  10.0s\n",
      "[CV 1/5] END colsample_bytree=0.1, learning_rate=0.1, max_depth=7, n_estimators=900;, score=0.830 total time=  22.2s\n",
      "[CV 3/5] END colsample_bytree=0.1, learning_rate=0.1, max_depth=7, n_estimators=900;, score=0.811 total time=  21.9s\n",
      "[CV 2/5] END colsample_bytree=0.1, learning_rate=0.1, max_depth=7, n_estimators=900;, score=0.844 total time=  22.1s\n",
      "[CV 4/5] END colsample_bytree=0.1, learning_rate=0.1, max_depth=7, n_estimators=900;, score=0.851 total time=  22.0s\n",
      "[CV 5/5] END colsample_bytree=0.1, learning_rate=0.1, max_depth=7, n_estimators=900;, score=0.831 total time=  22.1s\n",
      "[CV 1/5] END colsample_bytree=0.1, learning_rate=0.1, max_depth=10, n_estimators=500;, score=0.818 total time=  16.1s\n",
      "[CV 2/5] END colsample_bytree=0.1, learning_rate=0.1, max_depth=10, n_estimators=500;, score=0.830 total time=  16.2s\n",
      "[CV 4/5] END colsample_bytree=0.1, learning_rate=0.1, max_depth=10, n_estimators=500;, score=0.836 total time=  16.3s\n",
      "[CV 3/5] END colsample_bytree=0.1, learning_rate=0.1, max_depth=10, n_estimators=500;, score=0.808 total time=  16.2s\n",
      "[CV 5/5] END colsample_bytree=0.1, learning_rate=0.1, max_depth=10, n_estimators=500;, score=0.820 total time=  16.4s\n",
      "[CV 1/5] END colsample_bytree=0.1, learning_rate=0.1, max_depth=None, n_estimators=300;, score=0.811 total time=   6.8s\n",
      "[CV 2/5] END colsample_bytree=0.1, learning_rate=0.1, max_depth=None, n_estimators=300;, score=0.821 total time=   6.8s\n",
      "[CV 3/5] END colsample_bytree=0.1, learning_rate=0.1, max_depth=None, n_estimators=300;, score=0.795 total time=   6.8s\n",
      "[CV 4/5] END colsample_bytree=0.1, learning_rate=0.1, max_depth=None, n_estimators=300;, score=0.835 total time=   6.9s\n",
      "[CV 5/5] END colsample_bytree=0.1, learning_rate=0.1, max_depth=None, n_estimators=300;, score=0.814 total time=   6.8s\n",
      "[CV 2/5] END colsample_bytree=0.1, learning_rate=0.1, max_depth=10, n_estimators=900;, score=0.845 total time=  27.2s\n",
      "[CV 1/5] END colsample_bytree=0.1, learning_rate=0.1, max_depth=10, n_estimators=900;, score=0.830 total time=  27.4s\n",
      "[CV 3/5] END colsample_bytree=0.1, learning_rate=0.1, max_depth=10, n_estimators=900;, score=0.815 total time=  27.5s\n",
      "[CV 4/5] END colsample_bytree=0.1, learning_rate=0.1, max_depth=10, n_estimators=900;, score=0.842 total time=  27.3s\n",
      "[CV 5/5] END colsample_bytree=0.1, learning_rate=0.1, max_depth=10, n_estimators=900;, score=0.822 total time=  27.0s\n",
      "[CV 1/5] END colsample_bytree=0.1, learning_rate=0.1, max_depth=None, n_estimators=500;, score=0.826 total time=  10.5s\n",
      "[CV 2/5] END colsample_bytree=0.1, learning_rate=0.1, max_depth=None, n_estimators=500;, score=0.838 total time=  10.5s\n",
      "[CV 3/5] END colsample_bytree=0.1, learning_rate=0.1, max_depth=None, n_estimators=500;, score=0.811 total time=  10.5s\n",
      "[CV 4/5] END colsample_bytree=0.1, learning_rate=0.1, max_depth=None, n_estimators=500;, score=0.838 total time=  10.5s\n",
      "[CV 5/5] END colsample_bytree=0.1, learning_rate=0.1, max_depth=None, n_estimators=500;, score=0.829 total time=  10.4s\n",
      "[CV 1/5] END colsample_bytree=0.1, learning_rate=0.15, max_depth=3, n_estimators=300;, score=0.779 total time=   4.5s\n",
      "[CV 2/5] END colsample_bytree=0.1, learning_rate=0.15, max_depth=3, n_estimators=300;, score=0.800 total time=   4.5s\n",
      "[CV 3/5] END colsample_bytree=0.1, learning_rate=0.15, max_depth=3, n_estimators=300;, score=0.780 total time=   4.6s\n",
      "[CV 5/5] END colsample_bytree=0.1, learning_rate=0.15, max_depth=3, n_estimators=300;, score=0.794 total time=   4.5s\n",
      "[CV 4/5] END colsample_bytree=0.1, learning_rate=0.15, max_depth=3, n_estimators=300;, score=0.806 total time=   4.7s\n",
      "[CV 1/5] END colsample_bytree=0.1, learning_rate=0.15, max_depth=3, n_estimators=500;, score=0.807 total time=   6.9s\n",
      "[CV 2/5] END colsample_bytree=0.1, learning_rate=0.15, max_depth=3, n_estimators=500;, score=0.821 total time=   6.8s\n",
      "[CV 3/5] END colsample_bytree=0.1, learning_rate=0.15, max_depth=3, n_estimators=500;, score=0.787 total time=   7.0s\n",
      "[CV 5/5] END colsample_bytree=0.1, learning_rate=0.15, max_depth=3, n_estimators=500;, score=0.813 total time=   6.7s\n",
      "[CV 4/5] END colsample_bytree=0.1, learning_rate=0.15, max_depth=3, n_estimators=500;, score=0.825 total time=   6.9s\n",
      "[CV 1/5] END colsample_bytree=0.1, learning_rate=0.1, max_depth=None, n_estimators=900;, score=0.829 total time=  18.7s\n",
      "[CV 2/5] END colsample_bytree=0.1, learning_rate=0.1, max_depth=None, n_estimators=900;, score=0.853 total time=  18.6s\n",
      "[CV 5/5] END colsample_bytree=0.1, learning_rate=0.1, max_depth=None, n_estimators=900;, score=0.838 total time=  18.9s\n",
      "[CV 4/5] END colsample_bytree=0.1, learning_rate=0.1, max_depth=None, n_estimators=900;, score=0.842 total time=  18.7s\n",
      "[CV 3/5] END colsample_bytree=0.1, learning_rate=0.1, max_depth=None, n_estimators=900;, score=0.821 total time=  18.9s\n",
      "[CV 2/5] END colsample_bytree=0.1, learning_rate=0.15, max_depth=5, n_estimators=300;, score=0.821 total time=   5.9s\n",
      "[CV 1/5] END colsample_bytree=0.1, learning_rate=0.15, max_depth=5, n_estimators=300;, score=0.811 total time=   6.1s\n",
      "[CV 3/5] END colsample_bytree=0.1, learning_rate=0.15, max_depth=5, n_estimators=300;, score=0.799 total time=   6.0s\n",
      "[CV 4/5] END colsample_bytree=0.1, learning_rate=0.15, max_depth=5, n_estimators=300;, score=0.832 total time=   5.9s\n",
      "[CV 5/5] END colsample_bytree=0.1, learning_rate=0.15, max_depth=5, n_estimators=300;, score=0.827 total time=   6.1s\n",
      "[CV 2/5] END colsample_bytree=0.1, learning_rate=0.15, max_depth=3, n_estimators=900;, score=0.838 total time=  11.5s\n",
      "[CV 1/5] END colsample_bytree=0.1, learning_rate=0.15, max_depth=3, n_estimators=900;, score=0.825 total time=  12.0s\n",
      "[CV 3/5] END colsample_bytree=0.1, learning_rate=0.15, max_depth=3, n_estimators=900;, score=0.806 total time=  11.5s\n",
      "[CV 4/5] END colsample_bytree=0.1, learning_rate=0.15, max_depth=3, n_estimators=900;, score=0.839 total time=  11.7s\n",
      "[CV 5/5] END colsample_bytree=0.1, learning_rate=0.15, max_depth=3, n_estimators=900;, score=0.839 total time=  11.9s\n",
      "[CV 1/5] END colsample_bytree=0.1, learning_rate=0.15, max_depth=5, n_estimators=500;, score=0.828 total time=   9.5s\n",
      "[CV 2/5] END colsample_bytree=0.1, learning_rate=0.15, max_depth=5, n_estimators=500;, score=0.840 total time=   9.5s\n",
      "[CV 4/5] END colsample_bytree=0.1, learning_rate=0.15, max_depth=5, n_estimators=500;, score=0.839 total time=   9.2s\n",
      "[CV 3/5] END colsample_bytree=0.1, learning_rate=0.15, max_depth=5, n_estimators=500;, score=0.819 total time=   9.4s\n",
      "[CV 5/5] END colsample_bytree=0.1, learning_rate=0.15, max_depth=5, n_estimators=500;, score=0.836 total time=   9.5s\n",
      "[CV 1/5] END colsample_bytree=0.1, learning_rate=0.15, max_depth=7, n_estimators=300;, score=0.824 total time=   8.5s\n",
      "[CV 2/5] END colsample_bytree=0.1, learning_rate=0.15, max_depth=7, n_estimators=300;, score=0.830 total time=   8.5s\n",
      "[CV 4/5] END colsample_bytree=0.1, learning_rate=0.15, max_depth=7, n_estimators=300;, score=0.828 total time=   8.4s\n",
      "[CV 3/5] END colsample_bytree=0.1, learning_rate=0.15, max_depth=7, n_estimators=300;, score=0.786 total time=   8.5s\n",
      "[CV 5/5] END colsample_bytree=0.1, learning_rate=0.15, max_depth=7, n_estimators=300;, score=0.827 total time=   8.5s\n",
      "[CV 1/5] END colsample_bytree=0.1, learning_rate=0.15, max_depth=5, n_estimators=900;, score=0.835 total time=  17.4s\n",
      "[CV 2/5] END colsample_bytree=0.1, learning_rate=0.15, max_depth=5, n_estimators=900;, score=0.857 total time=  17.3s\n",
      "[CV 3/5] END colsample_bytree=0.1, learning_rate=0.15, max_depth=5, n_estimators=900;, score=0.828 total time=  17.6s\n",
      "[CV 5/5] END colsample_bytree=0.1, learning_rate=0.15, max_depth=5, n_estimators=900;, score=0.840 total time=  17.5s\n",
      "[CV 4/5] END colsample_bytree=0.1, learning_rate=0.15, max_depth=5, n_estimators=900;, score=0.850 total time=  17.7s\n",
      "[CV 4/5] END colsample_bytree=0.1, learning_rate=0.15, max_depth=7, n_estimators=500;, score=0.835 total time=  12.6s\n",
      "[CV 3/5] END colsample_bytree=0.1, learning_rate=0.15, max_depth=7, n_estimators=500;, score=0.820 total time=  12.6s\n",
      "[CV 1/5] END colsample_bytree=0.1, learning_rate=0.15, max_depth=7, n_estimators=500;, score=0.827 total time=  12.7s\n",
      "[CV 2/5] END colsample_bytree=0.1, learning_rate=0.15, max_depth=7, n_estimators=500;, score=0.837 total time=  12.7s\n",
      "[CV 5/5] END colsample_bytree=0.1, learning_rate=0.15, max_depth=7, n_estimators=500;, score=0.838 total time=  12.5s\n",
      "[CV 1/5] END colsample_bytree=0.1, learning_rate=0.15, max_depth=10, n_estimators=300;, score=0.809 total time=   9.9s\n",
      "[CV 2/5] END colsample_bytree=0.1, learning_rate=0.15, max_depth=10, n_estimators=300;, score=0.828 total time=  10.1s\n",
      "[CV 3/5] END colsample_bytree=0.1, learning_rate=0.15, max_depth=10, n_estimators=300;, score=0.809 total time=  10.1s\n",
      "[CV 4/5] END colsample_bytree=0.1, learning_rate=0.15, max_depth=10, n_estimators=300;, score=0.825 total time=   9.9s\n",
      "[CV 5/5] END colsample_bytree=0.1, learning_rate=0.15, max_depth=10, n_estimators=300;, score=0.826 total time=   9.8s\n",
      "[CV 1/5] END colsample_bytree=0.1, learning_rate=0.15, max_depth=7, n_estimators=900;, score=0.834 total time=  21.9s\n",
      "[CV 2/5] END colsample_bytree=0.1, learning_rate=0.15, max_depth=7, n_estimators=900;, score=0.851 total time=  22.1s\n",
      "[CV 4/5] END colsample_bytree=0.1, learning_rate=0.15, max_depth=7, n_estimators=900;, score=0.835 total time=  21.9s\n",
      "[CV 3/5] END colsample_bytree=0.1, learning_rate=0.15, max_depth=7, n_estimators=900;, score=0.825 total time=  22.3s\n",
      "[CV 5/5] END colsample_bytree=0.1, learning_rate=0.15, max_depth=7, n_estimators=900;, score=0.844 total time=  22.2s\n",
      "[CV 1/5] END colsample_bytree=0.1, learning_rate=0.15, max_depth=10, n_estimators=500;, score=0.824 total time=  16.8s\n",
      "[CV 2/5] END colsample_bytree=0.1, learning_rate=0.15, max_depth=10, n_estimators=500;, score=0.840 total time=  16.8s\n",
      "[CV 5/5] END colsample_bytree=0.1, learning_rate=0.15, max_depth=10, n_estimators=500;, score=0.831 total time=  16.8s\n",
      "[CV 3/5] END colsample_bytree=0.1, learning_rate=0.15, max_depth=10, n_estimators=500;, score=0.813 total time=  16.9s\n",
      "[CV 4/5] END colsample_bytree=0.1, learning_rate=0.15, max_depth=10, n_estimators=500;, score=0.832 total time=  17.3s\n",
      "[CV 2/5] END colsample_bytree=0.1, learning_rate=0.15, max_depth=None, n_estimators=300;, score=0.835 total time=   7.3s\n",
      "[CV 1/5] END colsample_bytree=0.1, learning_rate=0.15, max_depth=None, n_estimators=300;, score=0.829 total time=   7.4s\n",
      "[CV 3/5] END colsample_bytree=0.1, learning_rate=0.15, max_depth=None, n_estimators=300;, score=0.805 total time=   7.4s\n",
      "[CV 4/5] END colsample_bytree=0.1, learning_rate=0.15, max_depth=None, n_estimators=300;, score=0.835 total time=   7.5s\n",
      "[CV 5/5] END colsample_bytree=0.1, learning_rate=0.15, max_depth=None, n_estimators=300;, score=0.839 total time=   7.6s\n",
      "[CV 1/5] END colsample_bytree=0.1, learning_rate=0.15, max_depth=10, n_estimators=900;, score=0.823 total time=  27.6s\n",
      "[CV 2/5] END colsample_bytree=0.1, learning_rate=0.15, max_depth=10, n_estimators=900;, score=0.850 total time=  27.5s\n",
      "[CV 3/5] END colsample_bytree=0.1, learning_rate=0.15, max_depth=10, n_estimators=900;, score=0.815 total time=  27.4s\n",
      "[CV 4/5] END colsample_bytree=0.1, learning_rate=0.15, max_depth=10, n_estimators=900;, score=0.829 total time=  27.8s\n",
      "[CV 5/5] END colsample_bytree=0.1, learning_rate=0.15, max_depth=10, n_estimators=900;, score=0.834 total time=  27.2s\n",
      "[CV 2/5] END colsample_bytree=0.1, learning_rate=0.15, max_depth=None, n_estimators=500;, score=0.841 total time=  10.8s\n",
      "[CV 1/5] END colsample_bytree=0.1, learning_rate=0.15, max_depth=None, n_estimators=500;, score=0.830 total time=  11.0s\n",
      "[CV 3/5] END colsample_bytree=0.1, learning_rate=0.15, max_depth=None, n_estimators=500;, score=0.814 total time=  10.9s\n",
      "[CV 4/5] END colsample_bytree=0.1, learning_rate=0.15, max_depth=None, n_estimators=500;, score=0.835 total time=  11.0s\n",
      "[CV 5/5] END colsample_bytree=0.1, learning_rate=0.15, max_depth=None, n_estimators=500;, score=0.841 total time=  11.0s\n",
      "[CV 1/5] END colsample_bytree=0.1, learning_rate=0.2, max_depth=3, n_estimators=300;, score=0.790 total time=   4.6s\n",
      "[CV 2/5] END colsample_bytree=0.1, learning_rate=0.2, max_depth=3, n_estimators=300;, score=0.818 total time=   4.6s\n",
      "[CV 3/5] END colsample_bytree=0.1, learning_rate=0.2, max_depth=3, n_estimators=300;, score=0.782 total time=   4.8s\n",
      "[CV 4/5] END colsample_bytree=0.1, learning_rate=0.2, max_depth=3, n_estimators=300;, score=0.817 total time=   4.7s\n",
      "[CV 5/5] END colsample_bytree=0.1, learning_rate=0.2, max_depth=3, n_estimators=300;, score=0.806 total time=   4.6s\n",
      "[CV 1/5] END colsample_bytree=0.1, learning_rate=0.2, max_depth=3, n_estimators=500;, score=0.813 total time=   6.9s\n",
      "[CV 2/5] END colsample_bytree=0.1, learning_rate=0.2, max_depth=3, n_estimators=500;, score=0.832 total time=   6.8s\n",
      "[CV 1/5] END colsample_bytree=0.1, learning_rate=0.15, max_depth=None, n_estimators=900;, score=0.829 total time=  19.3s\n",
      "[CV 2/5] END colsample_bytree=0.1, learning_rate=0.15, max_depth=None, n_estimators=900;, score=0.856 total time=  19.5s\n",
      "[CV 3/5] END colsample_bytree=0.1, learning_rate=0.2, max_depth=3, n_estimators=500;, score=0.804 total time=   6.8s\n",
      "[CV 4/5] END colsample_bytree=0.1, learning_rate=0.2, max_depth=3, n_estimators=500;, score=0.831 total time=   6.7s\n",
      "[CV 5/5] END colsample_bytree=0.1, learning_rate=0.2, max_depth=3, n_estimators=500;, score=0.830 total time=   6.7s\n",
      "[CV 3/5] END colsample_bytree=0.1, learning_rate=0.15, max_depth=None, n_estimators=900;, score=0.825 total time=  18.9s\n",
      "[CV 4/5] END colsample_bytree=0.1, learning_rate=0.15, max_depth=None, n_estimators=900;, score=0.840 total time=  18.8s\n",
      "[CV 5/5] END colsample_bytree=0.1, learning_rate=0.15, max_depth=None, n_estimators=900;, score=0.845 total time=  19.4s\n",
      "[CV 1/5] END colsample_bytree=0.1, learning_rate=0.2, max_depth=5, n_estimators=300;, score=0.822 total time=   5.9s\n",
      "[CV 2/5] END colsample_bytree=0.1, learning_rate=0.2, max_depth=5, n_estimators=300;, score=0.837 total time=   6.0s\n",
      "[CV 3/5] END colsample_bytree=0.1, learning_rate=0.2, max_depth=5, n_estimators=300;, score=0.817 total time=   6.0s\n",
      "[CV 4/5] END colsample_bytree=0.1, learning_rate=0.2, max_depth=5, n_estimators=300;, score=0.836 total time=   6.0s\n",
      "[CV 5/5] END colsample_bytree=0.1, learning_rate=0.2, max_depth=5, n_estimators=300;, score=0.851 total time=   6.1s\n",
      "[CV 2/5] END colsample_bytree=0.1, learning_rate=0.2, max_depth=3, n_estimators=900;, score=0.852 total time=  11.5s\n",
      "[CV 1/5] END colsample_bytree=0.1, learning_rate=0.2, max_depth=3, n_estimators=900;, score=0.831 total time=  11.7s\n",
      "[CV 3/5] END colsample_bytree=0.1, learning_rate=0.2, max_depth=3, n_estimators=900;, score=0.819 total time=  12.0s\n",
      "[CV 4/5] END colsample_bytree=0.1, learning_rate=0.2, max_depth=3, n_estimators=900;, score=0.841 total time=  11.9s\n",
      "[CV 5/5] END colsample_bytree=0.1, learning_rate=0.2, max_depth=3, n_estimators=900;, score=0.846 total time=  11.9s\n",
      "[CV 1/5] END colsample_bytree=0.1, learning_rate=0.2, max_depth=5, n_estimators=500;, score=0.821 total time=   9.2s\n",
      "[CV 2/5] END colsample_bytree=0.1, learning_rate=0.2, max_depth=5, n_estimators=500;, score=0.849 total time=   9.2s\n",
      "[CV 3/5] END colsample_bytree=0.1, learning_rate=0.2, max_depth=5, n_estimators=500;, score=0.827 total time=   8.9s\n",
      "[CV 4/5] END colsample_bytree=0.1, learning_rate=0.2, max_depth=5, n_estimators=500;, score=0.832 total time=   9.2s\n",
      "[CV 5/5] END colsample_bytree=0.1, learning_rate=0.2, max_depth=5, n_estimators=500;, score=0.856 total time=   9.2s\n",
      "[CV 1/5] END colsample_bytree=0.1, learning_rate=0.2, max_depth=7, n_estimators=300;, score=0.819 total time=   7.7s\n",
      "[CV 2/5] END colsample_bytree=0.1, learning_rate=0.2, max_depth=7, n_estimators=300;, score=0.831 total time=   7.6s\n",
      "[CV 3/5] END colsample_bytree=0.1, learning_rate=0.2, max_depth=7, n_estimators=300;, score=0.813 total time=   7.7s\n",
      "[CV 4/5] END colsample_bytree=0.1, learning_rate=0.2, max_depth=7, n_estimators=300;, score=0.830 total time=   7.8s\n",
      "[CV 5/5] END colsample_bytree=0.1, learning_rate=0.2, max_depth=7, n_estimators=300;, score=0.825 total time=   7.8s\n",
      "[CV 1/5] END colsample_bytree=0.1, learning_rate=0.2, max_depth=5, n_estimators=900;, score=0.831 total time=  16.5s\n",
      "[CV 2/5] END colsample_bytree=0.1, learning_rate=0.2, max_depth=5, n_estimators=900;, score=0.855 total time=  16.7s\n",
      "[CV 3/5] END colsample_bytree=0.1, learning_rate=0.2, max_depth=5, n_estimators=900;, score=0.837 total time=  16.7s\n",
      "[CV 4/5] END colsample_bytree=0.1, learning_rate=0.2, max_depth=5, n_estimators=900;, score=0.838 total time=  16.3s\n",
      "[CV 5/5] END colsample_bytree=0.1, learning_rate=0.2, max_depth=5, n_estimators=900;, score=0.859 total time=  16.4s\n",
      "[CV 1/5] END colsample_bytree=0.1, learning_rate=0.2, max_depth=7, n_estimators=500;, score=0.823 total time=  12.6s\n",
      "[CV 2/5] END colsample_bytree=0.1, learning_rate=0.2, max_depth=7, n_estimators=500;, score=0.839 total time=  12.7s\n",
      "[CV 3/5] END colsample_bytree=0.1, learning_rate=0.2, max_depth=7, n_estimators=500;, score=0.824 total time=  12.9s\n",
      "[CV 4/5] END colsample_bytree=0.1, learning_rate=0.2, max_depth=7, n_estimators=500;, score=0.834 total time=  13.1s\n",
      "[CV 5/5] END colsample_bytree=0.1, learning_rate=0.2, max_depth=7, n_estimators=500;, score=0.830 total time=  12.8s\n",
      "[CV 1/5] END colsample_bytree=0.1, learning_rate=0.2, max_depth=10, n_estimators=300;, score=0.814 total time=   9.8s\n",
      "[CV 3/5] END colsample_bytree=0.1, learning_rate=0.2, max_depth=10, n_estimators=300;, score=0.802 total time=  10.0s\n",
      "[CV 2/5] END colsample_bytree=0.1, learning_rate=0.2, max_depth=10, n_estimators=300;, score=0.824 total time=   9.8s\n",
      "[CV 5/5] END colsample_bytree=0.1, learning_rate=0.2, max_depth=10, n_estimators=300;, score=0.817 total time=  10.0s\n",
      "[CV 4/5] END colsample_bytree=0.1, learning_rate=0.2, max_depth=10, n_estimators=300;, score=0.838 total time=   9.9s\n",
      "[CV 2/5] END colsample_bytree=0.1, learning_rate=0.2, max_depth=7, n_estimators=900;, score=0.852 total time=  21.8s\n",
      "[CV 1/5] END colsample_bytree=0.1, learning_rate=0.2, max_depth=7, n_estimators=900;, score=0.831 total time=  22.1s\n",
      "[CV 4/5] END colsample_bytree=0.1, learning_rate=0.2, max_depth=7, n_estimators=900;, score=0.832 total time=  21.7s\n",
      "[CV 3/5] END colsample_bytree=0.1, learning_rate=0.2, max_depth=7, n_estimators=900;, score=0.828 total time=  22.3s\n",
      "[CV 5/5] END colsample_bytree=0.1, learning_rate=0.2, max_depth=7, n_estimators=900;, score=0.833 total time=  21.9s\n",
      "[CV 1/5] END colsample_bytree=0.1, learning_rate=0.2, max_depth=10, n_estimators=500;, score=0.823 total time=  15.2s\n",
      "[CV 2/5] END colsample_bytree=0.1, learning_rate=0.2, max_depth=10, n_estimators=500;, score=0.829 total time=  15.4s\n",
      "[CV 3/5] END colsample_bytree=0.1, learning_rate=0.2, max_depth=10, n_estimators=500;, score=0.811 total time=  15.0s\n",
      "[CV 5/5] END colsample_bytree=0.1, learning_rate=0.2, max_depth=10, n_estimators=500;, score=0.827 total time=  15.3s\n",
      "[CV 4/5] END colsample_bytree=0.1, learning_rate=0.2, max_depth=10, n_estimators=500;, score=0.835 total time=  15.4s\n",
      "[CV 1/5] END colsample_bytree=0.1, learning_rate=0.2, max_depth=None, n_estimators=300;, score=0.838 total time=   7.2s\n",
      "[CV 2/5] END colsample_bytree=0.1, learning_rate=0.2, max_depth=None, n_estimators=300;, score=0.844 total time=   6.9s\n",
      "[CV 3/5] END colsample_bytree=0.1, learning_rate=0.2, max_depth=None, n_estimators=300;, score=0.816 total time=   7.2s\n",
      "[CV 5/5] END colsample_bytree=0.1, learning_rate=0.2, max_depth=None, n_estimators=300;, score=0.831 total time=   7.2s\n",
      "[CV 4/5] END colsample_bytree=0.1, learning_rate=0.2, max_depth=None, n_estimators=300;, score=0.839 total time=   7.3s\n",
      "[CV 1/5] END colsample_bytree=0.1, learning_rate=0.2, max_depth=10, n_estimators=900;, score=0.833 total time=  25.0s\n",
      "[CV 2/5] END colsample_bytree=0.1, learning_rate=0.2, max_depth=10, n_estimators=900;, score=0.852 total time=  25.2s\n",
      "[CV 3/5] END colsample_bytree=0.1, learning_rate=0.2, max_depth=10, n_estimators=900;, score=0.812 total time=  25.1s\n",
      "[CV 4/5] END colsample_bytree=0.1, learning_rate=0.2, max_depth=10, n_estimators=900;, score=0.845 total time=  25.1s\n",
      "[CV 5/5] END colsample_bytree=0.1, learning_rate=0.2, max_depth=10, n_estimators=900;, score=0.832 total time=  24.9s\n",
      "[CV 1/5] END colsample_bytree=0.1, learning_rate=0.2, max_depth=None, n_estimators=500;, score=0.836 total time=  10.9s\n",
      "[CV 2/5] END colsample_bytree=0.1, learning_rate=0.2, max_depth=None, n_estimators=500;, score=0.846 total time=  10.9s\n",
      "[CV 3/5] END colsample_bytree=0.1, learning_rate=0.2, max_depth=None, n_estimators=500;, score=0.826 total time=  10.9s\n",
      "[CV 4/5] END colsample_bytree=0.1, learning_rate=0.2, max_depth=None, n_estimators=500;, score=0.833 total time=  10.7s\n",
      "[CV 5/5] END colsample_bytree=0.1, learning_rate=0.2, max_depth=None, n_estimators=500;, score=0.840 total time=  10.8s\n",
      "[CV 1/5] END colsample_bytree=0.1, learning_rate=0.3, max_depth=3, n_estimators=300;, score=0.810 total time=   4.5s\n",
      "[CV 2/5] END colsample_bytree=0.1, learning_rate=0.3, max_depth=3, n_estimators=300;, score=0.819 total time=   4.6s\n",
      "[CV 3/5] END colsample_bytree=0.1, learning_rate=0.3, max_depth=3, n_estimators=300;, score=0.784 total time=   4.7s\n",
      "[CV 4/5] END colsample_bytree=0.1, learning_rate=0.3, max_depth=3, n_estimators=300;, score=0.818 total time=   4.6s\n",
      "[CV 5/5] END colsample_bytree=0.1, learning_rate=0.3, max_depth=3, n_estimators=300;, score=0.821 total time=   4.6s\n",
      "[CV 1/5] END colsample_bytree=0.1, learning_rate=0.3, max_depth=3, n_estimators=500;, score=0.831 total time=   7.1s\n",
      "[CV 3/5] END colsample_bytree=0.1, learning_rate=0.3, max_depth=3, n_estimators=500;, score=0.811 total time=   7.1s\n",
      "[CV 2/5] END colsample_bytree=0.1, learning_rate=0.3, max_depth=3, n_estimators=500;, score=0.832 total time=   7.0s\n",
      "[CV 4/5] END colsample_bytree=0.1, learning_rate=0.3, max_depth=3, n_estimators=500;, score=0.823 total time=   7.1s\n",
      "[CV 5/5] END colsample_bytree=0.1, learning_rate=0.3, max_depth=3, n_estimators=500;, score=0.839 total time=   7.0s\n",
      "[CV 1/5] END colsample_bytree=0.1, learning_rate=0.2, max_depth=None, n_estimators=900;, score=0.829 total time=  20.1s\n",
      "[CV 2/5] END colsample_bytree=0.1, learning_rate=0.2, max_depth=None, n_estimators=900;, score=0.859 total time=  20.1s\n",
      "[CV 3/5] END colsample_bytree=0.1, learning_rate=0.2, max_depth=None, n_estimators=900;, score=0.827 total time=  20.4s\n",
      "[CV 4/5] END colsample_bytree=0.1, learning_rate=0.2, max_depth=None, n_estimators=900;, score=0.843 total time=  20.1s\n",
      "[CV 5/5] END colsample_bytree=0.1, learning_rate=0.2, max_depth=None, n_estimators=900;, score=0.846 total time=  20.1s\n",
      "[CV 1/5] END colsample_bytree=0.1, learning_rate=0.3, max_depth=5, n_estimators=300;, score=0.837 total time=   5.8s\n",
      "[CV 2/5] END colsample_bytree=0.1, learning_rate=0.3, max_depth=5, n_estimators=300;, score=0.839 total time=   6.0s\n",
      "[CV 4/5] END colsample_bytree=0.1, learning_rate=0.3, max_depth=5, n_estimators=300;, score=0.834 total time=   6.0s\n",
      "[CV 3/5] END colsample_bytree=0.1, learning_rate=0.3, max_depth=5, n_estimators=300;, score=0.825 total time=   6.1s\n",
      "[CV 5/5] END colsample_bytree=0.1, learning_rate=0.3, max_depth=5, n_estimators=300;, score=0.832 total time=   6.0s\n",
      "[CV 1/5] END colsample_bytree=0.1, learning_rate=0.3, max_depth=3, n_estimators=900;, score=0.841 total time=  11.4s\n",
      "[CV 3/5] END colsample_bytree=0.1, learning_rate=0.3, max_depth=3, n_estimators=900;, score=0.836 total time=  11.6s\n",
      "[CV 2/5] END colsample_bytree=0.1, learning_rate=0.3, max_depth=3, n_estimators=900;, score=0.840 total time=  12.0s\n",
      "[CV 4/5] END colsample_bytree=0.1, learning_rate=0.3, max_depth=3, n_estimators=900;, score=0.846 total time=  11.6s\n",
      "[CV 5/5] END colsample_bytree=0.1, learning_rate=0.3, max_depth=3, n_estimators=900;, score=0.838 total time=  12.1s\n",
      "[CV 1/5] END colsample_bytree=0.1, learning_rate=0.3, max_depth=5, n_estimators=500;, score=0.829 total time=   9.1s\n",
      "[CV 2/5] END colsample_bytree=0.1, learning_rate=0.3, max_depth=5, n_estimators=500;, score=0.857 total time=   9.3s\n",
      "[CV 4/5] END colsample_bytree=0.1, learning_rate=0.3, max_depth=5, n_estimators=500;, score=0.841 total time=   9.2s\n",
      "[CV 3/5] END colsample_bytree=0.1, learning_rate=0.3, max_depth=5, n_estimators=500;, score=0.824 total time=   9.5s\n",
      "[CV 5/5] END colsample_bytree=0.1, learning_rate=0.3, max_depth=5, n_estimators=500;, score=0.832 total time=   9.5s\n",
      "[CV 1/5] END colsample_bytree=0.1, learning_rate=0.3, max_depth=7, n_estimators=300;, score=0.829 total time=   7.8s\n",
      "[CV 2/5] END colsample_bytree=0.1, learning_rate=0.3, max_depth=7, n_estimators=300;, score=0.830 total time=   7.8s\n",
      "[CV 3/5] END colsample_bytree=0.1, learning_rate=0.3, max_depth=7, n_estimators=300;, score=0.822 total time=   7.5s\n",
      "[CV 1/5] END colsample_bytree=0.1, learning_rate=0.3, max_depth=5, n_estimators=900;, score=0.839 total time=  16.7s\n",
      "[CV 4/5] END colsample_bytree=0.1, learning_rate=0.3, max_depth=7, n_estimators=300;, score=0.824 total time=   7.7s\n",
      "[CV 5/5] END colsample_bytree=0.1, learning_rate=0.3, max_depth=7, n_estimators=300;, score=0.823 total time=   7.6s\n",
      "[CV 2/5] END colsample_bytree=0.1, learning_rate=0.3, max_depth=5, n_estimators=900;, score=0.867 total time=  17.0s\n",
      "[CV 3/5] END colsample_bytree=0.1, learning_rate=0.3, max_depth=5, n_estimators=900;, score=0.829 total time=  16.7s\n",
      "[CV 4/5] END colsample_bytree=0.1, learning_rate=0.3, max_depth=5, n_estimators=900;, score=0.837 total time=  16.8s\n",
      "[CV 5/5] END colsample_bytree=0.1, learning_rate=0.3, max_depth=5, n_estimators=900;, score=0.844 total time=  17.0s\n",
      "[CV 1/5] END colsample_bytree=0.1, learning_rate=0.3, max_depth=7, n_estimators=500;, score=0.828 total time=  12.4s\n",
      "[CV 2/5] END colsample_bytree=0.1, learning_rate=0.3, max_depth=7, n_estimators=500;, score=0.837 total time=  12.5s\n",
      "[CV 3/5] END colsample_bytree=0.1, learning_rate=0.3, max_depth=7, n_estimators=500;, score=0.825 total time=  12.3s\n",
      "[CV 4/5] END colsample_bytree=0.1, learning_rate=0.3, max_depth=7, n_estimators=500;, score=0.834 total time=  12.3s\n",
      "[CV 5/5] END colsample_bytree=0.1, learning_rate=0.3, max_depth=7, n_estimators=500;, score=0.829 total time=  12.4s\n",
      "[CV 1/5] END colsample_bytree=0.1, learning_rate=0.3, max_depth=10, n_estimators=300;, score=0.811 total time=   9.4s\n",
      "[CV 2/5] END colsample_bytree=0.1, learning_rate=0.3, max_depth=10, n_estimators=300;, score=0.828 total time=   9.4s\n",
      "[CV 1/5] END colsample_bytree=0.1, learning_rate=0.3, max_depth=7, n_estimators=900;, score=0.829 total time=  20.9s\n",
      "[CV 2/5] END colsample_bytree=0.1, learning_rate=0.3, max_depth=7, n_estimators=900;, score=0.850 total time=  20.7s\n",
      "[CV 4/5] END colsample_bytree=0.1, learning_rate=0.3, max_depth=10, n_estimators=300;, score=0.835 total time=   9.1s\n",
      "[CV 5/5] END colsample_bytree=0.1, learning_rate=0.3, max_depth=10, n_estimators=300;, score=0.813 total time=   9.3s\n",
      "[CV 3/5] END colsample_bytree=0.1, learning_rate=0.3, max_depth=10, n_estimators=300;, score=0.814 total time=   9.4s\n",
      "[CV 3/5] END colsample_bytree=0.1, learning_rate=0.3, max_depth=7, n_estimators=900;, score=0.825 total time=  20.4s\n",
      "[CV 4/5] END colsample_bytree=0.1, learning_rate=0.3, max_depth=7, n_estimators=900;, score=0.837 total time=  20.5s\n",
      "[CV 5/5] END colsample_bytree=0.1, learning_rate=0.3, max_depth=7, n_estimators=900;, score=0.831 total time=  20.6s\n",
      "[CV 1/5] END colsample_bytree=0.1, learning_rate=0.3, max_depth=10, n_estimators=500;, score=0.818 total time=  13.8s\n",
      "[CV 2/5] END colsample_bytree=0.1, learning_rate=0.3, max_depth=10, n_estimators=500;, score=0.845 total time=  14.1s\n",
      "[CV 3/5] END colsample_bytree=0.1, learning_rate=0.3, max_depth=10, n_estimators=500;, score=0.810 total time=  14.1s\n",
      "[CV 4/5] END colsample_bytree=0.1, learning_rate=0.3, max_depth=10, n_estimators=500;, score=0.831 total time=  14.0s\n",
      "[CV 5/5] END colsample_bytree=0.1, learning_rate=0.3, max_depth=10, n_estimators=500;, score=0.825 total time=  14.1s\n",
      "[CV 1/5] END colsample_bytree=0.1, learning_rate=0.3, max_depth=None, n_estimators=300;, score=0.822 total time=   6.6s\n",
      "[CV 3/5] END colsample_bytree=0.1, learning_rate=0.3, max_depth=None, n_estimators=300;, score=0.813 total time=   6.8s\n",
      "[CV 2/5] END colsample_bytree=0.1, learning_rate=0.3, max_depth=None, n_estimators=300;, score=0.834 total time=   6.5s\n",
      "[CV 4/5] END colsample_bytree=0.1, learning_rate=0.3, max_depth=None, n_estimators=300;, score=0.830 total time=   6.5s\n",
      "[CV 5/5] END colsample_bytree=0.1, learning_rate=0.3, max_depth=None, n_estimators=300;, score=0.828 total time=   6.6s\n",
      "[CV 1/5] END colsample_bytree=0.1, learning_rate=0.3, max_depth=10, n_estimators=900;, score=0.823 total time=  21.6s\n",
      "[CV 2/5] END colsample_bytree=0.1, learning_rate=0.3, max_depth=10, n_estimators=900;, score=0.854 total time=  22.0s\n",
      "[CV 3/5] END colsample_bytree=0.1, learning_rate=0.3, max_depth=10, n_estimators=900;, score=0.818 total time=  21.8s\n",
      "[CV 4/5] END colsample_bytree=0.1, learning_rate=0.3, max_depth=10, n_estimators=900;, score=0.837 total time=  21.9s\n",
      "[CV 5/5] END colsample_bytree=0.1, learning_rate=0.3, max_depth=10, n_estimators=900;, score=0.839 total time=  22.2s\n",
      "[CV 1/5] END colsample_bytree=0.1, learning_rate=0.3, max_depth=None, n_estimators=500;, score=0.821 total time=  10.7s\n",
      "[CV 2/5] END colsample_bytree=0.1, learning_rate=0.3, max_depth=None, n_estimators=500;, score=0.844 total time=  10.6s\n",
      "[CV 3/5] END colsample_bytree=0.1, learning_rate=0.3, max_depth=None, n_estimators=500;, score=0.819 total time=  10.7s\n",
      "[CV 4/5] END colsample_bytree=0.1, learning_rate=0.3, max_depth=None, n_estimators=500;, score=0.830 total time=  10.7s\n",
      "[CV 5/5] END colsample_bytree=0.1, learning_rate=0.3, max_depth=None, n_estimators=500;, score=0.837 total time=  11.1s\n",
      "[CV 1/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=300;, score=0.797 total time=   4.3s\n",
      "[CV 2/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=300;, score=0.823 total time=   4.1s\n",
      "[CV 3/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=300;, score=0.794 total time=   4.4s\n",
      "[CV 4/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=300;, score=0.815 total time=   4.4s\n",
      "[CV 5/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=300;, score=0.815 total time=   4.3s\n",
      "[CV 1/5] END colsample_bytree=0.1, learning_rate=0.3, max_depth=None, n_estimators=900;, score=0.831 total time=  18.6s\n",
      "[CV 2/5] END colsample_bytree=0.1, learning_rate=0.3, max_depth=None, n_estimators=900;, score=0.852 total time=  18.8s\n",
      "[CV 1/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=500;, score=0.828 total time=   6.7s\n",
      "[CV 2/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=500;, score=0.849 total time=   6.5s\n",
      "[CV 3/5] END colsample_bytree=0.1, learning_rate=0.3, max_depth=None, n_estimators=900;, score=0.823 total time=  18.7s\n",
      "[CV 4/5] END colsample_bytree=0.1, learning_rate=0.3, max_depth=None, n_estimators=900;, score=0.837 total time=  19.0s\n",
      "[CV 3/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=500;, score=0.804 total time=   6.6s\n",
      "[CV 4/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=500;, score=0.840 total time=   6.5s\n",
      "[CV 5/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=500;, score=0.843 total time=   6.4s\n",
      "[CV 5/5] END colsample_bytree=0.1, learning_rate=0.3, max_depth=None, n_estimators=900;, score=0.842 total time=  18.5s\n",
      "[CV 1/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=300;, score=0.859 total time=   5.6s\n",
      "[CV 2/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=300;, score=0.864 total time=   5.7s\n",
      "[CV 3/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=300;, score=0.842 total time=   5.8s\n",
      "[CV 4/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=300;, score=0.851 total time=   5.8s\n",
      "[CV 5/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=300;, score=0.861 total time=   5.9s\n",
      "[CV 1/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=900;, score=0.848 total time=  11.4s\n",
      "[CV 2/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=900;, score=0.850 total time=  11.3s\n",
      "[CV 4/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=900;, score=0.860 total time=  11.2s\n",
      "[CV 3/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=900;, score=0.844 total time=  11.7s\n",
      "[CV 5/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=900;, score=0.858 total time=  11.6s\n",
      "[CV 2/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=500;, score=0.864 total time=   9.0s\n",
      "[CV 1/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=500;, score=0.869 total time=   9.1s\n",
      "[CV 4/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=500;, score=0.873 total time=   9.1s\n",
      "[CV 3/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=500;, score=0.867 total time=   8.9s\n",
      "[CV 5/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=500;, score=0.866 total time=   9.1s\n",
      "[CV 1/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=7, n_estimators=300;, score=0.852 total time=   7.5s\n",
      "[CV 3/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=7, n_estimators=300;, score=0.850 total time=   7.5s\n",
      "[CV 4/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=7, n_estimators=300;, score=0.861 total time=   7.6s\n",
      "[CV 2/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=7, n_estimators=300;, score=0.864 total time=   7.5s\n",
      "[CV 5/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=7, n_estimators=300;, score=0.850 total time=   7.3s\n",
      "[CV 1/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=900;, score=0.875 total time=  16.3s\n",
      "[CV 2/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=900;, score=0.869 total time=  16.1s\n",
      "[CV 5/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=900;, score=0.856 total time=  16.0s\n",
      "[CV 3/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=900;, score=0.878 total time=  16.2s\n",
      "[CV 4/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=900;, score=0.874 total time=  16.9s\n",
      "[CV 1/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=7, n_estimators=500;, score=0.862 total time=  12.4s\n",
      "[CV 2/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=7, n_estimators=500;, score=0.871 total time=  12.1s\n",
      "[CV 4/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=7, n_estimators=500;, score=0.865 total time=  12.3s\n",
      "[CV 3/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=7, n_estimators=500;, score=0.863 total time=  12.5s\n",
      "[CV 5/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=7, n_estimators=500;, score=0.858 total time=  12.2s\n",
      "[CV 1/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=10, n_estimators=300;, score=0.845 total time=   9.6s\n",
      "[CV 2/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=10, n_estimators=300;, score=0.852 total time=   9.5s\n",
      "[CV 3/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=10, n_estimators=300;, score=0.835 total time=   9.4s\n",
      "[CV 4/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=10, n_estimators=300;, score=0.859 total time=   9.4s\n",
      "[CV 5/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=10, n_estimators=300;, score=0.851 total time=   9.3s\n",
      "[CV 1/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=7, n_estimators=900;, score=0.862 total time=  21.2s\n",
      "[CV 2/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=7, n_estimators=900;, score=0.872 total time=  21.2s\n",
      "[CV 4/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=7, n_estimators=900;, score=0.865 total time=  21.2s\n",
      "[CV 3/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=7, n_estimators=900;, score=0.872 total time=  21.3s\n",
      "[CV 5/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=7, n_estimators=900;, score=0.858 total time=  20.7s\n",
      "[CV 1/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=10, n_estimators=500;, score=0.851 total time=  14.5s\n",
      "[CV 3/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=10, n_estimators=500;, score=0.847 total time=  14.4s\n",
      "[CV 4/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=10, n_estimators=500;, score=0.859 total time=  14.3s\n",
      "[CV 2/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=10, n_estimators=500;, score=0.867 total time=  14.4s\n",
      "[CV 5/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=10, n_estimators=500;, score=0.850 total time=  14.5s\n",
      "[CV 1/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=None, n_estimators=300;, score=0.857 total time=   6.6s\n",
      "[CV 3/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=None, n_estimators=300;, score=0.854 total time=   6.6s\n",
      "[CV 4/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=None, n_estimators=300;, score=0.864 total time=   6.6s\n",
      "[CV 2/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=None, n_estimators=300;, score=0.858 total time=   6.6s\n",
      "[CV 5/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=None, n_estimators=300;, score=0.860 total time=   6.7s\n",
      "[CV 1/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=10, n_estimators=900;, score=0.855 total time=  23.1s\n",
      "[CV 2/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=10, n_estimators=900;, score=0.865 total time=  23.5s\n",
      "[CV 4/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=10, n_estimators=900;, score=0.856 total time=  23.4s\n",
      "[CV 5/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=10, n_estimators=900;, score=0.856 total time=  22.9s\n",
      "[CV 3/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=10, n_estimators=900;, score=0.850 total time=  23.6s\n",
      "[CV 1/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=None, n_estimators=500;, score=0.861 total time=  10.7s\n",
      "[CV 2/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=None, n_estimators=500;, score=0.867 total time=  10.5s\n",
      "[CV 4/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=None, n_estimators=500;, score=0.869 total time=  11.0s\n",
      "[CV 3/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=None, n_estimators=500;, score=0.867 total time=  10.6s\n",
      "[CV 5/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=None, n_estimators=500;, score=0.863 total time=  10.7s\n",
      "[CV 1/5] END colsample_bytree=0.3, learning_rate=0.15, max_depth=3, n_estimators=300;, score=0.806 total time=   4.6s\n",
      "[CV 2/5] END colsample_bytree=0.3, learning_rate=0.15, max_depth=3, n_estimators=300;, score=0.840 total time=   4.4s\n",
      "[CV 3/5] END colsample_bytree=0.3, learning_rate=0.15, max_depth=3, n_estimators=300;, score=0.813 total time=   4.5s\n",
      "[CV 4/5] END colsample_bytree=0.3, learning_rate=0.15, max_depth=3, n_estimators=300;, score=0.833 total time=   4.6s\n",
      "[CV 5/5] END colsample_bytree=0.3, learning_rate=0.15, max_depth=3, n_estimators=300;, score=0.843 total time=   4.5s\n",
      "[CV 1/5] END colsample_bytree=0.3, learning_rate=0.15, max_depth=3, n_estimators=500;, score=0.835 total time=   6.8s\n",
      "[CV 2/5] END colsample_bytree=0.3, learning_rate=0.15, max_depth=3, n_estimators=500;, score=0.862 total time=   6.7s\n",
      "[CV 3/5] END colsample_bytree=0.3, learning_rate=0.15, max_depth=3, n_estimators=500;, score=0.850 total time=   6.8s\n",
      "[CV 5/5] END colsample_bytree=0.3, learning_rate=0.15, max_depth=3, n_estimators=500;, score=0.862 total time=   6.9s\n",
      "[CV 4/5] END colsample_bytree=0.3, learning_rate=0.15, max_depth=3, n_estimators=500;, score=0.848 total time=   6.9s\n",
      "[CV 1/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=None, n_estimators=900;, score=0.866 total time=  19.6s\n",
      "[CV 2/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=None, n_estimators=900;, score=0.870 total time=  19.2s\n",
      "[CV 3/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=None, n_estimators=900;, score=0.869 total time=  19.3s\n",
      "[CV 5/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=None, n_estimators=900;, score=0.863 total time=  19.2s\n",
      "[CV 4/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=None, n_estimators=900;, score=0.875 total time=  19.8s\n",
      "[CV 1/5] END colsample_bytree=0.3, learning_rate=0.15, max_depth=5, n_estimators=300;, score=0.858 total time=   5.7s\n",
      "[CV 2/5] END colsample_bytree=0.3, learning_rate=0.15, max_depth=5, n_estimators=300;, score=0.869 total time=   5.7s\n",
      "[CV 3/5] END colsample_bytree=0.3, learning_rate=0.15, max_depth=5, n_estimators=300;, score=0.851 total time=   5.8s\n",
      "[CV 5/5] END colsample_bytree=0.3, learning_rate=0.15, max_depth=5, n_estimators=300;, score=0.854 total time=   5.9s\n",
      "[CV 4/5] END colsample_bytree=0.3, learning_rate=0.15, max_depth=5, n_estimators=300;, score=0.867 total time=   5.8s\n",
      "[CV 2/5] END colsample_bytree=0.3, learning_rate=0.15, max_depth=3, n_estimators=900;, score=0.865 total time=  11.0s\n",
      "[CV 4/5] END colsample_bytree=0.3, learning_rate=0.15, max_depth=3, n_estimators=900;, score=0.865 total time=  11.2s\n",
      "[CV 3/5] END colsample_bytree=0.3, learning_rate=0.15, max_depth=3, n_estimators=900;, score=0.868 total time=  11.7s\n",
      "[CV 1/5] END colsample_bytree=0.3, learning_rate=0.15, max_depth=3, n_estimators=900;, score=0.845 total time=  12.4s\n",
      "[CV 5/5] END colsample_bytree=0.3, learning_rate=0.15, max_depth=3, n_estimators=900;, score=0.863 total time=  11.7s\n",
      "[CV 1/5] END colsample_bytree=0.3, learning_rate=0.15, max_depth=5, n_estimators=500;, score=0.869 total time=   9.4s\n",
      "[CV 2/5] END colsample_bytree=0.3, learning_rate=0.15, max_depth=5, n_estimators=500;, score=0.879 total time=   9.2s\n",
      "[CV 3/5] END colsample_bytree=0.3, learning_rate=0.15, max_depth=5, n_estimators=500;, score=0.868 total time=   8.9s\n",
      "[CV 4/5] END colsample_bytree=0.3, learning_rate=0.15, max_depth=5, n_estimators=500;, score=0.871 total time=   9.4s\n",
      "[CV 5/5] END colsample_bytree=0.3, learning_rate=0.15, max_depth=5, n_estimators=500;, score=0.858 total time=   9.2s\n",
      "[CV 1/5] END colsample_bytree=0.3, learning_rate=0.15, max_depth=7, n_estimators=300;, score=0.856 total time=   7.7s\n",
      "[CV 2/5] END colsample_bytree=0.3, learning_rate=0.15, max_depth=7, n_estimators=300;, score=0.863 total time=   7.7s\n",
      "[CV 3/5] END colsample_bytree=0.3, learning_rate=0.15, max_depth=7, n_estimators=300;, score=0.852 total time=   7.6s\n",
      "[CV 4/5] END colsample_bytree=0.3, learning_rate=0.15, max_depth=7, n_estimators=300;, score=0.851 total time=   7.6s\n",
      "[CV 5/5] END colsample_bytree=0.3, learning_rate=0.15, max_depth=7, n_estimators=300;, score=0.852 total time=   7.7s\n",
      "[CV 1/5] END colsample_bytree=0.3, learning_rate=0.15, max_depth=5, n_estimators=900;, score=0.872 total time=  16.7s\n",
      "[CV 3/5] END colsample_bytree=0.3, learning_rate=0.15, max_depth=5, n_estimators=900;, score=0.876 total time=  16.4s\n",
      "[CV 2/5] END colsample_bytree=0.3, learning_rate=0.15, max_depth=5, n_estimators=900;, score=0.877 total time=  17.0s\n",
      "[CV 5/5] END colsample_bytree=0.3, learning_rate=0.15, max_depth=5, n_estimators=900;, score=0.866 total time=  16.4s\n",
      "[CV 4/5] END colsample_bytree=0.3, learning_rate=0.15, max_depth=5, n_estimators=900;, score=0.872 total time=  16.8s\n",
      "[CV 1/5] END colsample_bytree=0.3, learning_rate=0.15, max_depth=7, n_estimators=500;, score=0.860 total time=  12.2s\n",
      "[CV 2/5] END colsample_bytree=0.3, learning_rate=0.15, max_depth=7, n_estimators=500;, score=0.873 total time=  12.4s\n",
      "[CV 3/5] END colsample_bytree=0.3, learning_rate=0.15, max_depth=7, n_estimators=500;, score=0.862 total time=  12.5s\n",
      "[CV 4/5] END colsample_bytree=0.3, learning_rate=0.15, max_depth=7, n_estimators=500;, score=0.861 total time=  12.5s\n",
      "[CV 5/5] END colsample_bytree=0.3, learning_rate=0.15, max_depth=7, n_estimators=500;, score=0.858 total time=  12.1s\n",
      "[CV 1/5] END colsample_bytree=0.3, learning_rate=0.15, max_depth=10, n_estimators=300;, score=0.839 total time=   9.2s\n",
      "[CV 2/5] END colsample_bytree=0.3, learning_rate=0.15, max_depth=10, n_estimators=300;, score=0.860 total time=   9.3s\n",
      "[CV 3/5] END colsample_bytree=0.3, learning_rate=0.15, max_depth=10, n_estimators=300;, score=0.844 total time=   9.4s\n",
      "[CV 4/5] END colsample_bytree=0.3, learning_rate=0.15, max_depth=10, n_estimators=300;, score=0.846 total time=   9.1s\n",
      "[CV 5/5] END colsample_bytree=0.3, learning_rate=0.15, max_depth=10, n_estimators=300;, score=0.858 total time=   9.2s\n",
      "[CV 1/5] END colsample_bytree=0.3, learning_rate=0.15, max_depth=7, n_estimators=900;, score=0.860 total time=  20.6s\n",
      "[CV 2/5] END colsample_bytree=0.3, learning_rate=0.15, max_depth=7, n_estimators=900;, score=0.873 total time=  20.8s\n",
      "[CV 3/5] END colsample_bytree=0.3, learning_rate=0.15, max_depth=7, n_estimators=900;, score=0.871 total time=  20.3s\n",
      "[CV 5/5] END colsample_bytree=0.3, learning_rate=0.15, max_depth=7, n_estimators=900;, score=0.858 total time=  20.4s\n",
      "[CV 4/5] END colsample_bytree=0.3, learning_rate=0.15, max_depth=7, n_estimators=900;, score=0.863 total time=  20.7s\n",
      "[CV 1/5] END colsample_bytree=0.3, learning_rate=0.15, max_depth=10, n_estimators=500;, score=0.848 total time=  13.4s\n",
      "[CV 2/5] END colsample_bytree=0.3, learning_rate=0.15, max_depth=10, n_estimators=500;, score=0.867 total time=  13.8s\n",
      "[CV 4/5] END colsample_bytree=0.3, learning_rate=0.15, max_depth=10, n_estimators=500;, score=0.851 total time=  13.5s\n",
      "[CV 3/5] END colsample_bytree=0.3, learning_rate=0.15, max_depth=10, n_estimators=500;, score=0.854 total time=  13.7s\n",
      "[CV 5/5] END colsample_bytree=0.3, learning_rate=0.15, max_depth=10, n_estimators=500;, score=0.858 total time=  13.8s\n",
      "[CV 1/5] END colsample_bytree=0.3, learning_rate=0.15, max_depth=None, n_estimators=300;, score=0.862 total time=   6.5s\n",
      "[CV 3/5] END colsample_bytree=0.3, learning_rate=0.15, max_depth=None, n_estimators=300;, score=0.857 total time=   6.5s\n",
      "[CV 2/5] END colsample_bytree=0.3, learning_rate=0.15, max_depth=None, n_estimators=300;, score=0.875 total time=   6.6s\n",
      "[CV 4/5] END colsample_bytree=0.3, learning_rate=0.15, max_depth=None, n_estimators=300;, score=0.869 total time=   6.8s\n",
      "[CV 5/5] END colsample_bytree=0.3, learning_rate=0.15, max_depth=None, n_estimators=300;, score=0.859 total time=   6.6s\n",
      "[CV 1/5] END colsample_bytree=0.3, learning_rate=0.15, max_depth=10, n_estimators=900;, score=0.854 total time=  21.5s\n",
      "[CV 3/5] END colsample_bytree=0.3, learning_rate=0.15, max_depth=10, n_estimators=900;, score=0.857 total time=  21.5s\n",
      "[CV 5/5] END colsample_bytree=0.3, learning_rate=0.15, max_depth=10, n_estimators=900;, score=0.859 total time=  21.4s\n",
      "[CV 2/5] END colsample_bytree=0.3, learning_rate=0.15, max_depth=10, n_estimators=900;, score=0.870 total time=  21.5s\n",
      "[CV 4/5] END colsample_bytree=0.3, learning_rate=0.15, max_depth=10, n_estimators=900;, score=0.848 total time=  21.7s\n",
      "[CV 1/5] END colsample_bytree=0.3, learning_rate=0.15, max_depth=None, n_estimators=500;, score=0.868 total time=  10.8s\n",
      "[CV 2/5] END colsample_bytree=0.3, learning_rate=0.15, max_depth=None, n_estimators=500;, score=0.876 total time=  10.9s\n",
      "[CV 3/5] END colsample_bytree=0.3, learning_rate=0.15, max_depth=None, n_estimators=500;, score=0.859 total time=  10.7s\n",
      "[CV 4/5] END colsample_bytree=0.3, learning_rate=0.15, max_depth=None, n_estimators=500;, score=0.874 total time=  10.9s\n",
      "[CV 5/5] END colsample_bytree=0.3, learning_rate=0.15, max_depth=None, n_estimators=500;, score=0.863 total time=  10.8s\n",
      "[CV 1/5] END colsample_bytree=0.3, learning_rate=0.2, max_depth=3, n_estimators=300;, score=0.819 total time=   4.3s\n",
      "[CV 2/5] END colsample_bytree=0.3, learning_rate=0.2, max_depth=3, n_estimators=300;, score=0.862 total time=   4.3s\n",
      "[CV 3/5] END colsample_bytree=0.3, learning_rate=0.2, max_depth=3, n_estimators=300;, score=0.802 total time=   4.3s\n",
      "[CV 4/5] END colsample_bytree=0.3, learning_rate=0.2, max_depth=3, n_estimators=300;, score=0.844 total time=   4.3s\n",
      "[CV 5/5] END colsample_bytree=0.3, learning_rate=0.2, max_depth=3, n_estimators=300;, score=0.851 total time=   4.5s\n",
      "[CV 1/5] END colsample_bytree=0.3, learning_rate=0.15, max_depth=None, n_estimators=900;, score=0.863 total time=  18.8s\n",
      "[CV 1/5] END colsample_bytree=0.3, learning_rate=0.2, max_depth=3, n_estimators=500;, score=0.840 total time=   6.5s\n",
      "[CV 2/5] END colsample_bytree=0.3, learning_rate=0.2, max_depth=3, n_estimators=500;, score=0.873 total time=   6.6s\n",
      "[CV 3/5] END colsample_bytree=0.3, learning_rate=0.2, max_depth=3, n_estimators=500;, score=0.835 total time=   6.8s\n",
      "[CV 5/5] END colsample_bytree=0.3, learning_rate=0.15, max_depth=None, n_estimators=900;, score=0.867 total time=  18.7s\n",
      "[CV 2/5] END colsample_bytree=0.3, learning_rate=0.15, max_depth=None, n_estimators=900;, score=0.878 total time=  19.2s\n",
      "[CV 3/5] END colsample_bytree=0.3, learning_rate=0.15, max_depth=None, n_estimators=900;, score=0.868 total time=  19.2s\n",
      "[CV 4/5] END colsample_bytree=0.3, learning_rate=0.15, max_depth=None, n_estimators=900;, score=0.867 total time=  19.1s\n",
      "[CV 4/5] END colsample_bytree=0.3, learning_rate=0.2, max_depth=3, n_estimators=500;, score=0.857 total time=   6.3s\n",
      "[CV 5/5] END colsample_bytree=0.3, learning_rate=0.2, max_depth=3, n_estimators=500;, score=0.866 total time=   6.6s\n",
      "[CV 1/5] END colsample_bytree=0.3, learning_rate=0.2, max_depth=5, n_estimators=300;, score=0.864 total time=   5.8s\n",
      "[CV 3/5] END colsample_bytree=0.3, learning_rate=0.2, max_depth=5, n_estimators=300;, score=0.863 total time=   5.8s\n",
      "[CV 2/5] END colsample_bytree=0.3, learning_rate=0.2, max_depth=5, n_estimators=300;, score=0.876 total time=   5.9s\n",
      "[CV 5/5] END colsample_bytree=0.3, learning_rate=0.2, max_depth=5, n_estimators=300;, score=0.867 total time=   5.8s\n",
      "[CV 4/5] END colsample_bytree=0.3, learning_rate=0.2, max_depth=5, n_estimators=300;, score=0.867 total time=   5.8s\n",
      "[CV 1/5] END colsample_bytree=0.3, learning_rate=0.2, max_depth=3, n_estimators=900;, score=0.853 total time=  11.5s\n",
      "[CV 2/5] END colsample_bytree=0.3, learning_rate=0.2, max_depth=3, n_estimators=900;, score=0.861 total time=  12.1s\n",
      "[CV 3/5] END colsample_bytree=0.3, learning_rate=0.2, max_depth=3, n_estimators=900;, score=0.850 total time=  11.6s\n",
      "[CV 4/5] END colsample_bytree=0.3, learning_rate=0.2, max_depth=3, n_estimators=900;, score=0.863 total time=  11.8s\n",
      "[CV 5/5] END colsample_bytree=0.3, learning_rate=0.2, max_depth=3, n_estimators=900;, score=0.872 total time=  11.9s\n",
      "[CV 1/5] END colsample_bytree=0.3, learning_rate=0.2, max_depth=5, n_estimators=500;, score=0.869 total time=   9.5s\n",
      "[CV 3/5] END colsample_bytree=0.3, learning_rate=0.2, max_depth=5, n_estimators=500;, score=0.867 total time=   9.3s\n",
      "[CV 2/5] END colsample_bytree=0.3, learning_rate=0.2, max_depth=5, n_estimators=500;, score=0.870 total time=   9.5s\n",
      "[CV 5/5] END colsample_bytree=0.3, learning_rate=0.2, max_depth=5, n_estimators=500;, score=0.869 total time=   9.4s\n",
      "[CV 4/5] END colsample_bytree=0.3, learning_rate=0.2, max_depth=5, n_estimators=500;, score=0.866 total time=   9.5s\n",
      "[CV 2/5] END colsample_bytree=0.3, learning_rate=0.2, max_depth=7, n_estimators=300;, score=0.870 total time=   7.8s\n",
      "[CV 1/5] END colsample_bytree=0.3, learning_rate=0.2, max_depth=7, n_estimators=300;, score=0.859 total time=   7.6s\n",
      "[CV 4/5] END colsample_bytree=0.3, learning_rate=0.2, max_depth=7, n_estimators=300;, score=0.856 total time=   7.7s\n",
      "[CV 3/5] END colsample_bytree=0.3, learning_rate=0.2, max_depth=7, n_estimators=300;, score=0.845 total time=   7.7s\n",
      "[CV 5/5] END colsample_bytree=0.3, learning_rate=0.2, max_depth=7, n_estimators=300;, score=0.851 total time=   7.9s\n",
      "[CV 2/5] END colsample_bytree=0.3, learning_rate=0.2, max_depth=5, n_estimators=900;, score=0.865 total time=  17.0s\n",
      "[CV 1/5] END colsample_bytree=0.3, learning_rate=0.2, max_depth=5, n_estimators=900;, score=0.870 total time=  16.8s\n",
      "[CV 3/5] END colsample_bytree=0.3, learning_rate=0.2, max_depth=5, n_estimators=900;, score=0.863 total time=  16.6s\n",
      "[CV 5/5] END colsample_bytree=0.3, learning_rate=0.2, max_depth=5, n_estimators=900;, score=0.869 total time=  16.3s\n",
      "[CV 4/5] END colsample_bytree=0.3, learning_rate=0.2, max_depth=5, n_estimators=900;, score=0.871 total time=  17.5s\n",
      "[CV 1/5] END colsample_bytree=0.3, learning_rate=0.2, max_depth=7, n_estimators=500;, score=0.863 total time=  11.9s\n",
      "[CV 4/5] END colsample_bytree=0.3, learning_rate=0.2, max_depth=7, n_estimators=500;, score=0.858 total time=  11.8s\n",
      "[CV 2/5] END colsample_bytree=0.3, learning_rate=0.2, max_depth=7, n_estimators=500;, score=0.873 total time=  12.2s\n",
      "[CV 3/5] END colsample_bytree=0.3, learning_rate=0.2, max_depth=7, n_estimators=500;, score=0.847 total time=  12.0s\n",
      "[CV 5/5] END colsample_bytree=0.3, learning_rate=0.2, max_depth=7, n_estimators=500;, score=0.853 total time=  11.8s\n",
      "[CV 1/5] END colsample_bytree=0.3, learning_rate=0.2, max_depth=10, n_estimators=300;, score=0.852 total time=   8.8s\n",
      "[CV 4/5] END colsample_bytree=0.3, learning_rate=0.2, max_depth=10, n_estimators=300;, score=0.852 total time=   8.9s\n",
      "[CV 2/5] END colsample_bytree=0.3, learning_rate=0.2, max_depth=10, n_estimators=300;, score=0.860 total time=   9.0s\n",
      "[CV 3/5] END colsample_bytree=0.3, learning_rate=0.2, max_depth=10, n_estimators=300;, score=0.854 total time=   9.0s\n",
      "[CV 5/5] END colsample_bytree=0.3, learning_rate=0.2, max_depth=10, n_estimators=300;, score=0.854 total time=   8.9s\n",
      "[CV 1/5] END colsample_bytree=0.3, learning_rate=0.2, max_depth=7, n_estimators=900;, score=0.861 total time=  19.6s\n",
      "[CV 2/5] END colsample_bytree=0.3, learning_rate=0.2, max_depth=7, n_estimators=900;, score=0.876 total time=  19.7s\n",
      "[CV 4/5] END colsample_bytree=0.3, learning_rate=0.2, max_depth=7, n_estimators=900;, score=0.866 total time=  19.6s\n",
      "[CV 3/5] END colsample_bytree=0.3, learning_rate=0.2, max_depth=7, n_estimators=900;, score=0.858 total time=  19.9s\n",
      "[CV 5/5] END colsample_bytree=0.3, learning_rate=0.2, max_depth=7, n_estimators=900;, score=0.863 total time=  19.4s\n",
      "[CV 1/5] END colsample_bytree=0.3, learning_rate=0.2, max_depth=10, n_estimators=500;, score=0.851 total time=  12.4s\n",
      "[CV 2/5] END colsample_bytree=0.3, learning_rate=0.2, max_depth=10, n_estimators=500;, score=0.856 total time=  12.8s\n",
      "[CV 3/5] END colsample_bytree=0.3, learning_rate=0.2, max_depth=10, n_estimators=500;, score=0.852 total time=  12.8s\n",
      "[CV 5/5] END colsample_bytree=0.3, learning_rate=0.2, max_depth=10, n_estimators=500;, score=0.849 total time=  12.7s\n",
      "[CV 4/5] END colsample_bytree=0.3, learning_rate=0.2, max_depth=10, n_estimators=500;, score=0.861 total time=  12.6s\n",
      "[CV 1/5] END colsample_bytree=0.3, learning_rate=0.2, max_depth=None, n_estimators=300;, score=0.855 total time=   6.8s\n",
      "[CV 2/5] END colsample_bytree=0.3, learning_rate=0.2, max_depth=None, n_estimators=300;, score=0.868 total time=   6.8s\n",
      "[CV 3/5] END colsample_bytree=0.3, learning_rate=0.2, max_depth=None, n_estimators=300;, score=0.866 total time=   6.9s\n",
      "[CV 4/5] END colsample_bytree=0.3, learning_rate=0.2, max_depth=None, n_estimators=300;, score=0.856 total time=   6.7s\n",
      "[CV 5/5] END colsample_bytree=0.3, learning_rate=0.2, max_depth=None, n_estimators=300;, score=0.855 total time=   6.6s\n",
      "[CV 1/5] END colsample_bytree=0.3, learning_rate=0.2, max_depth=10, n_estimators=900;, score=0.851 total time=  20.1s\n",
      "[CV 2/5] END colsample_bytree=0.3, learning_rate=0.2, max_depth=10, n_estimators=900;, score=0.858 total time=  20.5s\n",
      "[CV 3/5] END colsample_bytree=0.3, learning_rate=0.2, max_depth=10, n_estimators=900;, score=0.857 total time=  20.4s\n",
      "[CV 4/5] END colsample_bytree=0.3, learning_rate=0.2, max_depth=10, n_estimators=900;, score=0.857 total time=  20.4s\n",
      "[CV 5/5] END colsample_bytree=0.3, learning_rate=0.2, max_depth=10, n_estimators=900;, score=0.855 total time=  19.9s\n",
      "[CV 1/5] END colsample_bytree=0.3, learning_rate=0.2, max_depth=None, n_estimators=500;, score=0.860 total time=  10.8s\n",
      "[CV 3/5] END colsample_bytree=0.3, learning_rate=0.2, max_depth=None, n_estimators=500;, score=0.876 total time=  10.6s\n",
      "[CV 2/5] END colsample_bytree=0.3, learning_rate=0.2, max_depth=None, n_estimators=500;, score=0.864 total time=  10.7s\n",
      "[CV 4/5] END colsample_bytree=0.3, learning_rate=0.2, max_depth=None, n_estimators=500;, score=0.852 total time=  10.7s\n",
      "[CV 5/5] END colsample_bytree=0.3, learning_rate=0.2, max_depth=None, n_estimators=500;, score=0.860 total time=  10.5s\n",
      "[CV 1/5] END colsample_bytree=0.3, learning_rate=0.3, max_depth=3, n_estimators=300;, score=0.845 total time=   4.4s\n",
      "[CV 2/5] END colsample_bytree=0.3, learning_rate=0.3, max_depth=3, n_estimators=300;, score=0.858 total time=   4.3s\n",
      "[CV 3/5] END colsample_bytree=0.3, learning_rate=0.3, max_depth=3, n_estimators=300;, score=0.838 total time=   4.3s\n",
      "[CV 4/5] END colsample_bytree=0.3, learning_rate=0.3, max_depth=3, n_estimators=300;, score=0.858 total time=   4.4s\n",
      "[CV 5/5] END colsample_bytree=0.3, learning_rate=0.3, max_depth=3, n_estimators=300;, score=0.856 total time=   4.4s\n",
      "[CV 1/5] END colsample_bytree=0.3, learning_rate=0.3, max_depth=3, n_estimators=500;, score=0.856 total time=   6.9s\n",
      "[CV 1/5] END colsample_bytree=0.3, learning_rate=0.2, max_depth=None, n_estimators=900;, score=0.864 total time=  18.2s\n",
      "[CV 2/5] END colsample_bytree=0.3, learning_rate=0.3, max_depth=3, n_estimators=500;, score=0.873 total time=   6.6s\n",
      "[CV 2/5] END colsample_bytree=0.3, learning_rate=0.2, max_depth=None, n_estimators=900;, score=0.864 total time=  18.8s\n",
      "[CV 3/5] END colsample_bytree=0.3, learning_rate=0.3, max_depth=3, n_estimators=500;, score=0.858 total time=   6.8s\n",
      "[CV 4/5] END colsample_bytree=0.3, learning_rate=0.3, max_depth=3, n_estimators=500;, score=0.860 total time=   6.8s\n",
      "[CV 3/5] END colsample_bytree=0.3, learning_rate=0.2, max_depth=None, n_estimators=900;, score=0.873 total time=  18.7s\n",
      "[CV 5/5] END colsample_bytree=0.3, learning_rate=0.3, max_depth=3, n_estimators=500;, score=0.848 total time=   6.7s\n",
      "[CV 4/5] END colsample_bytree=0.3, learning_rate=0.2, max_depth=None, n_estimators=900;, score=0.865 total time=  18.8s\n",
      "[CV 5/5] END colsample_bytree=0.3, learning_rate=0.2, max_depth=None, n_estimators=900;, score=0.852 total time=  18.5s\n",
      "[CV 2/5] END colsample_bytree=0.3, learning_rate=0.3, max_depth=5, n_estimators=300;, score=0.878 total time=   5.7s\n",
      "[CV 3/5] END colsample_bytree=0.3, learning_rate=0.3, max_depth=5, n_estimators=300;, score=0.855 total time=   5.9s\n",
      "[CV 1/5] END colsample_bytree=0.3, learning_rate=0.3, max_depth=5, n_estimators=300;, score=0.858 total time=   6.0s\n",
      "[CV 5/5] END colsample_bytree=0.3, learning_rate=0.3, max_depth=5, n_estimators=300;, score=0.855 total time=   5.9s\n",
      "[CV 4/5] END colsample_bytree=0.3, learning_rate=0.3, max_depth=5, n_estimators=300;, score=0.863 total time=   5.8s\n",
      "[CV 1/5] END colsample_bytree=0.3, learning_rate=0.3, max_depth=3, n_estimators=900;, score=0.856 total time=  11.9s\n",
      "[CV 3/5] END colsample_bytree=0.3, learning_rate=0.3, max_depth=3, n_estimators=900;, score=0.860 total time=  11.9s\n",
      "[CV 2/5] END colsample_bytree=0.3, learning_rate=0.3, max_depth=3, n_estimators=900;, score=0.882 total time=  11.4s\n",
      "[CV 4/5] END colsample_bytree=0.3, learning_rate=0.3, max_depth=3, n_estimators=900;, score=0.864 total time=  11.9s\n",
      "[CV 5/5] END colsample_bytree=0.3, learning_rate=0.3, max_depth=3, n_estimators=900;, score=0.851 total time=  11.8s\n",
      "[CV 1/5] END colsample_bytree=0.3, learning_rate=0.3, max_depth=5, n_estimators=500;, score=0.862 total time=   9.4s\n",
      "[CV 2/5] END colsample_bytree=0.3, learning_rate=0.3, max_depth=5, n_estimators=500;, score=0.880 total time=   9.5s\n",
      "[CV 3/5] END colsample_bytree=0.3, learning_rate=0.3, max_depth=5, n_estimators=500;, score=0.862 total time=   9.7s\n",
      "[CV 5/5] END colsample_bytree=0.3, learning_rate=0.3, max_depth=5, n_estimators=500;, score=0.861 total time=   9.3s\n",
      "[CV 4/5] END colsample_bytree=0.3, learning_rate=0.3, max_depth=5, n_estimators=500;, score=0.870 total time=   9.7s\n",
      "[CV 1/5] END colsample_bytree=0.3, learning_rate=0.3, max_depth=7, n_estimators=300;, score=0.840 total time=   7.5s\n",
      "[CV 5/5] END colsample_bytree=0.3, learning_rate=0.3, max_depth=7, n_estimators=300;, score=0.856 total time=   7.5s\n",
      "[CV 4/5] END colsample_bytree=0.3, learning_rate=0.3, max_depth=7, n_estimators=300;, score=0.868 total time=   7.6s\n",
      "[CV 2/5] END colsample_bytree=0.3, learning_rate=0.3, max_depth=7, n_estimators=300;, score=0.865 total time=   7.6s\n",
      "[CV 3/5] END colsample_bytree=0.3, learning_rate=0.3, max_depth=7, n_estimators=300;, score=0.856 total time=   7.4s\n",
      "[CV 1/5] END colsample_bytree=0.3, learning_rate=0.3, max_depth=5, n_estimators=900;, score=0.854 total time=  16.6s\n",
      "[CV 2/5] END colsample_bytree=0.3, learning_rate=0.3, max_depth=5, n_estimators=900;, score=0.882 total time=  16.9s\n",
      "[CV 3/5] END colsample_bytree=0.3, learning_rate=0.3, max_depth=5, n_estimators=900;, score=0.862 total time=  16.4s\n",
      "[CV 4/5] END colsample_bytree=0.3, learning_rate=0.3, max_depth=5, n_estimators=900;, score=0.869 total time=  16.4s\n",
      "[CV 5/5] END colsample_bytree=0.3, learning_rate=0.3, max_depth=5, n_estimators=900;, score=0.859 total time=  16.3s\n",
      "[CV 1/5] END colsample_bytree=0.3, learning_rate=0.3, max_depth=7, n_estimators=500;, score=0.840 total time=  11.3s\n",
      "[CV 2/5] END colsample_bytree=0.3, learning_rate=0.3, max_depth=7, n_estimators=500;, score=0.867 total time=  11.3s\n",
      "[CV 3/5] END colsample_bytree=0.3, learning_rate=0.3, max_depth=7, n_estimators=500;, score=0.858 total time=  11.3s\n",
      "[CV 5/5] END colsample_bytree=0.3, learning_rate=0.3, max_depth=7, n_estimators=500;, score=0.858 total time=  11.3s\n",
      "[CV 4/5] END colsample_bytree=0.3, learning_rate=0.3, max_depth=7, n_estimators=500;, score=0.868 total time=  11.5s\n",
      "[CV 1/5] END colsample_bytree=0.3, learning_rate=0.3, max_depth=10, n_estimators=300;, score=0.845 total time=   8.3s\n",
      "[CV 2/5] END colsample_bytree=0.3, learning_rate=0.3, max_depth=10, n_estimators=300;, score=0.858 total time=   8.3s\n",
      "[CV 3/5] END colsample_bytree=0.3, learning_rate=0.3, max_depth=10, n_estimators=300;, score=0.838 total time=   8.3s\n",
      "[CV 4/5] END colsample_bytree=0.3, learning_rate=0.3, max_depth=10, n_estimators=300;, score=0.847 total time=   8.2s\n",
      "[CV 5/5] END colsample_bytree=0.3, learning_rate=0.3, max_depth=10, n_estimators=300;, score=0.849 total time=   8.1s\n",
      "[CV 1/5] END colsample_bytree=0.3, learning_rate=0.3, max_depth=7, n_estimators=900;, score=0.842 total time=  18.3s\n",
      "[CV 2/5] END colsample_bytree=0.3, learning_rate=0.3, max_depth=7, n_estimators=900;, score=0.868 total time=  18.3s\n",
      "[CV 3/5] END colsample_bytree=0.3, learning_rate=0.3, max_depth=7, n_estimators=900;, score=0.864 total time=  18.3s\n",
      "[CV 4/5] END colsample_bytree=0.3, learning_rate=0.3, max_depth=7, n_estimators=900;, score=0.873 total time=  18.4s\n",
      "[CV 5/5] END colsample_bytree=0.3, learning_rate=0.3, max_depth=7, n_estimators=900;, score=0.860 total time=  18.3s\n",
      "[CV 1/5] END colsample_bytree=0.3, learning_rate=0.3, max_depth=10, n_estimators=500;, score=0.848 total time=  11.8s\n",
      "[CV 2/5] END colsample_bytree=0.3, learning_rate=0.3, max_depth=10, n_estimators=500;, score=0.860 total time=  11.8s\n",
      "[CV 3/5] END colsample_bytree=0.3, learning_rate=0.3, max_depth=10, n_estimators=500;, score=0.842 total time=  12.1s\n",
      "[CV 5/5] END colsample_bytree=0.3, learning_rate=0.3, max_depth=10, n_estimators=500;, score=0.848 total time=  11.6s\n",
      "[CV 4/5] END colsample_bytree=0.3, learning_rate=0.3, max_depth=10, n_estimators=500;, score=0.854 total time=  11.8s\n",
      "[CV 1/5] END colsample_bytree=0.3, learning_rate=0.3, max_depth=None, n_estimators=300;, score=0.850 total time=   6.8s\n",
      "[CV 2/5] END colsample_bytree=0.3, learning_rate=0.3, max_depth=None, n_estimators=300;, score=0.880 total time=   6.8s\n",
      "[CV 3/5] END colsample_bytree=0.3, learning_rate=0.3, max_depth=None, n_estimators=300;, score=0.854 total time=   6.8s\n",
      "[CV 5/5] END colsample_bytree=0.3, learning_rate=0.3, max_depth=None, n_estimators=300;, score=0.848 total time=   6.6s\n",
      "[CV 4/5] END colsample_bytree=0.3, learning_rate=0.3, max_depth=None, n_estimators=300;, score=0.857 total time=   6.7s\n",
      "[CV 1/5] END colsample_bytree=0.3, learning_rate=0.3, max_depth=10, n_estimators=900;, score=0.848 total time=  18.5s\n",
      "[CV 2/5] END colsample_bytree=0.3, learning_rate=0.3, max_depth=10, n_estimators=900;, score=0.856 total time=  18.9s\n",
      "[CV 4/5] END colsample_bytree=0.3, learning_rate=0.3, max_depth=10, n_estimators=900;, score=0.858 total time=  18.4s\n",
      "[CV 3/5] END colsample_bytree=0.3, learning_rate=0.3, max_depth=10, n_estimators=900;, score=0.843 total time=  19.0s\n",
      "[CV 5/5] END colsample_bytree=0.3, learning_rate=0.3, max_depth=10, n_estimators=900;, score=0.851 total time=  18.7s\n",
      "[CV 1/5] END colsample_bytree=0.3, learning_rate=0.3, max_depth=None, n_estimators=500;, score=0.856 total time=  10.6s\n",
      "[CV 2/5] END colsample_bytree=0.3, learning_rate=0.3, max_depth=None, n_estimators=500;, score=0.877 total time=  10.5s\n",
      "[CV 3/5] END colsample_bytree=0.3, learning_rate=0.3, max_depth=None, n_estimators=500;, score=0.863 total time=  10.8s\n",
      "[CV 4/5] END colsample_bytree=0.3, learning_rate=0.3, max_depth=None, n_estimators=500;, score=0.870 total time=  10.9s\n",
      "[CV 5/5] END colsample_bytree=0.3, learning_rate=0.3, max_depth=None, n_estimators=500;, score=0.854 total time=  10.6s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=300;, score=0.811 total time=   4.4s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=300;, score=0.799 total time=   4.3s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=300;, score=0.826 total time=   4.4s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=300;, score=0.815 total time=   4.4s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=300;, score=0.817 total time=   4.3s\n",
      "[CV 1/5] END colsample_bytree=0.3, learning_rate=0.3, max_depth=None, n_estimators=900;, score=0.854 total time=  17.5s\n",
      "[CV 2/5] END colsample_bytree=0.3, learning_rate=0.3, max_depth=None, n_estimators=900;, score=0.881 total time=  18.1s\n",
      "[CV 3/5] END colsample_bytree=0.3, learning_rate=0.3, max_depth=None, n_estimators=900;, score=0.868 total time=  18.2s\n",
      "[CV 5/5] END colsample_bytree=0.3, learning_rate=0.3, max_depth=None, n_estimators=900;, score=0.850 total time=  17.9s\n",
      "[CV 4/5] END colsample_bytree=0.3, learning_rate=0.3, max_depth=None, n_estimators=900;, score=0.864 total time=  18.3s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=500;, score=0.831 total time=   6.7s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=500;, score=0.857 total time=   6.9s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=500;, score=0.848 total time=   6.6s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=500;, score=0.817 total time=   6.8s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=500;, score=0.839 total time=   6.5s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=300;, score=0.858 total time=   5.9s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=300;, score=0.868 total time=   5.7s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=300;, score=0.870 total time=   5.7s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=300;, score=0.865 total time=   5.6s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=300;, score=0.863 total time=   5.6s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=900;, score=0.859 total time=  11.7s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=900;, score=0.851 total time=  12.1s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=900;, score=0.864 total time=  11.6s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=900;, score=0.869 total time=  12.0s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=900;, score=0.859 total time=  11.8s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=500;, score=0.872 total time=   9.3s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=500;, score=0.865 total time=   9.4s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=500;, score=0.878 total time=   9.2s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=500;, score=0.873 total time=   9.2s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=500;, score=0.881 total time=   9.2s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=300;, score=0.871 total time=   7.3s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=300;, score=0.861 total time=   7.4s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=300;, score=0.877 total time=   7.4s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=300;, score=0.872 total time=   7.4s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=300;, score=0.867 total time=   7.5s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=900;, score=0.863 total time=  17.5s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=900;, score=0.874 total time=  17.1s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=900;, score=0.876 total time=  16.7s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=900;, score=0.879 total time=  16.5s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=900;, score=0.885 total time=  16.8s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=500;, score=0.867 total time=  12.1s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=500;, score=0.868 total time=  12.2s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=500;, score=0.862 total time=  12.0s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=500;, score=0.876 total time=  12.4s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=500;, score=0.881 total time=  12.4s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=10, n_estimators=300;, score=0.856 total time=   9.0s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=10, n_estimators=300;, score=0.862 total time=   9.2s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=10, n_estimators=300;, score=0.857 total time=   9.2s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=10, n_estimators=300;, score=0.866 total time=   9.0s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=10, n_estimators=300;, score=0.867 total time=   9.1s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=900;, score=0.868 total time=  21.1s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=900;, score=0.867 total time=  21.2s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=900;, score=0.871 total time=  20.7s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=900;, score=0.881 total time=  21.2s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=900;, score=0.876 total time=  21.5s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=10, n_estimators=500;, score=0.864 total time=  13.7s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=10, n_estimators=500;, score=0.858 total time=  13.8s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=10, n_estimators=500;, score=0.863 total time=  14.0s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=10, n_estimators=500;, score=0.864 total time=  13.9s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=10, n_estimators=500;, score=0.866 total time=  13.5s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=None, n_estimators=300;, score=0.870 total time=   6.5s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=None, n_estimators=300;, score=0.868 total time=   6.6s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=None, n_estimators=300;, score=0.878 total time=   6.6s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=None, n_estimators=300;, score=0.877 total time=   6.7s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=None, n_estimators=300;, score=0.875 total time=   6.5s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=10, n_estimators=900;, score=0.860 total time=  22.2s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=10, n_estimators=900;, score=0.865 total time=  22.5s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=10, n_estimators=900;, score=0.866 total time=  22.4s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=10, n_estimators=900;, score=0.867 total time=  22.1s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=10, n_estimators=900;, score=0.870 total time=  22.5s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=None, n_estimators=500;, score=0.872 total time=  10.6s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=None, n_estimators=500;, score=0.867 total time=  10.5s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=None, n_estimators=500;, score=0.884 total time=  10.5s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=None, n_estimators=500;, score=0.881 total time=  10.7s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=None, n_estimators=500;, score=0.880 total time=  10.4s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.15, max_depth=3, n_estimators=300;, score=0.827 total time=   4.3s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.15, max_depth=3, n_estimators=300;, score=0.848 total time=   4.3s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.15, max_depth=3, n_estimators=300;, score=0.817 total time=   4.4s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.15, max_depth=3, n_estimators=300;, score=0.847 total time=   4.4s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.15, max_depth=3, n_estimators=300;, score=0.857 total time=   4.5s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.15, max_depth=3, n_estimators=500;, score=0.852 total time=   6.7s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.15, max_depth=3, n_estimators=500;, score=0.842 total time=   6.6s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.15, max_depth=3, n_estimators=500;, score=0.861 total time=   6.8s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.15, max_depth=3, n_estimators=500;, score=0.869 total time=   6.8s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.15, max_depth=3, n_estimators=500;, score=0.848 total time=   6.8s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=None, n_estimators=900;, score=0.866 total time=  18.6s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=None, n_estimators=900;, score=0.878 total time=  18.4s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=None, n_estimators=900;, score=0.881 total time=  19.0s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=None, n_estimators=900;, score=0.863 total time=  19.4s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=None, n_estimators=900;, score=0.884 total time=  19.2s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.15, max_depth=5, n_estimators=300;, score=0.874 total time=   5.8s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.15, max_depth=5, n_estimators=300;, score=0.865 total time=   5.7s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.15, max_depth=5, n_estimators=300;, score=0.882 total time=   5.6s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.15, max_depth=5, n_estimators=300;, score=0.874 total time=   5.7s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.15, max_depth=5, n_estimators=300;, score=0.873 total time=   5.7s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.15, max_depth=3, n_estimators=900;, score=0.865 total time=  11.5s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.15, max_depth=3, n_estimators=900;, score=0.862 total time=  11.5s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.15, max_depth=3, n_estimators=900;, score=0.868 total time=  11.3s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.15, max_depth=3, n_estimators=900;, score=0.871 total time=  11.6s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.15, max_depth=3, n_estimators=900;, score=0.887 total time=  11.9s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.15, max_depth=5, n_estimators=500;, score=0.870 total time=   9.3s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.15, max_depth=5, n_estimators=500;, score=0.869 total time=   9.2s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.15, max_depth=5, n_estimators=500;, score=0.883 total time=   9.4s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.15, max_depth=5, n_estimators=500;, score=0.881 total time=   9.4s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.15, max_depth=5, n_estimators=500;, score=0.874 total time=   9.4s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.15, max_depth=7, n_estimators=300;, score=0.869 total time=   7.4s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.15, max_depth=7, n_estimators=300;, score=0.878 total time=   7.6s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.15, max_depth=7, n_estimators=300;, score=0.880 total time=   7.7s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.15, max_depth=7, n_estimators=300;, score=0.870 total time=   7.5s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.15, max_depth=7, n_estimators=300;, score=0.879 total time=   7.6s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.15, max_depth=5, n_estimators=900;, score=0.881 total time=  16.9s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.15, max_depth=5, n_estimators=900;, score=0.868 total time=  17.3s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.15, max_depth=5, n_estimators=900;, score=0.875 total time=  16.9s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.15, max_depth=5, n_estimators=900;, score=0.872 total time=  16.3s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.15, max_depth=5, n_estimators=900;, score=0.878 total time=  16.9s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.15, max_depth=7, n_estimators=500;, score=0.866 total time=  11.8s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.15, max_depth=7, n_estimators=500;, score=0.872 total time=  12.1s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.15, max_depth=7, n_estimators=500;, score=0.872 total time=  11.9s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.15, max_depth=7, n_estimators=500;, score=0.883 total time=  11.9s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.15, max_depth=7, n_estimators=500;, score=0.877 total time=  12.1s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.15, max_depth=10, n_estimators=300;, score=0.863 total time=   8.7s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.15, max_depth=10, n_estimators=300;, score=0.868 total time=   8.6s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.15, max_depth=10, n_estimators=300;, score=0.854 total time=   8.6s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.15, max_depth=10, n_estimators=300;, score=0.862 total time=   8.6s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.15, max_depth=10, n_estimators=300;, score=0.862 total time=   8.6s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.15, max_depth=7, n_estimators=900;, score=0.864 total time=  19.7s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.15, max_depth=7, n_estimators=900;, score=0.873 total time=  20.0s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.15, max_depth=7, n_estimators=900;, score=0.877 total time=  20.0s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.15, max_depth=7, n_estimators=900;, score=0.881 total time=  19.8s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.15, max_depth=7, n_estimators=900;, score=0.874 total time=  19.6s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.15, max_depth=10, n_estimators=500;, score=0.861 total time=  12.5s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.15, max_depth=10, n_estimators=500;, score=0.869 total time=  12.4s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.15, max_depth=10, n_estimators=500;, score=0.863 total time=  12.9s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.15, max_depth=10, n_estimators=500;, score=0.865 total time=  13.4s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.15, max_depth=10, n_estimators=500;, score=0.862 total time=  13.0s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.15, max_depth=None, n_estimators=300;, score=0.867 total time=   6.7s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.15, max_depth=None, n_estimators=300;, score=0.877 total time=   6.6s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.15, max_depth=None, n_estimators=300;, score=0.876 total time=   6.7s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.15, max_depth=None, n_estimators=300;, score=0.882 total time=   6.6s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.15, max_depth=None, n_estimators=300;, score=0.856 total time=   6.6s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.15, max_depth=10, n_estimators=900;, score=0.859 total time=  20.3s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.15, max_depth=10, n_estimators=900;, score=0.864 total time=  20.4s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.15, max_depth=10, n_estimators=900;, score=0.874 total time=  20.4s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.15, max_depth=10, n_estimators=900;, score=0.866 total time=  20.7s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.15, max_depth=10, n_estimators=900;, score=0.865 total time=  20.8s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.15, max_depth=None, n_estimators=500;, score=0.868 total time=  10.9s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.15, max_depth=None, n_estimators=500;, score=0.873 total time=  10.9s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.15, max_depth=None, n_estimators=500;, score=0.876 total time=  11.0s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.15, max_depth=None, n_estimators=500;, score=0.858 total time=  10.8s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.15, max_depth=None, n_estimators=500;, score=0.881 total time=  10.9s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=300;, score=0.843 total time=   4.3s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=300;, score=0.855 total time=   4.1s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=300;, score=0.850 total time=   4.2s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=300;, score=0.847 total time=   4.3s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=300;, score=0.863 total time=   4.3s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=500;, score=0.859 total time=   6.8s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.15, max_depth=None, n_estimators=900;, score=0.874 total time=  18.5s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=500;, score=0.866 total time=   6.5s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.15, max_depth=None, n_estimators=900;, score=0.879 total time=  18.8s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.15, max_depth=None, n_estimators=900;, score=0.864 total time=  18.7s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.15, max_depth=None, n_estimators=900;, score=0.868 total time=  19.1s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.15, max_depth=None, n_estimators=900;, score=0.881 total time=  19.2s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=500;, score=0.863 total time=   6.6s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=500;, score=0.874 total time=   6.6s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=500;, score=0.866 total time=   6.7s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=300;, score=0.879 total time=   5.9s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=300;, score=0.866 total time=   5.9s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=300;, score=0.888 total time=   5.9s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=300;, score=0.879 total time=   5.7s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=300;, score=0.868 total time=   5.8s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=900;, score=0.864 total time=  11.4s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=900;, score=0.881 total time=  11.6s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=900;, score=0.876 total time=  12.0s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=900;, score=0.864 total time=  11.9s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=900;, score=0.880 total time=  12.1s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=500;, score=0.879 total time=   9.6s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=500;, score=0.864 total time=   9.6s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=500;, score=0.883 total time=   9.7s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=500;, score=0.880 total time=   9.6s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=500;, score=0.877 total time=   9.6s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=7, n_estimators=300;, score=0.859 total time=   7.7s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=7, n_estimators=300;, score=0.871 total time=   7.5s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=7, n_estimators=300;, score=0.868 total time=   7.7s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=7, n_estimators=300;, score=0.871 total time=   7.6s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=7, n_estimators=300;, score=0.876 total time=   7.5s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=900;, score=0.868 total time=  17.1s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=900;, score=0.882 total time=  17.1s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=900;, score=0.873 total time=  16.9s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=900;, score=0.879 total time=  17.1s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=900;, score=0.877 total time=  16.5s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=7, n_estimators=500;, score=0.858 total time=  11.5s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=7, n_estimators=500;, score=0.873 total time=  11.8s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=7, n_estimators=500;, score=0.873 total time=  11.7s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=7, n_estimators=500;, score=0.866 total time=  11.9s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=7, n_estimators=500;, score=0.882 total time=  11.7s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=10, n_estimators=300;, score=0.862 total time=   8.3s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=10, n_estimators=300;, score=0.870 total time=   8.1s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=10, n_estimators=300;, score=0.862 total time=   8.4s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=10, n_estimators=300;, score=0.869 total time=   8.3s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=10, n_estimators=300;, score=0.857 total time=   8.3s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=7, n_estimators=900;, score=0.857 total time=  18.8s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=7, n_estimators=900;, score=0.875 total time=  18.8s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=7, n_estimators=900;, score=0.880 total time=  18.5s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=7, n_estimators=900;, score=0.870 total time=  19.0s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=7, n_estimators=900;, score=0.869 total time=  18.6s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=10, n_estimators=500;, score=0.864 total time=  12.0s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=10, n_estimators=500;, score=0.874 total time=  12.0s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=10, n_estimators=500;, score=0.864 total time=  12.2s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=10, n_estimators=500;, score=0.873 total time=  12.2s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=10, n_estimators=500;, score=0.865 total time=  12.1s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=None, n_estimators=300;, score=0.869 total time=   6.6s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=None, n_estimators=300;, score=0.865 total time=   6.7s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=None, n_estimators=300;, score=0.879 total time=   6.8s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=None, n_estimators=300;, score=0.883 total time=   6.6s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=None, n_estimators=300;, score=0.872 total time=   6.7s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=10, n_estimators=900;, score=0.864 total time=  19.2s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=10, n_estimators=900;, score=0.874 total time=  19.1s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=10, n_estimators=900;, score=0.871 total time=  19.2s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=10, n_estimators=900;, score=0.869 total time=  19.0s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=10, n_estimators=900;, score=0.865 total time=  18.8s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=None, n_estimators=500;, score=0.867 total time=  10.6s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=None, n_estimators=500;, score=0.869 total time=  10.8s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=None, n_estimators=500;, score=0.878 total time=  10.9s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=None, n_estimators=500;, score=0.872 total time=  10.7s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=None, n_estimators=500;, score=0.880 total time=  11.0s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, n_estimators=300;, score=0.853 total time=   4.3s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, n_estimators=300;, score=0.864 total time=   4.4s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, n_estimators=300;, score=0.858 total time=   4.4s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, n_estimators=300;, score=0.860 total time=   4.4s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, n_estimators=300;, score=0.875 total time=   4.5s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=None, n_estimators=900;, score=0.871 total time=  18.2s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=None, n_estimators=900;, score=0.866 total time=  18.2s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, n_estimators=500;, score=0.860 total time=   6.6s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=None, n_estimators=900;, score=0.885 total time=  18.2s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=None, n_estimators=900;, score=0.876 total time=  18.6s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, n_estimators=500;, score=0.866 total time=   6.5s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.2, max_depth=None, n_estimators=900;, score=0.872 total time=  18.0s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, n_estimators=500;, score=0.871 total time=   6.4s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, n_estimators=500;, score=0.869 total time=   6.6s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, n_estimators=500;, score=0.864 total time=   6.5s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=5, n_estimators=300;, score=0.872 total time=   6.1s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=5, n_estimators=300;, score=0.877 total time=   6.1s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=5, n_estimators=300;, score=0.885 total time=   5.9s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=5, n_estimators=300;, score=0.870 total time=   6.1s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=5, n_estimators=300;, score=0.868 total time=   6.0s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, n_estimators=900;, score=0.869 total time=  11.8s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, n_estimators=900;, score=0.876 total time=  11.7s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, n_estimators=900;, score=0.868 total time=  12.1s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, n_estimators=900;, score=0.869 total time=  12.1s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, n_estimators=900;, score=0.868 total time=  12.0s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=5, n_estimators=500;, score=0.872 total time=   9.6s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=5, n_estimators=500;, score=0.871 total time=   9.9s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=5, n_estimators=500;, score=0.883 total time=   9.6s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=5, n_estimators=500;, score=0.870 total time=   9.4s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=5, n_estimators=500;, score=0.868 total time=   9.8s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=7, n_estimators=300;, score=0.874 total time=   7.3s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=7, n_estimators=300;, score=0.860 total time=   7.4s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=7, n_estimators=300;, score=0.867 total time=   7.4s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=7, n_estimators=300;, score=0.867 total time=   7.2s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=7, n_estimators=300;, score=0.873 total time=   7.5s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=5, n_estimators=900;, score=0.864 total time=  16.6s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=5, n_estimators=900;, score=0.878 total time=  16.6s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=5, n_estimators=900;, score=0.872 total time=  17.0s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=5, n_estimators=900;, score=0.864 total time=  17.0s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=5, n_estimators=900;, score=0.866 total time=  16.3s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=7, n_estimators=500;, score=0.872 total time=  10.9s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=7, n_estimators=500;, score=0.865 total time=  11.3s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=7, n_estimators=500;, score=0.867 total time=  11.2s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=7, n_estimators=500;, score=0.875 total time=  11.1s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=7, n_estimators=500;, score=0.867 total time=  11.2s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=10, n_estimators=300;, score=0.861 total time=   7.6s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=10, n_estimators=300;, score=0.867 total time=   8.0s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=10, n_estimators=300;, score=0.868 total time=   7.8s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=10, n_estimators=300;, score=0.870 total time=   7.6s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=10, n_estimators=300;, score=0.852 total time=   7.7s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=7, n_estimators=900;, score=0.872 total time=  17.3s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=7, n_estimators=900;, score=0.863 total time=  17.9s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=7, n_estimators=900;, score=0.871 total time=  17.9s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=7, n_estimators=900;, score=0.871 total time=  18.0s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=7, n_estimators=900;, score=0.869 total time=  17.4s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=10, n_estimators=500;, score=0.863 total time=  11.2s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=10, n_estimators=500;, score=0.867 total time=  11.2s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=10, n_estimators=500;, score=0.868 total time=  11.3s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=10, n_estimators=500;, score=0.872 total time=  11.3s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=10, n_estimators=500;, score=0.855 total time=  11.3s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=None, n_estimators=300;, score=0.867 total time=   6.8s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=None, n_estimators=300;, score=0.872 total time=   6.8s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=None, n_estimators=300;, score=0.874 total time=   6.9s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=None, n_estimators=300;, score=0.874 total time=   6.8s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=10, n_estimators=900;, score=0.866 total time=  17.5s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=None, n_estimators=300;, score=0.872 total time=   6.6s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=10, n_estimators=900;, score=0.869 total time=  18.0s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=10, n_estimators=900;, score=0.868 total time=  18.0s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=10, n_estimators=900;, score=0.852 total time=  17.7s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=10, n_estimators=900;, score=0.870 total time=  17.8s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=None, n_estimators=500;, score=0.865 total time=  10.5s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=None, n_estimators=500;, score=0.870 total time=  10.6s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=None, n_estimators=500;, score=0.884 total time=  10.6s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=None, n_estimators=500;, score=0.875 total time=  10.8s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=None, n_estimators=500;, score=0.869 total time=  10.8s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.1, max_depth=3, n_estimators=300;, score=0.818 total time=   4.3s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.1, max_depth=3, n_estimators=300;, score=0.831 total time=   4.1s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.1, max_depth=3, n_estimators=300;, score=0.790 total time=   4.3s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.1, max_depth=3, n_estimators=300;, score=0.829 total time=   4.3s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.1, max_depth=3, n_estimators=300;, score=0.819 total time=   4.3s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=None, n_estimators=900;, score=0.863 total time=  17.4s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=None, n_estimators=900;, score=0.872 total time=  17.6s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=None, n_estimators=900;, score=0.881 total time=  17.5s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=None, n_estimators=900;, score=0.871 total time=  17.2s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.3, max_depth=None, n_estimators=900;, score=0.875 total time=  17.7s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.1, max_depth=3, n_estimators=500;, score=0.827 total time=   6.7s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.1, max_depth=3, n_estimators=500;, score=0.854 total time=   6.3s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.1, max_depth=3, n_estimators=500;, score=0.825 total time=   6.3s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.1, max_depth=3, n_estimators=500;, score=0.845 total time=   6.5s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.1, max_depth=3, n_estimators=500;, score=0.850 total time=   6.5s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=300;, score=0.851 total time=   5.8s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=300;, score=0.869 total time=   5.6s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=300;, score=0.862 total time=   5.6s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=300;, score=0.868 total time=   5.6s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=300;, score=0.860 total time=   5.8s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.1, max_depth=3, n_estimators=900;, score=0.856 total time=  11.7s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.1, max_depth=3, n_estimators=900;, score=0.876 total time=  11.4s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.1, max_depth=3, n_estimators=900;, score=0.875 total time=  11.6s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.1, max_depth=3, n_estimators=900;, score=0.868 total time=  11.7s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.1, max_depth=3, n_estimators=900;, score=0.865 total time=  11.9s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=500;, score=0.873 total time=   9.3s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=500;, score=0.872 total time=   9.3s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=500;, score=0.885 total time=   9.3s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=500;, score=0.886 total time=   9.4s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=500;, score=0.868 total time=   9.2s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.1, max_depth=7, n_estimators=300;, score=0.873 total time=   7.2s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.1, max_depth=7, n_estimators=300;, score=0.874 total time=   7.3s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.1, max_depth=7, n_estimators=300;, score=0.878 total time=   7.2s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.1, max_depth=7, n_estimators=300;, score=0.864 total time=   7.4s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.1, max_depth=7, n_estimators=300;, score=0.872 total time=   7.4s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=900;, score=0.874 total time=  17.1s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=900;, score=0.867 total time=  16.7s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=900;, score=0.883 total time=  16.9s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=900;, score=0.874 total time=  16.7s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=900;, score=0.892 total time=  17.3s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.1, max_depth=7, n_estimators=500;, score=0.870 total time=  11.9s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.1, max_depth=7, n_estimators=500;, score=0.875 total time=  12.3s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.1, max_depth=7, n_estimators=500;, score=0.880 total time=  12.2s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.1, max_depth=7, n_estimators=500;, score=0.875 total time=  12.1s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.1, max_depth=7, n_estimators=500;, score=0.874 total time=  12.2s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.1, max_depth=10, n_estimators=300;, score=0.861 total time=   8.8s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.1, max_depth=10, n_estimators=300;, score=0.864 total time=   8.9s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.1, max_depth=10, n_estimators=300;, score=0.874 total time=   9.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.1, max_depth=10, n_estimators=300;, score=0.872 total time=   9.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.1, max_depth=10, n_estimators=300;, score=0.864 total time=   8.8s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.1, max_depth=7, n_estimators=900;, score=0.871 total time=  20.8s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.1, max_depth=7, n_estimators=900;, score=0.877 total time=  20.9s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.1, max_depth=7, n_estimators=900;, score=0.871 total time=  21.1s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.1, max_depth=7, n_estimators=900;, score=0.876 total time=  20.4s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.1, max_depth=7, n_estimators=900;, score=0.873 total time=  21.2s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.1, max_depth=10, n_estimators=500;, score=0.859 total time=  13.7s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.1, max_depth=10, n_estimators=500;, score=0.866 total time=  13.9s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.1, max_depth=10, n_estimators=500;, score=0.872 total time=  13.7s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.1, max_depth=10, n_estimators=500;, score=0.880 total time=  13.8s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.1, max_depth=10, n_estimators=500;, score=0.866 total time=  13.8s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.1, max_depth=None, n_estimators=300;, score=0.877 total time=   6.7s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.1, max_depth=None, n_estimators=300;, score=0.872 total time=   6.4s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.1, max_depth=None, n_estimators=300;, score=0.873 total time=   6.5s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.1, max_depth=None, n_estimators=300;, score=0.872 total time=   6.6s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.1, max_depth=None, n_estimators=300;, score=0.863 total time=   6.5s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.1, max_depth=10, n_estimators=900;, score=0.867 total time=  21.9s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.1, max_depth=10, n_estimators=900;, score=0.876 total time=  22.1s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.1, max_depth=10, n_estimators=900;, score=0.869 total time=  22.4s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.1, max_depth=10, n_estimators=900;, score=0.866 total time=  21.9s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.1, max_depth=10, n_estimators=900;, score=0.881 total time=  22.2s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.1, max_depth=None, n_estimators=500;, score=0.871 total time=  10.6s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.1, max_depth=None, n_estimators=500;, score=0.875 total time=  10.4s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.1, max_depth=None, n_estimators=500;, score=0.879 total time=  10.4s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.1, max_depth=None, n_estimators=500;, score=0.877 total time=  10.6s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.1, max_depth=None, n_estimators=500;, score=0.871 total time=  10.5s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.15, max_depth=3, n_estimators=300;, score=0.866 total time=   4.2s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.15, max_depth=3, n_estimators=300;, score=0.822 total time=   4.2s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.15, max_depth=3, n_estimators=300;, score=0.838 total time=   4.2s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.15, max_depth=3, n_estimators=300;, score=0.852 total time=   4.3s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.15, max_depth=3, n_estimators=300;, score=0.842 total time=   4.3s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.15, max_depth=3, n_estimators=500;, score=0.867 total time=   6.9s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.15, max_depth=3, n_estimators=500;, score=0.846 total time=   6.9s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.1, max_depth=None, n_estimators=900;, score=0.871 total time=  18.9s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.15, max_depth=3, n_estimators=500;, score=0.847 total time=   6.9s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.15, max_depth=3, n_estimators=500;, score=0.863 total time=   6.8s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.15, max_depth=3, n_estimators=500;, score=0.867 total time=   6.8s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.1, max_depth=None, n_estimators=900;, score=0.875 total time=  19.1s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.1, max_depth=None, n_estimators=900;, score=0.881 total time=  19.2s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.1, max_depth=None, n_estimators=900;, score=0.876 total time=  18.6s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.1, max_depth=None, n_estimators=900;, score=0.881 total time=  18.9s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.15, max_depth=5, n_estimators=300;, score=0.864 total time=   5.8s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.15, max_depth=5, n_estimators=300;, score=0.876 total time=   6.1s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.15, max_depth=5, n_estimators=300;, score=0.875 total time=   5.9s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.15, max_depth=5, n_estimators=300;, score=0.877 total time=   5.9s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.15, max_depth=5, n_estimators=300;, score=0.860 total time=   5.9s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.15, max_depth=3, n_estimators=900;, score=0.880 total time=  11.4s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.15, max_depth=3, n_estimators=900;, score=0.861 total time=  11.6s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.15, max_depth=3, n_estimators=900;, score=0.879 total time=  11.8s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.15, max_depth=3, n_estimators=900;, score=0.874 total time=  12.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.15, max_depth=3, n_estimators=900;, score=0.878 total time=  12.1s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.15, max_depth=5, n_estimators=500;, score=0.868 total time=   9.8s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.15, max_depth=5, n_estimators=500;, score=0.875 total time=   9.5s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.15, max_depth=5, n_estimators=500;, score=0.885 total time=   9.6s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.15, max_depth=5, n_estimators=500;, score=0.884 total time=   9.8s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.15, max_depth=5, n_estimators=500;, score=0.867 total time=   9.3s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.15, max_depth=7, n_estimators=300;, score=0.869 total time=   7.7s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.15, max_depth=7, n_estimators=300;, score=0.873 total time=   7.7s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.15, max_depth=7, n_estimators=300;, score=0.880 total time=   7.7s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.15, max_depth=7, n_estimators=300;, score=0.882 total time=   7.7s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.15, max_depth=7, n_estimators=300;, score=0.862 total time=   7.5s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.15, max_depth=5, n_estimators=900;, score=0.878 total time=  17.1s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.15, max_depth=5, n_estimators=900;, score=0.869 total time=  17.2s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.15, max_depth=5, n_estimators=900;, score=0.874 total time=  17.1s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.15, max_depth=5, n_estimators=900;, score=0.885 total time=  17.6s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.15, max_depth=5, n_estimators=900;, score=0.874 total time=  17.3s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.15, max_depth=7, n_estimators=500;, score=0.871 total time=  12.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.15, max_depth=7, n_estimators=500;, score=0.878 total time=  12.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.15, max_depth=7, n_estimators=500;, score=0.862 total time=  11.9s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.15, max_depth=7, n_estimators=500;, score=0.882 total time=  12.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.15, max_depth=7, n_estimators=500;, score=0.873 total time=  12.2s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.15, max_depth=10, n_estimators=300;, score=0.868 total time=   8.7s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.15, max_depth=10, n_estimators=300;, score=0.864 total time=   8.6s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.15, max_depth=10, n_estimators=300;, score=0.872 total time=   8.9s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.15, max_depth=10, n_estimators=300;, score=0.864 total time=   8.8s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.15, max_depth=10, n_estimators=300;, score=0.881 total time=   8.5s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.15, max_depth=7, n_estimators=900;, score=0.877 total time=  19.8s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.15, max_depth=7, n_estimators=900;, score=0.871 total time=  20.1s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.15, max_depth=7, n_estimators=900;, score=0.878 total time=  19.9s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.15, max_depth=7, n_estimators=900;, score=0.869 total time=  19.2s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.15, max_depth=7, n_estimators=900;, score=0.880 total time=  19.6s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.15, max_depth=10, n_estimators=500;, score=0.869 total time=  12.8s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.15, max_depth=10, n_estimators=500;, score=0.874 total time=  13.1s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.15, max_depth=10, n_estimators=500;, score=0.887 total time=  13.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.15, max_depth=10, n_estimators=500;, score=0.863 total time=  13.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.15, max_depth=10, n_estimators=500;, score=0.864 total time=  12.8s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.15, max_depth=None, n_estimators=300;, score=0.868 total time=   6.8s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.15, max_depth=None, n_estimators=300;, score=0.878 total time=   7.1s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.15, max_depth=None, n_estimators=300;, score=0.865 total time=   6.8s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.15, max_depth=None, n_estimators=300;, score=0.882 total time=   7.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.15, max_depth=None, n_estimators=300;, score=0.868 total time=   6.8s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.15, max_depth=10, n_estimators=900;, score=0.868 total time=  20.5s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.15, max_depth=10, n_estimators=900;, score=0.874 total time=  20.7s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.15, max_depth=10, n_estimators=900;, score=0.865 total time=  20.5s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.15, max_depth=10, n_estimators=900;, score=0.887 total time=  20.3s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.15, max_depth=10, n_estimators=900;, score=0.863 total time=  20.3s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.15, max_depth=None, n_estimators=500;, score=0.869 total time=  11.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.15, max_depth=None, n_estimators=500;, score=0.867 total time=  11.1s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.15, max_depth=None, n_estimators=500;, score=0.882 total time=  11.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.15, max_depth=None, n_estimators=500;, score=0.885 total time=  11.3s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.15, max_depth=None, n_estimators=500;, score=0.869 total time=  11.4s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.2, max_depth=3, n_estimators=300;, score=0.841 total time=   4.5s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.2, max_depth=3, n_estimators=300;, score=0.867 total time=   4.5s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.2, max_depth=3, n_estimators=300;, score=0.832 total time=   4.5s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.2, max_depth=3, n_estimators=300;, score=0.845 total time=   4.5s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.2, max_depth=3, n_estimators=300;, score=0.861 total time=   4.4s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.15, max_depth=None, n_estimators=900;, score=0.870 total time=  19.3s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.15, max_depth=None, n_estimators=900;, score=0.869 total time=  19.3s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.2, max_depth=3, n_estimators=500;, score=0.858 total time=   6.9s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.15, max_depth=None, n_estimators=900;, score=0.881 total time=  19.1s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.15, max_depth=None, n_estimators=900;, score=0.885 total time=  19.3s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.2, max_depth=3, n_estimators=500;, score=0.868 total time=   6.9s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.15, max_depth=None, n_estimators=900;, score=0.873 total time=  18.9s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.2, max_depth=3, n_estimators=500;, score=0.889 total time=   6.9s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.2, max_depth=3, n_estimators=500;, score=0.860 total time=   6.5s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.2, max_depth=3, n_estimators=500;, score=0.863 total time=   6.8s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.2, max_depth=5, n_estimators=300;, score=0.866 total time=   6.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.2, max_depth=5, n_estimators=300;, score=0.874 total time=   6.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.2, max_depth=5, n_estimators=300;, score=0.865 total time=   5.9s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.2, max_depth=5, n_estimators=300;, score=0.881 total time=   6.1s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.2, max_depth=5, n_estimators=300;, score=0.876 total time=   6.1s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.2, max_depth=3, n_estimators=900;, score=0.870 total time=  11.5s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.2, max_depth=3, n_estimators=900;, score=0.883 total time=  12.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.2, max_depth=3, n_estimators=900;, score=0.878 total time=  11.8s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.2, max_depth=3, n_estimators=900;, score=0.898 total time=  12.1s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.2, max_depth=3, n_estimators=900;, score=0.862 total time=  12.3s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.2, max_depth=5, n_estimators=500;, score=0.869 total time=   9.7s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.2, max_depth=5, n_estimators=500;, score=0.875 total time=   9.8s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.2, max_depth=5, n_estimators=500;, score=0.879 total time=   9.7s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.2, max_depth=5, n_estimators=500;, score=0.862 total time=   9.7s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.2, max_depth=5, n_estimators=500;, score=0.881 total time=   9.6s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.2, max_depth=7, n_estimators=300;, score=0.859 total time=   7.6s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.2, max_depth=7, n_estimators=300;, score=0.869 total time=   7.7s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.2, max_depth=7, n_estimators=300;, score=0.878 total time=   7.7s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.2, max_depth=7, n_estimators=300;, score=0.883 total time=   7.6s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.2, max_depth=7, n_estimators=300;, score=0.868 total time=   7.6s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.2, max_depth=5, n_estimators=900;, score=0.866 total time=  17.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.2, max_depth=5, n_estimators=900;, score=0.873 total time=  17.2s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.2, max_depth=5, n_estimators=900;, score=0.881 total time=  17.3s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.2, max_depth=5, n_estimators=900;, score=0.873 total time=  17.3s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.2, max_depth=5, n_estimators=900;, score=0.870 total time=  17.1s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.2, max_depth=7, n_estimators=500;, score=0.860 total time=  11.7s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.2, max_depth=7, n_estimators=500;, score=0.873 total time=  11.8s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.2, max_depth=7, n_estimators=500;, score=0.882 total time=  11.8s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.2, max_depth=7, n_estimators=500;, score=0.878 total time=  11.6s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.2, max_depth=7, n_estimators=500;, score=0.877 total time=  11.5s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.2, max_depth=10, n_estimators=300;, score=0.866 total time=   8.3s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.2, max_depth=10, n_estimators=300;, score=0.865 total time=   8.5s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.2, max_depth=10, n_estimators=300;, score=0.873 total time=   8.4s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.2, max_depth=10, n_estimators=300;, score=0.875 total time=   8.3s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.2, max_depth=10, n_estimators=300;, score=0.867 total time=   8.3s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.2, max_depth=7, n_estimators=900;, score=0.860 total time=  19.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.2, max_depth=7, n_estimators=900;, score=0.876 total time=  18.9s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.2, max_depth=7, n_estimators=900;, score=0.878 total time=  18.6s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.2, max_depth=7, n_estimators=900;, score=0.882 total time=  19.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.2, max_depth=7, n_estimators=900;, score=0.872 total time=  19.4s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.2, max_depth=10, n_estimators=500;, score=0.875 total time=  12.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.2, max_depth=10, n_estimators=500;, score=0.866 total time=  12.3s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.2, max_depth=10, n_estimators=500;, score=0.868 total time=  12.2s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.2, max_depth=10, n_estimators=500;, score=0.868 total time=  12.1s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.2, max_depth=10, n_estimators=500;, score=0.872 total time=  11.9s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.2, max_depth=None, n_estimators=300;, score=0.872 total time=   6.9s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.2, max_depth=None, n_estimators=300;, score=0.874 total time=   7.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.2, max_depth=None, n_estimators=300;, score=0.872 total time=   7.1s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.2, max_depth=None, n_estimators=300;, score=0.856 total time=   6.7s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.2, max_depth=None, n_estimators=300;, score=0.875 total time=   6.9s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.2, max_depth=10, n_estimators=900;, score=0.864 total time=  19.1s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.2, max_depth=10, n_estimators=900;, score=0.874 total time=  19.2s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.2, max_depth=10, n_estimators=900;, score=0.878 total time=  18.7s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.2, max_depth=10, n_estimators=900;, score=0.869 total time=  19.2s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.2, max_depth=10, n_estimators=900;, score=0.866 total time=  18.6s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.2, max_depth=None, n_estimators=500;, score=0.870 total time=  10.8s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.2, max_depth=None, n_estimators=500;, score=0.875 total time=  10.9s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.2, max_depth=None, n_estimators=500;, score=0.873 total time=  11.1s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.2, max_depth=None, n_estimators=500;, score=0.857 total time=  10.9s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.2, max_depth=None, n_estimators=500;, score=0.873 total time=  10.8s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.3, max_depth=3, n_estimators=300;, score=0.859 total time=   4.4s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.3, max_depth=3, n_estimators=300;, score=0.869 total time=   4.3s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.3, max_depth=3, n_estimators=300;, score=0.870 total time=   4.4s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.3, max_depth=3, n_estimators=300;, score=0.873 total time=   4.4s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.3, max_depth=3, n_estimators=300;, score=0.860 total time=   4.4s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.2, max_depth=None, n_estimators=900;, score=0.870 total time=  18.5s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.2, max_depth=None, n_estimators=900;, score=0.876 total time=  18.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.3, max_depth=3, n_estimators=500;, score=0.862 total time=   6.9s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.2, max_depth=None, n_estimators=900;, score=0.873 total time=  18.7s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.2, max_depth=None, n_estimators=900;, score=0.883 total time=  18.7s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.2, max_depth=None, n_estimators=900;, score=0.862 total time=  17.9s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.3, max_depth=3, n_estimators=500;, score=0.874 total time=   6.8s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.3, max_depth=3, n_estimators=500;, score=0.875 total time=   6.7s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.3, max_depth=3, n_estimators=500;, score=0.888 total time=   6.9s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.3, max_depth=3, n_estimators=500;, score=0.870 total time=   6.9s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.3, max_depth=5, n_estimators=300;, score=0.880 total time=   6.2s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.3, max_depth=5, n_estimators=300;, score=0.859 total time=   6.1s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.3, max_depth=5, n_estimators=300;, score=0.883 total time=   6.1s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.3, max_depth=5, n_estimators=300;, score=0.886 total time=   6.1s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.3, max_depth=5, n_estimators=300;, score=0.878 total time=   6.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.3, max_depth=3, n_estimators=900;, score=0.871 total time=  11.8s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.3, max_depth=3, n_estimators=900;, score=0.879 total time=  11.8s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.3, max_depth=3, n_estimators=900;, score=0.895 total time=  12.4s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.3, max_depth=3, n_estimators=900;, score=0.872 total time=  11.9s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.3, max_depth=3, n_estimators=900;, score=0.871 total time=  12.6s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.3, max_depth=5, n_estimators=500;, score=0.878 total time=  10.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.3, max_depth=5, n_estimators=500;, score=0.861 total time=  10.1s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.3, max_depth=5, n_estimators=500;, score=0.885 total time=   9.9s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.3, max_depth=5, n_estimators=500;, score=0.879 total time=   9.8s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.3, max_depth=5, n_estimators=500;, score=0.873 total time=   9.6s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.3, max_depth=7, n_estimators=300;, score=0.870 total time=   7.4s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.3, max_depth=7, n_estimators=300;, score=0.863 total time=   7.5s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.3, max_depth=7, n_estimators=300;, score=0.873 total time=   7.4s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.3, max_depth=7, n_estimators=300;, score=0.858 total time=   7.5s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.3, max_depth=7, n_estimators=300;, score=0.860 total time=   7.3s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.3, max_depth=5, n_estimators=900;, score=0.878 total time=  16.6s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.3, max_depth=5, n_estimators=900;, score=0.865 total time=  16.7s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.3, max_depth=5, n_estimators=900;, score=0.880 total time=  16.6s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.3, max_depth=5, n_estimators=900;, score=0.885 total time=  16.8s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.3, max_depth=5, n_estimators=900;, score=0.866 total time=  16.8s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.3, max_depth=7, n_estimators=500;, score=0.870 total time=  10.8s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.3, max_depth=7, n_estimators=500;, score=0.861 total time=  11.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.3, max_depth=7, n_estimators=500;, score=0.863 total time=  10.9s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.3, max_depth=7, n_estimators=500;, score=0.868 total time=  11.2s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.3, max_depth=7, n_estimators=500;, score=0.875 total time=  10.8s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.3, max_depth=10, n_estimators=300;, score=0.868 total time=   7.6s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.3, max_depth=10, n_estimators=300;, score=0.869 total time=   7.6s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.3, max_depth=10, n_estimators=300;, score=0.857 total time=   7.9s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.3, max_depth=10, n_estimators=300;, score=0.869 total time=   7.6s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.3, max_depth=10, n_estimators=300;, score=0.860 total time=   7.9s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.3, max_depth=7, n_estimators=900;, score=0.870 total time=  17.6s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.3, max_depth=7, n_estimators=900;, score=0.865 total time=  17.5s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.3, max_depth=7, n_estimators=900;, score=0.879 total time=  17.6s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.3, max_depth=7, n_estimators=900;, score=0.863 total time=  17.4s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.3, max_depth=7, n_estimators=900;, score=0.870 total time=  17.7s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.3, max_depth=10, n_estimators=500;, score=0.863 total time=  10.8s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.3, max_depth=10, n_estimators=500;, score=0.858 total time=  11.2s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.3, max_depth=10, n_estimators=500;, score=0.869 total time=  11.2s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.3, max_depth=10, n_estimators=500;, score=0.862 total time=  11.1s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.3, max_depth=10, n_estimators=500;, score=0.868 total time=  11.3s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.3, max_depth=None, n_estimators=300;, score=0.864 total time=   6.9s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.3, max_depth=None, n_estimators=300;, score=0.887 total time=   6.8s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.3, max_depth=None, n_estimators=300;, score=0.862 total time=   7.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.3, max_depth=10, n_estimators=900;, score=0.869 total time=  17.4s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.3, max_depth=10, n_estimators=900;, score=0.861 total time=  17.8s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.3, max_depth=None, n_estimators=300;, score=0.874 total time=   6.8s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.3, max_depth=None, n_estimators=300;, score=0.876 total time=   6.9s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.3, max_depth=10, n_estimators=900;, score=0.873 total time=  17.6s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.3, max_depth=10, n_estimators=900;, score=0.859 total time=  17.1s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.3, max_depth=10, n_estimators=900;, score=0.865 total time=  17.4s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.3, max_depth=None, n_estimators=500;, score=0.864 total time=  10.4s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.3, max_depth=None, n_estimators=500;, score=0.874 total time=  10.5s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.3, max_depth=None, n_estimators=500;, score=0.886 total time=  10.6s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.3, max_depth=None, n_estimators=500;, score=0.862 total time=  10.7s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.3, max_depth=None, n_estimators=500;, score=0.876 total time=  10.7s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.3, max_depth=None, n_estimators=900;, score=0.867 total time=  15.6s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.3, max_depth=None, n_estimators=900;, score=0.866 total time=  15.7s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.3, max_depth=None, n_estimators=900;, score=0.877 total time=  15.2s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.3, max_depth=None, n_estimators=900;, score=0.876 total time=  15.2s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.3, max_depth=None, n_estimators=900;, score=0.887 total time=  15.6s\n",
      "Best parameters found:  {'colsample_bytree': 0.9, 'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 900}\n",
      "Best average F1 score found:  0.8789625360230547\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.9, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.2, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=3,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=900,\n",
       "              n_jobs=None, num_parallel_tree=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;XGBClassifier<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.9, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.2, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=3,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=900,\n",
       "              n_jobs=None, num_parallel_tree=None, random_state=None, ...)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.9, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric='logloss',\n",
       "              feature_types=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.2, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=3,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=900,\n",
       "              n_jobs=None, num_parallel_tree=None, random_state=None, ...)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score, make_scorer\n",
    "# Initialize the XGBClassifier\n",
    "xgb_clf = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7, 10, None],\n",
    "    'learning_rate': [0.1, 0.15, 0.2, 0.3],\n",
    "    'n_estimators': [300, 500, 900],\n",
    "    'colsample_bytree': [0.1, 0.3, 0.7, 0.9]\n",
    "}\n",
    "\n",
    "# Set up GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=xgb_clf, param_grid=param_grid, scoring='f1', cv=5, n_jobs=-1, verbose=3)\n",
    "grid_search.fit(X_train, y_train)\n",
    "clf = grid_search.best_estimator_\n",
    "# Best parameters and best score\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "print(\"Best average F1 score found: \", f1_score(y_val, clf.predict(X_val)))\n",
    "\n",
    "# Train the model with the optimal parameters\n",
    "optimal_clf = XGBClassifier(**grid_search.best_params_, use_label_encoder=False, eval_metric='logloss')\n",
    "optimal_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('model_final_xgb.obj', 'wb') as f:\n",
    "    pickle.dump(optimal_clf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Kaggle Submission\n",
    "pred = test_df.drop(['is_fraud', 'city_pop_cluster', 'Id'], axis=1)\n",
    "pred2 = test_df.drop(['is_fraud'], axis=1)\n",
    "\n",
    "pred2['is_fraud'] = optimal_clf.predict(pred)\n",
    "pred2.is_fraud = pred2.is_fraud.astype(int)\n",
    "submission = pred2[['Id', 'is_fraud']]\n",
    "submission.to_csv(\"./data/submission6.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 10 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 300\n",
      "building tree 2 of 300\n",
      "building tree 3 of 300\n",
      "building tree 4 of 300\n",
      "building tree 5 of 300\n",
      "building tree 6 of 300\n",
      "building tree 7 of 300\n",
      "building tree 8 of 300\n",
      "building tree 9 of 300\n",
      "building tree 10 of 300\n",
      "building tree 11 of 300\n",
      "building tree 12 of 300\n",
      "building tree 13 of 300\n",
      "building tree 14 of 300\n",
      "building tree 15 of 300\n",
      "building tree 16 of 300\n",
      "building tree 17 of 300\n",
      "building tree 18 of 300\n",
      "building tree 19 of 300\n",
      "building tree 20 of 300\n",
      "building tree 21 of 300\n",
      "building tree 22 of 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:    1.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 23 of 300\n",
      "building tree 24 of 300\n",
      "building tree 25 of 300\n",
      "building tree 26 of 300\n",
      "building tree 27 of 300\n",
      "building tree 28 of 300\n",
      "building tree 29 of 300building tree 30 of 300\n",
      "\n",
      "building tree 31 of 300\n",
      "building tree 32 of 300\n",
      "building tree 33 of 300\n",
      "building tree 34 of 300\n",
      "building tree 35 of 300\n",
      "building tree 36 of 300\n",
      "building tree 37 of 300\n",
      "building tree 38 of 300\n",
      "building tree 39 of 300\n",
      "building tree 40 of 300\n",
      "building tree 41 of 300\n",
      "building tree 42 of 300\n",
      "building tree 43 of 300\n",
      "building tree 44 of 300\n",
      "building tree 45 of 300\n",
      "building tree 46 of 300building tree 47 of 300\n",
      "\n",
      "building tree 48 of 300\n",
      "building tree 49 of 300\n",
      "building tree 50 of 300\n",
      "building tree 51 of 300\n",
      "building tree 52 of 300\n",
      "building tree 53 of 300\n",
      "building tree 54 of 300\n",
      "building tree 55 of 300\n",
      "building tree 56 of 300\n",
      "building tree 57 of 300\n",
      "building tree 58 of 300\n",
      "building tree 59 of 300\n",
      "building tree 60 of 300\n",
      "building tree 61 of 300\n",
      "building tree 62 of 300\n",
      "building tree 63 of 300\n",
      "building tree 64 of 300\n",
      "building tree 65 of 300\n",
      "building tree 66 of 300\n",
      "building tree 67 of 300\n",
      "building tree 68 of 300\n",
      "building tree 69 of 300\n",
      "building tree 70 of 300\n",
      "building tree 71 of 300\n",
      "building tree 72 of 300\n",
      "building tree 73 of 300\n",
      "building tree 74 of 300\n",
      "building tree 75 of 300\n",
      "building tree 76 of 300\n",
      "building tree 77 of 300\n",
      "building tree 78 of 300\n",
      "building tree 79 of 300\n",
      "building tree 80 of 300\n",
      "building tree 81 of 300\n",
      "building tree 82 of 300\n",
      "building tree 83 of 300\n",
      "building tree 84 of 300\n",
      "building tree 85 of 300\n",
      "building tree 86 of 300\n",
      "building tree 87 of 300\n",
      "building tree 88 of 300\n",
      "building tree 89 of 300\n",
      "building tree 90 of 300\n",
      "building tree 91 of 300\n",
      "building tree 92 of 300\n",
      "building tree 93 of 300\n",
      "building tree 94 of 300\n",
      "building tree 95 of 300\n",
      "building tree 96 of 300\n",
      "building tree 97 of 300\n",
      "building tree 98 of 300\n",
      "building tree 99 of 300\n",
      "building tree 100 of 300building tree 101 of 300\n",
      "\n",
      "building tree 102 of 300\n",
      "building tree 103 of 300\n",
      "building tree 104 of 300\n",
      "building tree 105 of 300\n",
      "building tree 106 of 300\n",
      "building tree 107 of 300\n",
      "building tree 108 of 300\n",
      "building tree 109 of 300\n",
      "building tree 110 of 300\n",
      "building tree 111 of 300\n",
      "building tree 112 of 300\n",
      "building tree 113 of 300\n",
      "building tree 114 of 300\n",
      "building tree 115 of 300\n",
      "building tree 116 of 300\n",
      "building tree 117 of 300\n",
      "building tree 118 of 300\n",
      "building tree 119 of 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 108 tasks      | elapsed:    8.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 120 of 300\n",
      "building tree 121 of 300\n",
      "building tree 122 of 300\n",
      "building tree 123 of 300\n",
      "building tree 124 of 300\n",
      "building tree 125 of 300\n",
      "building tree 126 of 300\n",
      "building tree 127 of 300\n",
      "building tree 128 of 300\n",
      "building tree 129 of 300\n",
      "building tree 130 of 300\n",
      "building tree 131 of 300\n",
      "building tree 132 of 300\n",
      "building tree 133 of 300\n",
      "building tree 134 of 300\n",
      "building tree 135 of 300\n",
      "building tree 136 of 300\n",
      "building tree 137 of 300\n",
      "building tree 138 of 300\n",
      "building tree 139 of 300\n",
      "building tree 140 of 300\n",
      "building tree 141 of 300\n",
      "building tree 142 of 300\n",
      "building tree 143 of 300\n",
      "building tree 144 of 300\n",
      "building tree 145 of 300\n",
      "building tree 146 of 300\n",
      "building tree 147 of 300\n",
      "building tree 148 of 300\n",
      "building tree 149 of 300\n",
      "building tree 150 of 300\n",
      "building tree 151 of 300\n",
      "building tree 152 of 300\n",
      "building tree 153 of 300\n",
      "building tree 154 of 300\n",
      "building tree 155 of 300\n",
      "building tree 156 of 300\n",
      "building tree 157 of 300\n",
      "building tree 158 of 300\n",
      "building tree 159 of 300\n",
      "building tree 160 of 300\n",
      "building tree 161 of 300\n",
      "building tree 162 of 300\n",
      "building tree 163 of 300\n",
      "building tree 164 of 300\n",
      "building tree 165 of 300\n",
      "building tree 166 of 300\n",
      "building tree 167 of 300\n",
      "building tree 168 of 300\n",
      "building tree 169 of 300\n",
      "building tree 170 of 300\n",
      "building tree 171 of 300\n",
      "building tree 172 of 300\n",
      "building tree 173 of 300\n",
      "building tree 174 of 300\n",
      "building tree 175 of 300\n",
      "building tree 176 of 300\n",
      "building tree 177 of 300\n",
      "building tree 178 of 300\n",
      "building tree 179 of 300\n",
      "building tree 180 of 300\n",
      "building tree 181 of 300\n",
      "building tree 182 of 300\n",
      "building tree 183 of 300\n",
      "building tree 184 of 300\n",
      "building tree 185 of 300\n",
      "building tree 186 of 300\n",
      "building tree 187 of 300\n",
      "building tree 188 of 300\n",
      "building tree 189 of 300\n",
      "building tree 190 of 300\n",
      "building tree 191 of 300\n",
      "building tree 192 of 300\n",
      "building tree 193 of 300\n",
      "building tree 194 of 300\n",
      "building tree 195 of 300\n",
      "building tree 196 of 300\n",
      "building tree 197 of 300\n",
      "building tree 198 of 300\n",
      "building tree 199 of 300\n",
      "building tree 200 of 300\n",
      "building tree 201 of 300\n",
      "building tree 202 of 300\n",
      "building tree 203 of 300\n",
      "building tree 204 of 300\n",
      "building tree 205 of 300\n",
      "building tree 206 of 300\n",
      "building tree 207 of 300\n",
      "building tree 208 of 300\n",
      "building tree 209 of 300\n",
      "building tree 210 of 300\n",
      "building tree 211 of 300\n",
      "building tree 212 of 300\n",
      "building tree 213 of 300\n",
      "building tree 214 of 300\n",
      "building tree 215 of 300\n",
      "building tree 216 of 300\n",
      "building tree 217 of 300\n",
      "building tree 218 of 300\n",
      "building tree 219 of 300\n",
      "building tree 220 of 300\n",
      "building tree 221 of 300\n",
      "building tree 222 of 300\n",
      "building tree 223 of 300\n",
      "building tree 224 of 300\n",
      "building tree 225 of 300\n",
      "building tree 226 of 300\n",
      "building tree 227 of 300\n",
      "building tree 228 of 300\n",
      "building tree 229 of 300\n",
      "building tree 230 of 300\n",
      "building tree 231 of 300\n",
      "building tree 232 of 300\n",
      "building tree 233 of 300\n",
      "building tree 234 of 300\n",
      "building tree 235 of 300\n",
      "building tree 236 of 300\n",
      "building tree 237 of 300\n",
      "building tree 238 of 300\n",
      "building tree 239 of 300\n",
      "building tree 240 of 300\n",
      "building tree 241 of 300\n",
      "building tree 242 of 300\n",
      "building tree 243 of 300\n",
      "building tree 244 of 300\n",
      "building tree 245 of 300\n",
      "building tree 246 of 300\n",
      "building tree 247 of 300\n",
      "building tree 248 of 300\n",
      "building tree 249 of 300\n",
      "building tree 250 of 300\n",
      "building tree 251 of 300\n",
      "building tree 252 of 300\n",
      "building tree 253 of 300\n",
      "building tree 254 of 300\n",
      "building tree 255 of 300\n",
      "building tree 256 of 300\n",
      "building tree 257 of 300\n",
      "building tree 258 of 300\n",
      "building tree 259 of 300\n",
      "building tree 260 of 300\n",
      "building tree 261 of 300\n",
      "building tree 262 of 300\n",
      "building tree 263 of 300\n",
      "building tree 264 of 300\n",
      "building tree 265 of 300\n",
      "building tree 266 of 300\n",
      "building tree 267 of 300\n",
      "building tree 268 of 300\n",
      "building tree 269 of 300\n",
      "building tree 270 of 300\n",
      "building tree 271 of 300\n",
      "building tree 272 of 300\n",
      "building tree 273 of 300\n",
      "building tree 274 of 300\n",
      "building tree 275 of 300\n",
      "building tree 276 of 300\n",
      "building tree 277 of 300\n",
      "building tree 278 of 300\n",
      "building tree 279 of 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 268 tasks      | elapsed:   18.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 280 of 300\n",
      "building tree 281 of 300\n",
      "building tree 282 of 300\n",
      "building tree 283 of 300\n",
      "building tree 284 of 300\n",
      "building tree 285 of 300\n",
      "building tree 286 of 300\n",
      "building tree 287 of 300\n",
      "building tree 288 of 300\n",
      "building tree 289 of 300\n",
      "building tree 290 of 300\n",
      "building tree 291 of 300\n",
      "building tree 292 of 300\n",
      "building tree 293 of 300\n",
      "building tree 294 of 300\n",
      "building tree 295 of 300\n",
      "building tree 296 of 300\n",
      "building tree 297 of 300\n",
      "building tree 298 of 300\n",
      "building tree 299 of 300\n",
      "building tree 300 of 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:   21.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 10 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 900\n",
      "building tree 2 of 900\n",
      "building tree 3 of 900\n",
      "building tree 4 of 900\n",
      "building tree 5 of 900\n",
      "building tree 6 of 900\n",
      "building tree 7 of 900\n",
      "building tree 8 of 900\n",
      "building tree 9 of 900\n",
      "building tree 10 of 900\n",
      "building tree 11 of 900\n",
      "building tree 12 of 900\n",
      "building tree 13 of 900\n",
      "building tree 14 of 900\n",
      "building tree 15 of 900\n",
      "building tree 16 of 900\n",
      "building tree 17 of 900\n",
      "building tree 18 of 900\n",
      "building tree 19 of 900\n",
      "building tree 20 of 900\n",
      "building tree 21 of 900\n",
      "building tree 22 of 900\n",
      "building tree 23 of 900\n",
      "building tree 24 of 900\n",
      "building tree 25 of 900\n",
      "building tree 26 of 900\n",
      "building tree 27 of 900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:    1.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 28 of 900\n",
      "building tree 29 of 900\n",
      "building tree 30 of 900\n",
      "building tree 31 of 900\n",
      "building tree 32 of 900\n",
      "building tree 33 of 900\n",
      "building tree 34 of 900\n",
      "building tree 35 of 900\n",
      "building tree 36 of 900\n",
      "building tree 37 of 900\n",
      "building tree 38 of 900\n",
      "building tree 39 of 900\n",
      "building tree 40 of 900\n",
      "building tree 41 of 900\n",
      "building tree 42 of 900\n",
      "building tree 43 of 900\n",
      "building tree 44 of 900\n",
      "building tree 45 of 900\n",
      "building tree 46 of 900\n",
      "building tree 47 of 900\n",
      "building tree 48 of 900\n",
      "building tree 49 of 900\n",
      "building tree 50 of 900\n",
      "building tree 51 of 900\n",
      "building tree 52 of 900\n",
      "building tree 53 of 900\n",
      "building tree 54 of 900\n",
      "building tree 55 of 900\n",
      "building tree 56 of 900\n",
      "building tree 57 of 900\n",
      "building tree 58 of 900\n",
      "building tree 59 of 900\n",
      "building tree 60 of 900\n",
      "building tree 61 of 900\n",
      "building tree 62 of 900\n",
      "building tree 63 of 900\n",
      "building tree 64 of 900\n",
      "building tree 65 of 900\n",
      "building tree 66 of 900\n",
      "building tree 67 of 900\n",
      "building tree 68 of 900\n",
      "building tree 69 of 900\n",
      "building tree 70 of 900\n",
      "building tree 71 of 900\n",
      "building tree 72 of 900\n",
      "building tree 73 of 900\n",
      "building tree 74 of 900\n",
      "building tree 75 of 900\n",
      "building tree 76 of 900\n",
      "building tree 77 of 900\n",
      "building tree 78 of 900\n",
      "building tree 79 of 900\n",
      "building tree 80 of 900\n",
      "building tree 81 of 900\n",
      "building tree 82 of 900\n",
      "building tree 83 of 900\n",
      "building tree 84 of 900\n",
      "building tree 85 of 900\n",
      "building tree 86 of 900\n",
      "building tree 87 of 900\n",
      "building tree 88 of 900\n",
      "building tree 89 of 900\n",
      "building tree 90 of 900\n",
      "building tree 91 of 900\n",
      "building tree 92 of 900\n",
      "building tree 93 of 900\n",
      "building tree 94 of 900\n",
      "building tree 95 of 900\n",
      "building tree 96 of 900\n",
      "building tree 97 of 900\n",
      "building tree 98 of 900\n",
      "building tree 99 of 900\n",
      "building tree 100 of 900\n",
      "building tree 101 of 900\n",
      "building tree 102 of 900\n",
      "building tree 103 of 900\n",
      "building tree 104 of 900\n",
      "building tree 105 of 900\n",
      "building tree 106 of 900\n",
      "building tree 107 of 900\n",
      "building tree 108 of 900\n",
      "building tree 109 of 900\n",
      "building tree 110 of 900\n",
      "building tree 111 of 900\n",
      "building tree 112 of 900\n",
      "building tree 113 of 900\n",
      "building tree 114 of 900\n",
      "building tree 115 of 900\n",
      "building tree 116 of 900\n",
      "building tree 117 of 900\n",
      "building tree 118 of 900\n",
      "building tree 119 of 900\n",
      "building tree 120 of 900\n",
      "building tree 121 of 900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 108 tasks      | elapsed:    7.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 122 of 900\n",
      "building tree 123 of 900\n",
      "building tree 124 of 900\n",
      "building tree 125 of 900\n",
      "building tree 126 of 900\n",
      "building tree 127 of 900\n",
      "building tree 128 of 900\n",
      "building tree 129 of 900\n",
      "building tree 130 of 900\n",
      "building tree 131 of 900\n",
      "building tree 132 of 900\n",
      "building tree 133 of 900\n",
      "building tree 134 of 900\n",
      "building tree 135 of 900\n",
      "building tree 136 of 900\n",
      "building tree 137 of 900\n",
      "building tree 138 of 900\n",
      "building tree 139 of 900\n",
      "building tree 140 of 900\n",
      "building tree 141 of 900\n",
      "building tree 142 of 900\n",
      "building tree 143 of 900\n",
      "building tree 144 of 900\n",
      "building tree 145 of 900\n",
      "building tree 146 of 900\n",
      "building tree 147 of 900\n",
      "building tree 148 of 900\n",
      "building tree 149 of 900\n",
      "building tree 150 of 900\n",
      "building tree 151 of 900\n",
      "building tree 152 of 900\n",
      "building tree 153 of 900\n",
      "building tree 154 of 900\n",
      "building tree 155 of 900\n",
      "building tree 156 of 900\n",
      "building tree 157 of 900\n",
      "building tree 158 of 900\n",
      "building tree 159 of 900\n",
      "building tree 160 of 900\n",
      "building tree 161 of 900\n",
      "building tree 162 of 900\n",
      "building tree 163 of 900\n",
      "building tree 164 of 900\n",
      "building tree 165 of 900\n",
      "building tree 166 of 900\n",
      "building tree 167 of 900\n",
      "building tree 168 of 900\n",
      "building tree 169 of 900\n",
      "building tree 170 of 900\n",
      "building tree 171 of 900\n",
      "building tree 172 of 900\n",
      "building tree 173 of 900\n",
      "building tree 174 of 900\n",
      "building tree 175 of 900\n",
      "building tree 176 of 900\n",
      "building tree 177 of 900\n",
      "building tree 178 of 900\n",
      "building tree 179 of 900\n",
      "building tree 180 of 900\n",
      "building tree 181 of 900\n",
      "building tree 182 of 900\n",
      "building tree 183 of 900\n",
      "building tree 184 of 900\n",
      "building tree 185 of 900\n",
      "building tree 186 of 900\n",
      "building tree 187 of 900\n",
      "building tree 188 of 900\n",
      "building tree 189 of 900\n",
      "building tree 190 of 900\n",
      "building tree 191 of 900\n",
      "building tree 192 of 900\n",
      "building tree 193 of 900\n",
      "building tree 194 of 900\n",
      "building tree 195 of 900\n",
      "building tree 196 of 900\n",
      "building tree 197 of 900\n",
      "building tree 198 of 900\n",
      "building tree 199 of 900\n",
      "building tree 200 of 900\n",
      "building tree 201 of 900\n",
      "building tree 202 of 900\n",
      "building tree 203 of 900\n",
      "building tree 204 of 900\n",
      "building tree 205 of 900\n",
      "building tree 206 of 900\n",
      "building tree 207 of 900\n",
      "building tree 208 of 900\n",
      "building tree 209 of 900\n",
      "building tree 210 of 900\n",
      "building tree 211 of 900\n",
      "building tree 212 of 900\n",
      "building tree 213 of 900\n",
      "building tree 214 of 900\n",
      "building tree 215 of 900\n",
      "building tree 216 of 900\n",
      "building tree 217 of 900\n",
      "building tree 218 of 900\n",
      "building tree 219 of 900\n",
      "building tree 220 of 900\n",
      "building tree 221 of 900\n",
      "building tree 222 of 900\n",
      "building tree 223 of 900\n",
      "building tree 224 of 900\n",
      "building tree 225 of 900\n",
      "building tree 226 of 900\n",
      "building tree 227 of 900\n",
      "building tree 228 of 900\n",
      "building tree 229 of 900\n",
      "building tree 230 of 900\n",
      "building tree 231 of 900\n",
      "building tree 232 of 900\n",
      "building tree 233 of 900\n",
      "building tree 234 of 900\n",
      "building tree 235 of 900\n",
      "building tree 236 of 900\n",
      "building tree 237 of 900\n",
      "building tree 238 of 900\n",
      "building tree 239 of 900\n",
      "building tree 240 of 900\n",
      "building tree 241 of 900\n",
      "building tree 242 of 900\n",
      "building tree 243 of 900\n",
      "building tree 244 of 900\n",
      "building tree 245 of 900\n",
      "building tree 246 of 900\n",
      "building tree 247 of 900\n",
      "building tree 248 of 900\n",
      "building tree 249 of 900\n",
      "building tree 250 of 900\n",
      "building tree 251 of 900\n",
      "building tree 252 of 900\n",
      "building tree 253 of 900\n",
      "building tree 254 of 900\n",
      "building tree 255 of 900\n",
      "building tree 256 of 900\n",
      "building tree 257 of 900\n",
      "building tree 258 of 900\n",
      "building tree 259 of 900\n",
      "building tree 260 of 900\n",
      "building tree 261 of 900\n",
      "building tree 262 of 900\n",
      "building tree 263 of 900\n",
      "building tree 264 of 900\n",
      "building tree 265 of 900\n",
      "building tree 266 of 900\n",
      "building tree 267 of 900\n",
      "building tree 268 of 900\n",
      "building tree 269 of 900\n",
      "building tree 270 of 900\n",
      "building tree 271 of 900\n",
      "building tree 272 of 900\n",
      "building tree 273 of 900\n",
      "building tree 274 of 900\n",
      "building tree 275 of 900\n",
      "building tree 276 of 900\n",
      "building tree 277 of 900\n",
      "building tree 278 of 900\n",
      "building tree 279 of 900\n",
      "building tree 280 of 900\n",
      "building tree 281 of 900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 268 tasks      | elapsed:   18.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 282 of 900\n",
      "building tree 283 of 900\n",
      "building tree 284 of 900\n",
      "building tree 285 of 900\n",
      "building tree 286 of 900\n",
      "building tree 287 of 900\n",
      "building tree 288 of 900\n",
      "building tree 289 of 900\n",
      "building tree 290 of 900\n",
      "building tree 291 of 900\n",
      "building tree 292 of 900\n",
      "building tree 293 of 900\n",
      "building tree 294 of 900\n",
      "building tree 295 of 900\n",
      "building tree 296 of 900\n",
      "building tree 297 of 900\n",
      "building tree 298 of 900\n",
      "building tree 299 of 900\n",
      "building tree 300 of 900\n",
      "building tree 301 of 900\n",
      "building tree 302 of 900\n",
      "building tree 303 of 900\n",
      "building tree 304 of 900\n",
      "building tree 305 of 900\n",
      "building tree 306 of 900\n",
      "building tree 307 of 900\n",
      "building tree 308 of 900\n",
      "building tree 309 of 900\n",
      "building tree 310 of 900\n",
      "building tree 311 of 900\n",
      "building tree 312 of 900\n",
      "building tree 313 of 900\n",
      "building tree 314 of 900\n",
      "building tree 315 of 900\n",
      "building tree 316 of 900\n",
      "building tree 317 of 900\n",
      "building tree 318 of 900\n",
      "building tree 319 of 900\n",
      "building tree 320 of 900\n",
      "building tree 321 of 900\n",
      "building tree 322 of 900\n",
      "building tree 323 of 900\n",
      "building tree 324 of 900\n",
      "building tree 325 of 900\n",
      "building tree 326 of 900\n",
      "building tree 327 of 900\n",
      "building tree 328 of 900\n",
      "building tree 329 of 900\n",
      "building tree 330 of 900\n",
      "building tree 331 of 900\n",
      "building tree 332 of 900\n",
      "building tree 333 of 900\n",
      "building tree 334 of 900\n",
      "building tree 335 of 900\n",
      "building tree 336 of 900\n",
      "building tree 337 of 900\n",
      "building tree 338 of 900\n",
      "building tree 339 of 900\n",
      "building tree 340 of 900\n",
      "building tree 341 of 900\n",
      "building tree 342 of 900\n",
      "building tree 343 of 900\n",
      "building tree 344 of 900\n",
      "building tree 345 of 900\n",
      "building tree 346 of 900\n",
      "building tree 347 of 900\n",
      "building tree 348 of 900\n",
      "building tree 349 of 900\n",
      "building tree 350 of 900\n",
      "building tree 351 of 900\n",
      "building tree 352 of 900\n",
      "building tree 353 of 900\n",
      "building tree 354 of 900\n",
      "building tree 355 of 900\n",
      "building tree 356 of 900\n",
      "building tree 357 of 900\n",
      "building tree 358 of 900\n",
      "building tree 359 of 900\n",
      "building tree 360 of 900\n",
      "building tree 361 of 900\n",
      "building tree 362 of 900\n",
      "building tree 363 of 900\n",
      "building tree 364 of 900\n",
      "building tree 365 of 900\n",
      "building tree 366 of 900\n",
      "building tree 367 of 900\n",
      "building tree 368 of 900\n",
      "building tree 369 of 900\n",
      "building tree 370 of 900\n",
      "building tree 371 of 900\n",
      "building tree 372 of 900\n",
      "building tree 373 of 900\n",
      "building tree 374 of 900\n",
      "building tree 375 of 900\n",
      "building tree 376 of 900\n",
      "building tree 377 of 900\n",
      "building tree 378 of 900\n",
      "building tree 379 of 900\n",
      "building tree 380 of 900\n",
      "building tree 381 of 900\n",
      "building tree 382 of 900\n",
      "building tree 383 of 900\n",
      "building tree 384 of 900\n",
      "building tree 385 of 900\n",
      "building tree 386 of 900\n",
      "building tree 387 of 900\n",
      "building tree 388 of 900\n",
      "building tree 389 of 900\n",
      "building tree 390 of 900\n",
      "building tree 391 of 900\n",
      "building tree 392 of 900\n",
      "building tree 393 of 900\n",
      "building tree 394 of 900\n",
      "building tree 395 of 900\n",
      "building tree 396 of 900\n",
      "building tree 397 of 900\n",
      "building tree 398 of 900\n",
      "building tree 399 of 900\n",
      "building tree 400 of 900\n",
      "building tree 401 of 900\n",
      "building tree 402 of 900\n",
      "building tree 403 of 900\n",
      "building tree 404 of 900\n",
      "building tree 405 of 900\n",
      "building tree 406 of 900\n",
      "building tree 407 of 900\n",
      "building tree 408 of 900\n",
      "building tree 409 of 900\n",
      "building tree 410 of 900\n",
      "building tree 411 of 900\n",
      "building tree 412 of 900\n",
      "building tree 413 of 900\n",
      "building tree 414 of 900\n",
      "building tree 415 of 900\n",
      "building tree 416 of 900\n",
      "building tree 417 of 900\n",
      "building tree 418 of 900\n",
      "building tree 419 of 900\n",
      "building tree 420 of 900\n",
      "building tree 421 of 900\n",
      "building tree 422 of 900\n",
      "building tree 423 of 900\n",
      "building tree 424 of 900\n",
      "building tree 425 of 900\n",
      "building tree 426 of 900\n",
      "building tree 427 of 900\n",
      "building tree 428 of 900\n",
      "building tree 429 of 900\n",
      "building tree 430 of 900\n",
      "building tree 431 of 900\n",
      "building tree 432 of 900\n",
      "building tree 433 of 900\n",
      "building tree 434 of 900\n",
      "building tree 435 of 900\n",
      "building tree 436 of 900\n",
      "building tree 437 of 900\n",
      "building tree 438 of 900\n",
      "building tree 439 of 900\n",
      "building tree 440 of 900\n",
      "building tree 441 of 900\n",
      "building tree 442 of 900\n",
      "building tree 443 of 900\n",
      "building tree 444 of 900\n",
      "building tree 445 of 900\n",
      "building tree 446 of 900\n",
      "building tree 447 of 900\n",
      "building tree 448 of 900\n",
      "building tree 449 of 900\n",
      "building tree 450 of 900\n",
      "building tree 451 of 900\n",
      "building tree 452 of 900\n",
      "building tree 453 of 900\n",
      "building tree 454 of 900\n",
      "building tree 455 of 900\n",
      "building tree 456 of 900\n",
      "building tree 457 of 900\n",
      "building tree 458 of 900\n",
      "building tree 459 of 900\n",
      "building tree 460 of 900\n",
      "building tree 461 of 900\n",
      "building tree 462 of 900\n",
      "building tree 463 of 900\n",
      "building tree 464 of 900\n",
      "building tree 465 of 900\n",
      "building tree 466 of 900\n",
      "building tree 467 of 900\n",
      "building tree 468 of 900\n",
      "building tree 469 of 900\n",
      "building tree 470 of 900\n",
      "building tree 471 of 900\n",
      "building tree 472 of 900\n",
      "building tree 473 of 900\n",
      "building tree 474 of 900\n",
      "building tree 475 of 900\n",
      "building tree 476 of 900\n",
      "building tree 477 of 900\n",
      "building tree 478 of 900\n",
      "building tree 479 of 900\n",
      "building tree 480 of 900\n",
      "building tree 481 of 900\n",
      "building tree 482 of 900\n",
      "building tree 483 of 900\n",
      "building tree 484 of 900\n",
      "building tree 485 of 900\n",
      "building tree 486 of 900\n",
      "building tree 487 of 900\n",
      "building tree 488 of 900\n",
      "building tree 489 of 900\n",
      "building tree 490 of 900\n",
      "building tree 491 of 900\n",
      "building tree 492 of 900\n",
      "building tree 493 of 900\n",
      "building tree 494 of 900\n",
      "building tree 495 of 900\n",
      "building tree 496 of 900\n",
      "building tree 497 of 900\n",
      "building tree 498 of 900\n",
      "building tree 499 of 900\n",
      "building tree 500 of 900\n",
      "building tree 501 of 900\n",
      "building tree 502 of 900\n",
      "building tree 503 of 900\n",
      "building tree 504 of 900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 492 tasks      | elapsed:   34.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 505 of 900\n",
      "building tree 506 of 900\n",
      "building tree 507 of 900\n",
      "building tree 508 of 900\n",
      "building tree 509 of 900\n",
      "building tree 510 of 900\n",
      "building tree 511 of 900\n",
      "building tree 512 of 900\n",
      "building tree 513 of 900\n",
      "building tree 514 of 900\n",
      "building tree 515 of 900\n",
      "building tree 516 of 900\n",
      "building tree 517 of 900\n",
      "building tree 518 of 900\n",
      "building tree 519 of 900\n",
      "building tree 520 of 900\n",
      "building tree 521 of 900\n",
      "building tree 522 of 900\n",
      "building tree 523 of 900\n",
      "building tree 524 of 900\n",
      "building tree 525 of 900\n",
      "building tree 526 of 900\n",
      "building tree 527 of 900\n",
      "building tree 528 of 900\n",
      "building tree 529 of 900\n",
      "building tree 530 of 900\n",
      "building tree 531 of 900\n",
      "building tree 532 of 900\n",
      "building tree 533 of 900\n",
      "building tree 534 of 900\n",
      "building tree 535 of 900\n",
      "building tree 536 of 900\n",
      "building tree 537 of 900\n",
      "building tree 538 of 900\n",
      "building tree 539 of 900\n",
      "building tree 540 of 900\n",
      "building tree 541 of 900\n",
      "building tree 542 of 900\n",
      "building tree 543 of 900\n",
      "building tree 544 of 900\n",
      "building tree 545 of 900\n",
      "building tree 546 of 900\n",
      "building tree 547 of 900\n",
      "building tree 548 of 900\n",
      "building tree 549 of 900\n",
      "building tree 550 of 900\n",
      "building tree 551 of 900\n",
      "building tree 552 of 900\n",
      "building tree 553 of 900\n",
      "building tree 554 of 900\n",
      "building tree 555 of 900\n",
      "building tree 556 of 900\n",
      "building tree 557 of 900\n",
      "building tree 558 of 900\n",
      "building tree 559 of 900\n",
      "building tree 560 of 900\n",
      "building tree 561 of 900\n",
      "building tree 562 of 900\n",
      "building tree 563 of 900\n",
      "building tree 564 of 900\n",
      "building tree 565 of 900\n",
      "building tree 566 of 900\n",
      "building tree 567 of 900\n",
      "building tree 568 of 900\n",
      "building tree 569 of 900\n",
      "building tree 570 of 900\n",
      "building tree 571 of 900\n",
      "building tree 572 of 900\n",
      "building tree 573 of 900\n",
      "building tree 574 of 900\n",
      "building tree 575 of 900\n",
      "building tree 576 of 900\n",
      "building tree 577 of 900\n",
      "building tree 578 of 900\n",
      "building tree 579 of 900\n",
      "building tree 580 of 900\n",
      "building tree 581 of 900\n",
      "building tree 582 of 900\n",
      "building tree 583 of 900\n",
      "building tree 584 of 900\n",
      "building tree 585 of 900\n",
      "building tree 586 of 900\n",
      "building tree 587 of 900\n",
      "building tree 588 of 900\n",
      "building tree 589 of 900\n",
      "building tree 590 of 900\n",
      "building tree 591 of 900\n",
      "building tree 592 of 900\n",
      "building tree 593 of 900\n",
      "building tree 594 of 900\n",
      "building tree 595 of 900\n",
      "building tree 596 of 900\n",
      "building tree 597 of 900\n",
      "building tree 598 of 900\n",
      "building tree 599 of 900\n",
      "building tree 600 of 900\n",
      "building tree 601 of 900\n",
      "building tree 602 of 900\n",
      "building tree 603 of 900\n",
      "building tree 604 of 900\n",
      "building tree 605 of 900\n",
      "building tree 606 of 900\n",
      "building tree 607 of 900\n",
      "building tree 608 of 900\n",
      "building tree 609 of 900\n",
      "building tree 610 of 900\n",
      "building tree 611 of 900\n",
      "building tree 612 of 900\n",
      "building tree 613 of 900\n",
      "building tree 614 of 900\n",
      "building tree 615 of 900\n",
      "building tree 616 of 900\n",
      "building tree 617 of 900\n",
      "building tree 618 of 900\n",
      "building tree 619 of 900\n",
      "building tree 620 of 900\n",
      "building tree 621 of 900\n",
      "building tree 622 of 900\n",
      "building tree 623 of 900\n",
      "building tree 624 of 900\n",
      "building tree 625 of 900\n",
      "building tree 626 of 900\n",
      "building tree 627 of 900\n",
      "building tree 628 of 900\n",
      "building tree 629 of 900\n",
      "building tree 630 of 900\n",
      "building tree 631 of 900\n",
      "building tree 632 of 900\n",
      "building tree 633 of 900\n",
      "building tree 634 of 900\n",
      "building tree 635 of 900\n",
      "building tree 636 of 900\n",
      "building tree 637 of 900\n",
      "building tree 638 of 900\n",
      "building tree 639 of 900\n",
      "building tree 640 of 900\n",
      "building tree 641 of 900\n",
      "building tree 642 of 900\n",
      "building tree 643 of 900\n",
      "building tree 644 of 900\n",
      "building tree 645 of 900\n",
      "building tree 646 of 900\n",
      "building tree 647 of 900\n",
      "building tree 648 of 900\n",
      "building tree 649 of 900\n",
      "building tree 650 of 900\n",
      "building tree 651 of 900\n",
      "building tree 652 of 900\n",
      "building tree 653 of 900\n",
      "building tree 654 of 900\n",
      "building tree 655 of 900\n",
      "building tree 656 of 900\n",
      "building tree 657 of 900\n",
      "building tree 658 of 900\n",
      "building tree 659 of 900\n",
      "building tree 660 of 900\n",
      "building tree 661 of 900\n",
      "building tree 662 of 900\n",
      "building tree 663 of 900\n",
      "building tree 664 of 900\n",
      "building tree 665 of 900\n",
      "building tree 666 of 900\n",
      "building tree 667 of 900\n",
      "building tree 668 of 900\n",
      "building tree 669 of 900\n",
      "building tree 670 of 900\n",
      "building tree 671 of 900\n",
      "building tree 672 of 900\n",
      "building tree 673 of 900\n",
      "building tree 674 of 900\n",
      "building tree 675 of 900\n",
      "building tree 676 of 900\n",
      "building tree 677 of 900\n",
      "building tree 678 of 900\n",
      "building tree 679 of 900\n",
      "building tree 680 of 900\n",
      "building tree 681 of 900\n",
      "building tree 682 of 900\n",
      "building tree 683 of 900\n",
      "building tree 684 of 900\n",
      "building tree 685 of 900\n",
      "building tree 686 of 900\n",
      "building tree 687 of 900\n",
      "building tree 688 of 900\n",
      "building tree 689 of 900\n",
      "building tree 690 of 900\n",
      "building tree 691 of 900\n",
      "building tree 692 of 900\n",
      "building tree 693 of 900\n",
      "building tree 694 of 900\n",
      "building tree 695 of 900\n",
      "building tree 696 of 900\n",
      "building tree 697 of 900\n",
      "building tree 698 of 900\n",
      "building tree 699 of 900\n",
      "building tree 700 of 900\n",
      "building tree 701 of 900\n",
      "building tree 702 of 900\n",
      "building tree 703 of 900\n",
      "building tree 704 of 900\n",
      "building tree 705 of 900\n",
      "building tree 706 of 900\n",
      "building tree 707 of 900\n",
      "building tree 708 of 900\n",
      "building tree 709 of 900\n",
      "building tree 710 of 900\n",
      "building tree 711 of 900\n",
      "building tree 712 of 900\n",
      "building tree 713 of 900\n",
      "building tree 714 of 900\n",
      "building tree 715 of 900\n",
      "building tree 716 of 900\n",
      "building tree 717 of 900\n",
      "building tree 718 of 900\n",
      "building tree 719 of 900\n",
      "building tree 720 of 900\n",
      "building tree 721 of 900\n",
      "building tree 722 of 900\n",
      "building tree 723 of 900\n",
      "building tree 724 of 900\n",
      "building tree 725 of 900\n",
      "building tree 726 of 900\n",
      "building tree 727 of 900\n",
      "building tree 728 of 900\n",
      "building tree 729 of 900\n",
      "building tree 730 of 900\n",
      "building tree 731 of 900\n",
      "building tree 732 of 900\n",
      "building tree 733 of 900\n",
      "building tree 734 of 900\n",
      "building tree 735 of 900\n",
      "building tree 736 of 900\n",
      "building tree 737 of 900\n",
      "building tree 738 of 900\n",
      "building tree 739 of 900\n",
      "building tree 740 of 900\n",
      "building tree 741 of 900\n",
      "building tree 742 of 900\n",
      "building tree 743 of 900\n",
      "building tree 744 of 900\n",
      "building tree 745 of 900\n",
      "building tree 746 of 900\n",
      "building tree 747 of 900\n",
      "building tree 748 of 900\n",
      "building tree 749 of 900\n",
      "building tree 750 of 900\n",
      "building tree 751 of 900\n",
      "building tree 752 of 900\n",
      "building tree 753 of 900\n",
      "building tree 754 of 900\n",
      "building tree 755 of 900\n",
      "building tree 756 of 900\n",
      "building tree 757 of 900\n",
      "building tree 758 of 900\n",
      "building tree 759 of 900\n",
      "building tree 760 of 900\n",
      "building tree 761 of 900\n",
      "building tree 762 of 900\n",
      "building tree 763 of 900\n",
      "building tree 764 of 900\n",
      "building tree 765 of 900\n",
      "building tree 766 of 900\n",
      "building tree 767 of 900\n",
      "building tree 768 of 900\n",
      "building tree 769 of 900\n",
      "building tree 770 of 900\n",
      "building tree 771 of 900\n",
      "building tree 772 of 900\n",
      "building tree 773 of 900\n",
      "building tree 774 of 900\n",
      "building tree 775 of 900\n",
      "building tree 776 of 900\n",
      "building tree 777 of 900\n",
      "building tree 778 of 900\n",
      "building tree 779 of 900\n",
      "building tree 780 of 900\n",
      "building tree 781 of 900\n",
      "building tree 782 of 900\n",
      "building tree 783 of 900\n",
      "building tree 784 of 900\n",
      "building tree 785 of 900\n",
      "building tree 786 of 900\n",
      "building tree 787 of 900\n",
      "building tree 788 of 900\n",
      "building tree 789 of 900\n",
      "building tree 790 of 900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 780 tasks      | elapsed:   54.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 791 of 900\n",
      "building tree 792 of 900\n",
      "building tree 793 of 900\n",
      "building tree 794 of 900\n",
      "building tree 795 of 900\n",
      "building tree 796 of 900\n",
      "building tree 797 of 900\n",
      "building tree 798 of 900\n",
      "building tree 799 of 900\n",
      "building tree 800 of 900\n",
      "building tree 801 of 900\n",
      "building tree 802 of 900\n",
      "building tree 803 of 900\n",
      "building tree 804 of 900\n",
      "building tree 805 of 900\n",
      "building tree 806 of 900\n",
      "building tree 807 of 900\n",
      "building tree 808 of 900\n",
      "building tree 809 of 900\n",
      "building tree 810 of 900\n",
      "building tree 811 of 900\n",
      "building tree 812 of 900\n",
      "building tree 813 of 900\n",
      "building tree 814 of 900\n",
      "building tree 815 of 900\n",
      "building tree 816 of 900\n",
      "building tree 817 of 900\n",
      "building tree 818 of 900\n",
      "building tree 819 of 900\n",
      "building tree 820 of 900\n",
      "building tree 821 of 900\n",
      "building tree 822 of 900\n",
      "building tree 823 of 900\n",
      "building tree 824 of 900\n",
      "building tree 825 of 900\n",
      "building tree 826 of 900\n",
      "building tree 827 of 900\n",
      "building tree 828 of 900\n",
      "building tree 829 of 900\n",
      "building tree 830 of 900\n",
      "building tree 831 of 900\n",
      "building tree 832 of 900\n",
      "building tree 833 of 900\n",
      "building tree 834 of 900\n",
      "building tree 835 of 900\n",
      "building tree 836 of 900\n",
      "building tree 837 of 900\n",
      "building tree 838 of 900\n",
      "building tree 839 of 900\n",
      "building tree 840 of 900\n",
      "building tree 841 of 900\n",
      "building tree 842 of 900\n",
      "building tree 843 of 900\n",
      "building tree 844 of 900\n",
      "building tree 845 of 900\n",
      "building tree 846 of 900\n",
      "building tree 847 of 900\n",
      "building tree 848 of 900\n",
      "building tree 849 of 900\n",
      "building tree 850 of 900\n",
      "building tree 851 of 900\n",
      "building tree 852 of 900\n",
      "building tree 853 of 900\n",
      "building tree 854 of 900\n",
      "building tree 855 of 900\n",
      "building tree 856 of 900\n",
      "building tree 857 of 900\n",
      "building tree 858 of 900\n",
      "building tree 859 of 900\n",
      "building tree 860 of 900\n",
      "building tree 861 of 900\n",
      "building tree 862 of 900\n",
      "building tree 863 of 900\n",
      "building tree 864 of 900\n",
      "building tree 865 of 900\n",
      "building tree 866 of 900\n",
      "building tree 867 of 900\n",
      "building tree 868 of 900\n",
      "building tree 869 of 900\n",
      "building tree 870 of 900\n",
      "building tree 871 of 900\n",
      "building tree 872 of 900\n",
      "building tree 873 of 900\n",
      "building tree 874 of 900\n",
      "building tree 875 of 900\n",
      "building tree 876 of 900\n",
      "building tree 877 of 900\n",
      "building tree 878 of 900\n",
      "building tree 879 of 900\n",
      "building tree 880 of 900\n",
      "building tree 881 of 900\n",
      "building tree 882 of 900\n",
      "building tree 883 of 900\n",
      "building tree 884 of 900\n",
      "building tree 885 of 900\n",
      "building tree 886 of 900\n",
      "building tree 887 of 900\n",
      "building tree 888 of 900\n",
      "building tree 889 of 900\n",
      "building tree 890 of 900\n",
      "building tree 891 of 900\n",
      "building tree 892 of 900\n",
      "building tree 893 of 900\n",
      "building tree 894 of 900\n",
      "building tree 895 of 900\n",
      "building tree 896 of 900\n",
      "building tree 897 of 900\n",
      "building tree 898 of 900\n",
      "building tree 899 of 900\n",
      "building tree 900 of 900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 900 out of 900 | elapsed:  1.0min finished\n",
      "[Parallel(n_jobs=10)]: Using backend ThreadingBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done  12 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=10)]: Done 108 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=10)]: Done 268 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=10)]: Done 300 out of 300 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8097982708933718\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     96876\n",
      "         1.0       0.88      0.75      0.81       375\n",
      "\n",
      "    accuracy                           1.00     97251\n",
      "   macro avg       0.94      0.87      0.90     97251\n",
      "weighted avg       1.00      1.00      1.00     97251\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend ThreadingBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done  12 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=10)]: Done 108 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=10)]: Done 268 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=10)]: Done 492 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=10)]: Done 780 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=10)]: Done 900 out of 900 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8055130168453293\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     96876\n",
      "         1.0       0.95      0.70      0.81       375\n",
      "\n",
      "    accuracy                           1.00     97251\n",
      "   macro avg       0.97      0.85      0.90     97251\n",
      "weighted avg       1.00      1.00      1.00     97251\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pickle\n",
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "# Create a VotingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "rf = RandomForestClassifier(class_weight='balanced', n_estimators=300, max_depth=None, min_samples_split=10, min_samples_leaf=4, criterion='entropy', n_jobs=-1, verbose=3)\n",
    "\n",
    "rf2 = RandomForestClassifier(class_weight='balanced', n_estimators=900, max_depth=None, min_samples_split=10, min_samples_leaf=1, criterion='entropy', n_jobs=-1, verbose=3)\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "rf2.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rf.predict(X_val)\n",
    "print(f1_score(y_val, y_pred_rf))\n",
    "print(classification_report(y_val, y_pred_rf))\n",
    "\n",
    "y_pred_rf2 = rf2.predict(X_val)\n",
    "print(f1_score(y_val, y_pred_rf2))\n",
    "print(classification_report(y_val, y_pred_rf2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Initialize the Bagging Classifier\n",
    "bagging_clf = BaggingClassifier(estimator=xgb_clf,\n",
    "                                n_estimators=500,  # Number of base estimators in the ensemble\n",
    "                                random_state=42,\n",
    "                                n_jobs=-1,\n",
    "                                verbose=3)  # Use parallel processing\n",
    "\n",
    "bagging_clf.fit(X_train, y_train)\n",
    "y_pred_bag = bagging_clf.predict(X_val)\n",
    "print(f1_score(y_val, y_pred_bag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pickle\n",
    "\n",
    "# Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier(criterion='entropy', random_state=42)\n",
    "\n",
    "# Parameters for GridSearchCV\n",
    "param_grid = {\n",
    "    'max_depth': [7, 10, 20, None],\n",
    "    'min_samples_split': [2, 5, 10, 20],\n",
    "    'min_samples_leaf': [1, 2, 4, 8]\n",
    "}\n",
    "\n",
    "# GridSearchCV\n",
    "grid_search = GridSearchCV(dt_classifier, param_grid, cv=5, scoring='f1_micro', n_jobs=-1, verbose=3)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and score\n",
    "best_params_dt = grid_search.best_params_\n",
    "\n",
    "# Validation\n",
    "best_dt = grid_search.best_estimator_\n",
    "\n",
    "y_pred_dt = best_dt.predict(X_val)\n",
    "\n",
    "val_f1_dt = f1_score(y_val, y_pred_dt)\n",
    "\n",
    "(best_params_dt, val_f1_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pickle\n",
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "# Create a VotingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier(class_weight='balanced', n_estimators=300, max_depth=None, min_samples_split=10, min_samples_leaf=4, criterion='entropy')\n",
    "\n",
    "rf2 = RandomForestClassifier(class_weight='balanced', n_estimators=900, max_depth=None, min_samples_split=10, min_samples_leaf=1, criterion='entropy')\n",
    "\n",
    "xgb_clf = XGBClassifier(colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=300, use_label_encoder=False, eval_metric='logloss')\n",
    "\n",
    "# Initialize the Bagging Classifier\n",
    "bagging_xgb_clf = BaggingClassifier(estimator=xgb_clf,\n",
    "                                n_estimators=200,\n",
    "                                n_jobs=-1)  # Use parallel processing\n",
    "\n",
    "# Initialize the Bagging Classifier\n",
    "bagging_rf_clf = BaggingClassifier(estimator=rf,\n",
    "                                n_estimators=200,\n",
    "                                n_jobs=-1)\n",
    "\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('rf', rf), ('rf2', rf2), ('xgb', xgb_clf), ('bag_rf', bagging_rf_clf), ('bag_xgb', bagging_xgb_clf)],\n",
    "    voting='soft',\n",
    "    n_jobs=-1,\n",
    "    verbose=3\n",
    ")\n",
    "\n",
    "# Train the ensemble model\n",
    "vot_clf = voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# # Evaluate the model\n",
    "# scores = cross_val_score(voting_clf, X, y, cv=5, scoring='f1_micro', n_jobs=-1, verbose=3)\n",
    "# print(\"F1 Score: \", scores.mean())\n",
    "y_pred_vote = vot_clf.predict(X_val)\n",
    "f1_score_vote = f1_score(y_val, y_pred_vote)\n",
    "print(f1_score_vote)\n",
    "\n",
    "with open('best_vote_model.obj', 'wb') as f:\n",
    "    pickle.dump(vot_clf, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
